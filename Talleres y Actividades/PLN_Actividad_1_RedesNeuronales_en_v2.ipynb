{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mottasilvia/UCU-NLP/blob/main/PLN_Actividad_1_RedesNeuronales_en_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados de la Clasificación de Reviews de Películas\n",
        "\n",
        "| Modelo                       | Embeddings          | Accuracy | Negative Precision | Negative Recall | Negative F1-Score | Positive Precision | Positive Recall | Positive F1-Score | Macro Avg Precision | Macro Avg Recall | Macro Avg F1-Score | Weighted Avg Precision | Weighted Avg Recall | Weighted Avg F1-Score |\n",
        "|------------------------------|---------------------|----------|--------------------|----------------|-------------------|--------------------|----------------|-------------------|----------------------|------------------|---------------------|-------------------------|---------------------|------------------------|\n",
        "| SimpleRNN                    | Aleatorios          | 0.49     | 0.49               | 0.69           | 0.57              | 0.48               | 0.29           | 0.37              | 0.49                 | 0.49             | 0.47                | 0.49                    | 0.49                | 0.47                   |\n",
        "| CNN                          | Aleatorios          | 0.78     | 0.79               | 0.77           | 0.78              | 0.77               | 0.79           | 0.78              | 0.78                 | 0.78             | 0.78                | 0.78                    | 0.78                | 0.78                   |\n",
        "| RNN                          | Preentrenados (es)  | 0.65     | 0.66               | 0.60           | 0.63              | 0.63               | 0.69           | 0.66              | 0.65                 | 0.65             | 0.64                | 0.65                    | 0.65                | 0.64                   |\n",
        "| RNN                          | Preentrenados (en)  | 0.76     | 0.76               | 0.74           | 0.75              | 0.75               | 0.77           | 0.76              | 0.76                 | 0.76             | 0.75                | 0.76                    | 0.76                | 0.75                   |\n",
        "| LSTM                         | Preentrenados (es)  | 0.50     | 0.50               | 1.00           | 0.67              | 0.00               | 0.00           | 0.00              | 0.25                 | 0.50             | 0.33                | 0.25                    | 0.50                | 0.33                   |\n",
        "| LSTM                         | Preentrenados (en)  | 0.50     | 0.00               | 0.00           | 0.00              | 0.50               | 1.00           | 0.67              | 0.25                 | 0.50             | 0.33                | 0.25                    | 0.50                | 0.33                   |\n",
        "| GRU                          | Preentrenados (es)  | 0.50     | 0.50               | 1.00           | 0.67              | 0.00               | 0.00           | 0.00              | 0.25                 | 0.50             | 0.33                | 0.25                    | 0.50                | 0.33                   |\n",
        "| GRU                          | Preentrenados (en)  | 0.50     | 0.00               | 0.00           | 0.00              | 0.50               | 1.00           | 0.67              | 0.25                 | 0.50             | 0.33                | 0.25                    | 0.50                | 0.33                   |\n",
        "| Bidirectional LSTM           | Preentrenados (es)  | 0.48     | 0.47               | 0.47           | 0.48              | 0.47               | 0.47           | 0.48              | 0.47                 | 0.47             | 0.48                | 0.47                    | 0.47                | 0.47                   |\n",
        "| Bidirectional LSTM           | Preentrenados (en)  | 0.56     | 0.56               | 0.48           | 0.52              | 0.55               | 0.63           | 0.59              | 0.56                 | 0.55             | 0.55                | 0.56                    | 0.56                | 0.55                   |\n",
        "| LSTM                         | Aleatorios          | 0.50     | 0.50               | 1.00           | 0.67              | 0.00               | 0.00           | 0.00              | 0.25                 | 0.50             | 0.33                | 0.25                    | 0.50                | 0.33                   |\n",
        "\n",
        "## Conclusiones\n",
        "\n",
        "1. **Mejor Modelo**:\n",
        "   - El **CNN con embeddings aleatorios** se destacó como el mejor modelo con una accuracy de 0.78. Este modelo también tuvo buenos valores en todas las métricas de precisión, recall y F1-score.\n",
        "\n",
        "2. **Influencia de los Embeddings**:\n",
        "   - Los embeddings preentrenados en inglés mostraron mejor rendimiento que los embeddings preentrenados en español, lo cual es lógico dado que las reviews están en inglés.\n",
        "   - El uso de embeddings aleatorios fue sorprendentemente efectivo, especialmente en el modelo CNN.\n",
        "\n",
        "3. **Desempeño de Diferentes Modelos**:\n",
        "   - Los modelos basados en RNN y LSTM no mejoraron significativamente con los embeddings preentrenados en español debido a la discrepancia idiomática.\n",
        "   - El modelo Bidirectional LSTM con embeddings preentrenados en inglés mostró un desempeño aceptable, pero no superó al modelo CNN.\n",
        "   - El modelo LSTM con embeddings aleatorios tuvo una accuracy de 0.50, con los siguientes resultados detallados:\n",
        "     - **Negative**: Precision: 0.50, Recall: 1.00, F1-Score: 0.67\n",
        "     - **Positive**: Precision: 0.00, Recall: 0.00, F1-Score: 0.00\n",
        "     - **Macro Avg**: Precision: 0.25, Recall: 0.50, F1-Score: 0.33\n",
        "     - **Weighted Avg**: Precision: 0.25, Recall: 0.50, F1-Score: 0.33\n",
        "\n",
        "Estos resultados destacan la importancia de utilizar embeddings en el idioma adecuado y el potencial de diferentes arquitecturas de redes neuronales en tareas de clasificación de texto.\n"
      ],
      "metadata": {
        "id": "4AD-fnTfjTPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential # Import Sequential from tensorflow.keras\n",
        "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN # Import recurrent layers from tensorflow.keras\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout # Import core layers from tensorflow.keras\n",
        "from tensorflow.keras.layers import Embedding # Import Embedding layer from tensorflow.keras\n",
        "from tensorflow.keras.layers import BatchNormalization # Import BatchNormalization from tensorflow.keras\n",
        "from tensorflow.keras.utils import to_categorical # Import to_categorical for one-hot encoding\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D # Import additional layers from tensorflow.keras\n",
        "from tensorflow.keras.preprocessing import sequence, text # Import preprocessing modules from tensorflow.keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping # Import EarlyStopping from tensorflow.keras\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "8EHR_YVHCwHC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la disponibilidad de la GPU\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh7TSH6Ed2er",
        "outputId": "980f0a79-f150-4eaf-bab3-5eaaff8463fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "Default GPU Device: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqjQlE90bmXL",
        "outputId": "632bb614-aeab-49f5-e603-4b78c0405dd2"
      },
      "source": [
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LATMW4Fyb5IM",
        "outputId": "33b391de-2f86-4961-dbb5-f1852efdc7bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "carpeta_laboratorios = \"/\"\n",
        "path_laboratorios = '/content/drive/My Drive/'\n",
        "#df = pd.read_csv(path_laboratorios+\"Canciones_limpias_finalisismo.csv\")\n",
        "\n",
        "#train = pd.read_csv(path_laboratorios+\"train.csv\")\n",
        "#test = pd.read_csv(path_laboratorios+\"test.csv\")\n",
        "#validation = pd.read_csv(path_laboratorios+\"val.csv\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_to_folder(zip_files, target_dir=\"unzipped_files\"):\n",
        "  os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "  for zip_file in zip_files:\n",
        "    filename, _ = os.path.splitext(os.path.basename(zip_file))\n",
        "    folder_name = target_dir\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "      zip_ref.extractall(folder_name)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # Example usage\n",
        "  zip_files = [\"/content/drive/MyDrive/UCU-TesisFinal/aarchive (3).zip\"]\n",
        "  unzip_to_folder(zip_files, \"/content/Movie\")\n"
      ],
      "metadata": {
        "id": "_WUBOSyMEn9y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "# Define los paths a los directorios que contienen las reseñas\n",
        "neg_dir = '/content/Movie/txt_sentoken/neg'\n",
        "pos_dir = '/content/Movie/txt_sentoken/pos'\n",
        "\n",
        "# Función para leer reseñas de un directorio y asignar una etiqueta\n",
        "def load_reviews_from_directory(directory, tag):\n",
        "    reviews = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
        "                review = file.read()\n",
        "                reviews.append((review, tag))\n",
        "    return reviews\n",
        "\n",
        "# Verificar si los directorios existen\n",
        "if os.path.exists(neg_dir) and os.path.exists(pos_dir):\n",
        "    # Cargar reseñas negativas y positivas\n",
        "    negative_reviews = load_reviews_from_directory(neg_dir, 'negative')\n",
        "    positive_reviews = load_reviews_from_directory(pos_dir, 'positive')\n",
        "\n",
        "    # Combinar las reseñas en un único DataFrame\n",
        "    all_reviews = negative_reviews + positive_reviews\n",
        "    df = pd.DataFrame(all_reviews, columns=['review', 'tag'])\n",
        "\n",
        "    # Mostrar el DataFrame\n",
        "    from IPython.display import display\n",
        "    display(df)\n",
        "\n",
        "    # Verificar las primeras filas del DataFrame\n",
        "    print(df.head())\n",
        "    # Verificar el balance de clases\n",
        "    class_counts = df['tag'].value_counts()\n",
        "    print(\"Distribución de clases:\")\n",
        "    print(class_counts)\n",
        "\n",
        "    # Visualización de la distribución de clases\n",
        "    import matplotlib.pyplot as plt\n",
        "    class_counts.plot(kind='bar')\n",
        "    plt.title('Distribución de Clases')\n",
        "    plt.xlabel('Clase')\n",
        "    plt.ylabel('Número de Muestras')\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Los directorios especificados no existen. Verifica los paths y vuelve a intentarlo.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TjjPOysInDBS",
        "outputId": "80f9d937-63fe-4a00-95ce-6d8e8fb1b644"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                 review       tag\n",
              "0     alexandre dumas meets hong kong action with ne...  negative\n",
              "1     this is my first review that i post to this ne...  negative\n",
              "2     an 18-foot-high , 43-foot-long dragon is the c...  negative\n",
              "3     in double jeopardy , the stakes are high . \\nt...  negative\n",
              "4     when it comes to the average teenage romantic ...  negative\n",
              "...                                                 ...       ...\n",
              "1995  before even seeing a single frame of the film ...  positive\n",
              "1996  i'll be the first to admit i didn't expect muc...  positive\n",
              "1997  melvin udall is a heartless man . \\nhe spends ...  positive\n",
              "1998  the booming introduction music finishes , and ...  positive\n",
              "1999  ingredients : london gal , fate , true love , ...  positive\n",
              "\n",
              "[2000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb3cbfbc-477c-49cb-b396-2eda7bb43c16\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>alexandre dumas meets hong kong action with ne...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this is my first review that i post to this ne...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>an 18-foot-high , 43-foot-long dragon is the c...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in double jeopardy , the stakes are high . \\nt...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>when it comes to the average teenage romantic ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>before even seeing a single frame of the film ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>i'll be the first to admit i didn't expect muc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>melvin udall is a heartless man . \\nhe spends ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>the booming introduction music finishes , and ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>ingredients : london gal , fate , true love , ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb3cbfbc-477c-49cb-b396-2eda7bb43c16')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb3cbfbc-477c-49cb-b396-2eda7bb43c16 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb3cbfbc-477c-49cb-b396-2eda7bb43c16');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fe45be14-c5c2-46bb-9420-fa7313710171\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe45be14-c5c2-46bb-9420-fa7313710171')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fe45be14-c5c2-46bb-9420-fa7313710171 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a1131ec0-8cd9-4f8e-8af6-0d471b88f390\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a1131ec0-8cd9-4f8e-8af6-0d471b88f390 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"in 1995 , brian singer and christopher mcquarrie dreamed up a simple concept : the audience isn't stupid . \\nfrom that , they went on and created the most plot-driven , intricately pieced movie in the last 25 years . \\nthe result : the usual suspects , one hell of a movie that redefines the word plot twist . \\nthe story is convoluted , and is really confusing to read , although easy to follow on screen . \\nspecial investigator kujan ( chazz palminteri ) grills \\\" verbal \\\" kint ( kevin spacey ) , a crippled con-man who is the lone survivor of an la boat explosion that claimed more than 20 victims . \\nkujan wants to confirm that his nemesis , the rogue cop keaton ( gabriel byrne ) , is actually dead . \\nkint relates the majority of the film in flashback , beginning with the fateful day when five shifty guys meet in a police-station lineup in new york city . \\nalong with dour keaton , kint encounters cheerfully sociopathic mcmanus ( stephen baldwin ) , mordantly sarcastic hockney ( kevin pollak ) , and fenster ( benicio del toro ) , whose speech is virtually incomprehensible . \\ntogether they plot to steal a small fortune in gems from \\\" new york's finest taxi service \\\" --crooked cops who provide escort service for visiting drug kingpins . \\nwhat follows is a shell-game of violence and betrayal , all hinging on the identity of a mysterious villain called keyser soze . \\nthe film is brilliantly compact : its the shortest 90 minutes you'll ever spend in a movie theater . \\nthe cast is exceptional . \\npalminteri shines , he is brutally honest , a true cop , one who is going after the whole story because its there . \\nbyrne is terrific , his brooding character , his seriousness is needed to supplement the hysteria of benicio del toro , who is a riot as fenster . \\ndel toro is brilliant , his lines are a jumbled mess , you can't understand a word the man says , but it sure is damn funny . \\nbaldwin is also very good , he is careful , methodical , and cold , a chilling character with a nasty streak of hot-blooded sarcasm . \\npollak is also terrific as usual , a very good character actor . \\nhowever , this will be forever known as the film that launched kevin spacey . \\nspacey is simply breathtaking , he is a force on screen , giving a magnetic performance that jars the senses at the end of this twisting maze . \\nspacey's performance will be remembered for years , for it is the best of his career , it may be the best supporting actor performance in the last 50 years . \\nverbal kint is a clever storyteller , weak , oppressed , and gleefully evil to the bone , yet pitiful , one who draws sympathy . \\nthe film is a good one , a decent film until the last 10 minutes . \\nwhat this film boils down to is the greatest ending in cinematic history , for me at least . \\nthe revelation of keyser soze , the closing gunfights , it is something wondrous . \\nyou have to see this movie about 10 times to believe what they do . \\nkudos to mcquarrie and singer for giving the audience a delightful , fast-paced , furiously plot-driven movie with quirky characters , phenomenal acting , and some hilarious moments stuck in the middle . \\nmcquarrie refuses to believe the audience is dumb . \\nwithout furnishing too many details , he concocts his story and lets it run , hoping the audience gets it at the end . \\nwe do . \\nthis might just be the finest cinematic puzzle ever created . \\nkudos also to singer and john ottman , who created the score . \\nthey both create what is a true film-noir setting , carefully setting up this intricate puzzle until the final , jarring ending . \\nthere are flaws : more questions raised than answers , lack of character development , and no strong female characters ( save one ) . \\nhowever , the plot , and that stunning ending , make up for all the flaws and more . \\nif you haven't seen the movie , rent it . \\nwatch it . \\nthen rewind the tape , and watch it again . \\ntrust me , you'll be amazed . \\n\",\n          \" \\\" love to kill \\\" starts off aimlessly and gets progressively less coherent as time passes . \\nat the outset , the movie appears to be about tony danza , who's an illegal distributor of guns , trying to establish a relationship with an unsuspecting woman . \\ndanza sets up a double date with her , her sister , and a collegue of his . \\neverything seems to be going well , until the sister accidentally dies by falling down a set of stairs . \\nmuch confusion and mahem ensues , as the death is covered up and other associates of danza's begin to emerge , all after one thing or another . \\nsound confusing ? \\nit is . \\ni think what the filmmakers were trying to do is take the standard crime movie and throw in a little humour and levity . \\nin some respects , it works . \\nbut the majority of the film is a convoluted and confusing mess . \\ncharacters keep popping up with no explanation , demanding money for deals that occur off-screen . \\nthe only aspect of the movie that actually works is the budding relationship between danza and the dead woman's sister . \\nbut so little time is devoted to this part of the story , we never really become too familiar with these characters , and because of this , we don't really care what happens to them . \\nwell , i didn't , at least . \\none thing i will give the movie is that it's a complete departure for tony danza . \\nhere's a guy , because of his many sitcom roles , who's ingrained in the consciousness as a nice guy who always does the right thing . \\nhere , he plays a man who's just looking out for himself , and if that means he needs to kill in order to save his own skin , so be it . \\ni was very impressed by his performance , and within minutes of the start of the film , i had forgotten all about his good-guy persona . \\nmichael madsen is also good as an associate of danza's who spends half the movie buddying up to him and the other half trying to kill him . \\nlike i said , it's not exactly a linear storyline . \\n \\\" love to kill \\\" should be praised for trying to do something different with the well worn crime genre , but it's just too bad that the story doesn't really add up to much . \\nthe stars deserved better , and so did the audience . \\n\",\n          \"mars attacks ! \\n ( 1996 ) - c : jack nicholson , glenn close , annette bening , martin short , danny devito , rod steiger , pierce brosnan , sarah jessica parker , michael j . fox , jim brown , pam grier , joe don baker , natalie portman , christina applegate , lisa marie , tom jones . \\nthis is director tim burton's finest film to date . \\nmany will compare this tale of martians who invade earth to independence day , but even though the stories are similar , they really are two distinctly different films . \\nhowever as a whole , mars attacks is much more entertaining than id4 , and i loved id4 . \\nyou really have to be in the right frame of mind to enjoy this film . \\nit is completely wacked-out and unlike anything you've ever seen . \\nonce the silly tone of the film is set , it's easy to just sit back and throw logic out the window because logic and comedy just don't mix . \\nthe plot is simple : martians invade the earth . \\nbut it's different than any other invasion film . \\nusually it's the evil aliens versus the heroic humans . \\nthis time however , it's the goofy aliens versus the equally goofy humans . \\nthe martians , who are all computer generated , are just about the funniest things i've seen in a long time . \\nthey look funny , they move funny , and their \\\" language \\\" is hilarious . \\nand about the special effects . \\nthe effects in mars attacks ! \\nare just about the most flawless ones i've seen to date . \\nthe computer animation of the martians combined with the goofy personalities they are given makes them seem 100% real . \\nthere are just a couple of scenes that don't work , mainly those involving sarah jessica parker and pierce brosnan on board an alien ship . \\nalso , glenn close overacts tremendously in her ( thankfully ) very limited screen time , so much so that i actually applauded silently when her character meets her demise . \\nbut there are many big laughs in the film , as i said , if you are in the right mood . \\ncould it have been funnier ? \\ncertainly . \\nwas it funny enough ? \\nyes . \\nwas i entertained ? \\nabsolutely . \\non a personal note , i'd like to thank whomever cast rod steiger ( my favorite actor ) in the film as war-crazy general decker . \\nfinally , after many very small parts in direct to video garbage and minor tv roles , steiger is back on the big screen in a real movie that many people will see . \\nwhile he's not given the type of role that you can give a real \\\" performance \\\" in , he does the job well and has some good lines of dialogue . \\nthe preview audience i saw the film with really seemed to enjoy him . \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review       tag\n",
            "0  alexandre dumas meets hong kong action with ne...  negative\n",
            "1  this is my first review that i post to this ne...  negative\n",
            "2  an 18-foot-high , 43-foot-long dragon is the c...  negative\n",
            "3  in double jeopardy , the stakes are high . \\nt...  negative\n",
            "4  when it comes to the average teenage romantic ...  negative\n",
            "Distribución de clases:\n",
            "tag\n",
            "negative    1000\n",
            "positive    1000\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir el DataFrame en train (60%) y temp (40%)\n",
        "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42, stratify=df['tag'])\n",
        "\n",
        "# Dividir el temp_df en validation (50% de 40% -> 20%) y test (50% de 40% -> 20%)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['tag'])\n",
        "\n",
        "# Mostrar los tamaños de los conjuntos de datos\n",
        "print(f\"Tamaño del conjunto de entrenamiento: {len(train_df)}\")\n",
        "print(f\"Tamaño del conjunto de validación: {len(val_df)}\")\n",
        "print(f\"Tamaño del conjunto de prueba: {len(test_df)}\")\n",
        "\n",
        "# Mostrar las primeras filas de cada conjunto de datos para verificación\n",
        "print(\"Conjunto de entrenamiento:\")\n",
        "print(train_df.head())\n",
        "# Verificar el balance de clases\n",
        "class_counts_train = train_df['tag'].value_counts()\n",
        "print(\"Distribución de clases de train:\")\n",
        "print(class_counts_train)\n",
        "print(\"\\nConjunto de validación:\")\n",
        "print(val_df.head())\n",
        "\n",
        "print(\"\\nConjunto de prueba:\")\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW58VTUiqNb8",
        "outputId": "ad2fb313-bf3c-4c00-85c7-77b9bde52c1c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: 1200\n",
            "Tamaño del conjunto de validación: 400\n",
            "Tamaño del conjunto de prueba: 400\n",
            "Conjunto de entrenamiento:\n",
            "                                                 review       tag\n",
            "1523  susan granger's review of \" the closet \" ( mir...  positive\n",
            "1202  when i left the theater after seeing david lyn...  positive\n",
            "468    \" saving silverman \" is a good example of a g...  negative\n",
            "578   if you're into watching near on two hours of b...  negative\n",
            "1029   \" the end of the affair \" is a dark and moody...  positive\n",
            "Distribución de clases de train:\n",
            "tag\n",
            "positive    600\n",
            "negative    600\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Conjunto de validación:\n",
            "                                                 review       tag\n",
            "1152  full metal jacket , very much like every other...  positive\n",
            "1762  available for rental - october 12 , 1999 \\n10 ...  positive\n",
            "1142  i guess there are those who have never been ki...  positive\n",
            "612   first troy beyer wrote the critically panned \"...  negative\n",
            "202   what would you do if no one could see you ? \\n...  negative\n",
            "\n",
            "Conjunto de prueba:\n",
            "                                                 review       tag\n",
            "200    \" i would appreciate it if you didn't do that...  negative\n",
            "1702  if there is one thing that bothers me about ho...  positive\n",
            "1209  jacques tati's 1953 classic \" les vacances de ...  positive\n",
            "1451  the release of dolores claiborne into wide rel...  positive\n",
            "1409  on seeing the outrageous previews for bulworth...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX8PvSfgpc_1"
      },
      "source": [
        "# **Redes Neuronales Recurrentes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC_wtAZ_osQV"
      },
      "source": [
        "Veamos el máximo de palabras por review para tener una idea luego a la hora de paddear y todas esas cosas.-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjsIc7QXe9u6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0824909c-63c2-4de3-d479-4a1c9384a4cd"
      },
      "source": [
        "max_words_per_review = df['review'].apply(lambda x: len(str(x).split())).max()\n",
        "max_words_per_review"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2678"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv7p-XHpzTFq"
      },
      "source": [
        "max_len = 2700 #Si bien el máximo es 2678, ponemos 2700 para tener un poco más de holgura. Se va a usar después para padear!"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFSFwIz0ylXC"
      },
      "source": [
        "xtrain = train_df.review.values\n",
        "xvalid = val_df.review.values\n",
        "xtest = test_df.review.values\n",
        "ytrain = train_df.tag.values\n",
        "yvalid = val_df.tag.values\n",
        "ytest = test_df.tag.values\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6LD_n0jmv3-",
        "outputId": "ddb2d48f-c0ba-4db7-9b73-a1063200d092"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['susan granger\\'s review of \" the closet \" ( miramax films ) \\nin this hilarious french farce , a shy , boring accountant ( daniel auteil ) named francois pignon discovers he\\'s going to be fired from his job at a condom factory . \\nlonely and distraught , he contemplates suicide . \\nbut then he runs into belone ( michel aumont ) , an elderly homosexual neighbor , who suggests a \" sex discrimination \" lawsuit to intimidate management . \\nas evidence , belone concocts provocative photographs of pignon locked in a leather-clad embrace with another man and mails them anonymously to pignon\\'s boss . \\nwhen the racy snapshots start circulating around the factory , not only does pignon get his job back but he suddenly finds himself the focus of attention as an openly gay man . \\nhis lusty supervisor ( michele laroque ) is so intrigued that she wonders if , perhaps , she could change his sexual preferences . \\neven his ex-wife ( alexandra vandernoot ) and indifferent teenage son ( stanislas crevillen ) drop their disdain . \\nbut not everyone is enchanted . \\na mucho macho co-worker felix ( gerard depardieu ) , a self-righteous homophobe , is stunned and repulsed when he\\'s forced by the pr director ( thierry lhermite ) to grovel and court pignon\\'s friendship or risk losing his own job . \\nwriter/director francis verber artfully milks the farcical comedy as he dissects the hypocrisy of political correctness , veering off-track only occasionally into pedophilia . \\ndaniel auteuil ( \" the widow of saint-pierre \" ) is delightful - particularly with a blown-up condom perched on his head , riding on a float in a gay pride parade - and gerard depardieu delivers one of his most restrained , and effective , performances . \\non the granger movie gauge of 1 to 10 , \" the closet \" is a frankly sexual , adult 8 . \\nit\\'s so clever , in fact , that hollywood is already planning to re-make it in english , like \" la cage aux folles . \" \\n',\n",
              "       'when i left the theater after seeing david lynch\\'s \" lost highway , \" i remarked to a fellow movie-goer , \" i feel like someone just sucked my brains out through my nose and put them back in through my ears . \" \\nin his first feature film in five years , lynch delivers a film second only to his debut picture \" eraserhead \" on the weirdness scale . \\nyou won\\'t \" know \" what happened when it\\'s over , though there are certainly enough clues with which to make some reasonable guesses . \\nit is difficult to describe the plot of this film , because it depends partly on how you interpret it . \\ni can , however , describe what we see on the screen : l . a . jazz saxophonist fred madison ( bill pullman ) and his wife renee ( patricia arquette ) , whom he clearly suspects of infidelity , receive a series of videotapes apparently filmed inside their house while they were asleep . \\nthey are , naturally enough , more than a little frightened and confused , and it doesn\\'t help matters any when \" mystery man \" ( robert blake ) approaches fred at a party and proceeds to call himself on the telephone at the madisons\\' house in a scene that is at once hilarious and unnerving . \\nthe next morning , fred finds another videotape which , to his ( and our ) surprise , shows him brutally murdering renee in their bedroom . \\nhe is convicted of her murder and sent to death row , where he inexplicably disappears one night and is replaced by a young mechanic named pete dayton ( balthazar getty ) . \\nthe perplexed prison officials release dayton , whose life begins to intersect with fred in a number of ways - most notably his affair with alice wakefield ( arquette again ) , a blonde who is otherwise renee\\'s spitting image , and another encounter with the mystery man . \\ni would be giving away a little too much to reveal any more , but suffice it to say that lynch doesn\\'t offer any neat wrap ? ups , nor does he put a lid on the metaphysical confusion : the cinematic demons of \" lost highway \" are out in full force from beginning to end . \\nthis description might make \" lost highway \" sound like a giddy exercise in haywire surrealism , but in fact , while there are traces of lynch\\'s weird sense of humor , this film is anything but giddy most of the time . \\non the contrary , lost highway is a dark and perplexing mystery that takes lynch\\'s previous excursions into murder and intrigue one step farther . \\nthe film does not revolve around a character investigating a mystery ; rather , the character * is * the mystery . \\nthere are recurring and at times deeply disturbing images of suspicion , distrust , and infidelity thoughout the film that seem to indicate a deluded , fractured psyche at the root of all the bizarre goings-on here . \\nwe , the audience , are left to puzzle out whose psyche it is that is driving this ( probably fred\\'s , in my opinion ) and what , in that case , the other characters and events are meant to represent . \\nall of this proceeds , appropriately , in lynch\\'s typically slow-paced , idiosyncratic style . \\nas is often the case , lynch relies on sound , imagery , and mood more than on dialogue and action to tell his story , and in \" lost highway \" it works perfectly . \\nthere are scenes when the camera lingers on fred\\'s blank expression as he drifts uncomfortably down a hallway , or on his pained face in his prison cell while the haunting strains of this mortal coil\\'s \" song to the siren \" can be heard faintly in the background ; nothing is technically \" happening \" in these scenes , yet they present a vivid picture of a man losing his grip just as effective as , if not more so than , the hysterical screaming found in most movie presentations of insanity . \\nlynch\\'s direction and director of photography pete deming\\'s darkly lit cinematography serve to create a nearly suffocating atmosphere of tension and fear that are exactly what is needed for this story . \\nwell , most of the time , anyway - i have to admit that i was a bit bored at times during the section of the film with pete dayton as the protgaonist , which is less inherently interesting and mostly keeps the viewer\\'s attention because of its tie-ins to the original mystery . \\nthe main characters in this \" reality \" - dayton ( a well-meaning but none too intelligent 24-year-old ) , a sleazy gangster ( who for some reason has two names but otherwise is pretty much a stock character ) , and his porn-star girlfriend ( the blond arquette ) - are nothing you couldn\\'t find in any of the two dozen \" pulp fiction \" wannabes ; fortunately , the reappearance of the mystery man as well as some other typically lynchian elements , such as the strained , awkward conversations between pete and his parents , help to preserve the film\\'s spooky , unnerving tone during this stretch . \\nlynch\\'s typically graphic and disturbing portrayals of fringe sexuality , while relevant to the themes of jealousy and adultery , are also somewhat overdone here . \\nit\\'s not exactly exploitative - like almost everything else in this film , the sex is thoroughly weird and creepy and is unlikely to provide any cheap lurid thrills - as much as it is unnecessary and frankly kind of dumb by the seventh or eighth time arquette takes her clothes off . \\nthat said , these minor flaws don\\'t prevent \" lost highway \" from attaining its place as one of the darkest , most unsettling films to hit the screens in recent years . \\nit is a one-way ride down the lost highway of a disturbed mind , and as such it is gripping , intense , and brilliantly effective . \\n',\n",
              "       ' \" saving silverman \" is a good example of a good comedy gone bad . \\nas a love story it is good , however as a comedy it falls flat on it\\'s face . \\ni think throughout the short 90 minutes i laughed a total of seven times . . . and \\nthose were just chuckles at the most ! \\nthe movie doesn\\'t have the oomph to make it a great movie , and doesn\\'t have the script to make it a funny movie . \\nwayne lefessier ( steven zahn ) , j . d . mcnugent ( jack black ) , and darren silverman ( jason biggs ) have grown up all their lives together , they have been best friends forever and vow to stay close till the end . \\nwhile in a bar after doing a show with their band , based on their love of neil diamond , darren meets a young woman named judith ( amanda peet ) whom he instantly falls for . \\nwayne and j . d . however think differently and when judith tells darren that he can never see his friends again , it\\'s up to wayne and j . d . to try and begin saving silverman . \\nthe performances are topnotch and surprisingly , they are what keep the movie afloat . \\njason biggs right off the flop \" loser \" does an ok job playing silverman , but he is stale and flat at times . \\nsteve zahn is perfect in the role of wayne lefessier , and even though the movie is about silverman , lefessier is really the main character and the narrator of the movie itself . \\njack black is well jack black , and he does an all right job as j . d . but he isn\\'t as funny as he has been in the past . \\namanda peet plays the ultimate bitch as judith , and neil diamond plays neil diamond ( he\\'s better at singing than acting ) . \\nanyway the performances in the film are good , but it\\'s too bad the script isn\\'t . \\nspeaking of script , hank nelkan\\'s choppy script is not only badly written , but not funny enough even for an episode of sesame street . \\nthe trailer for the movie , as with most movies gives away everything that happens in the movie , especially the funniest parts . \\nsomewhere \" saving silverman \" was meant to be a good movie , and it could have been , but alas in the end it wasn\\'t . \\ndennis dugan\\'s direction is all right , he adds a few directorial touches here and there , nothing special being a simple comedy . \\n \" saving silverman \" is a perfectly bad movie in more ways than one . \\nit has a great cast , a good director and a sweet story . . . it\\'s \\njust too bad it has a bad script and is all together a bad movie . \\n',\n",
              "       ...,\n",
              "       'it\\'s a curious thing - i\\'ve found that when willis is not called on to carry the whole movie , he\\'s much better and so is the movie . \\neven though , in the sixth sense he is the \" name \" , he doesn\\'t have the pivotal role . \\nthat honour goes to haley osment who plays cole sear ( cute pun , seer ) a 9 year old boy who can see ghosts . \\nif osment was cute or precious , the director going for the maudlin , this would be nothing more than a movie-of-the-week , thankfully , osment is not only better than that , but in some instances , blows everyone else off the screen in a bravura performance . \\nwe get to see his fears , vulnerabilities , strengths and intelligence which makes the sixth sense one of the best movies i\\'ve seen this year . \\nthe whole cast matches him in quality , with willis giving a fairly low key performance that matches the subject matter . \\none thing about this movie , its target . \\nthis isn\\'t a sfxfest like the haunting or a gorefest , this is more what i\\'d call a supernatural drama , more interested in characters than in dazzling you with makeup . \\none caveat : there\\'s a lovely twist in the movie , something like the usual suspects , where you end up replaying the movie in your head rethinking what you have just seen . \\ni was extremely lucky to see it as a sneak preview in toronto , before any hype or critical reviews were out , so i went in with no biases . \\nif anyone want to talk to about the movie before you see it , don\\'t let them . \\nlet the director explain on his own pace and you\\'ll enjoy the movie vastly more . \\n',\n",
              "       'roman emperor marcus aurelius ( richard harris ) chooses his trusted general maximus ( russell crowe ) as his successor . \\nhowever the emperor\\'s evil son commodus ( joaquin phoenix ) murders his father before the announcement can be made , and maximus ( as well as his family ) is sentenced to be executed . \\nmaximus is able to escape his executioners , but is later captured and sold as a slave to proximo ( oliver reed ) . \\nproximo is looking for gladiators to earn himself money ( he being a former gladiator himself ) , and maximus reluctantly uses his skills to prove himself a powerful gladiator . \\nwhen emperor commodus announces that new games will be held in the colisseum , proximo takes his gladiators there to do battle . \\nmaximus sees this as his chance to exact revenge on commodus . \\ngladiator begins with a great battle sequence between the roman army and germania , and actually is able to maintain interest during the now required \" 40 minutes of exposition after a kick ass opening sequence \" style of moviemaking . \\nthe only downfall of the opening sequence is the editing style used . . . \\nit\\'s choppy slow-motion which is unsettling and distracting . \\nit\\'s similar to the opening sequence in saving private ryan , but nowhere near as effective . \\nthe actual gladiator battles are thrilling , but also a bit disjointed . \\nmany times it\\'s unclear as to exactly what\\'s going on . . . \\nall the audience can tell is that blood is being spilled . \\nwe\\'re not sure who\\'s blood or by who\\'s hand though . \\nthere\\'s an instance of this earlier in the film too that\\'s disappointing . \\nit\\'s comes when maximus escapes his executioners . \\nsome flashes and a few quick cuts later and maximus is free . . . \\nbut i still don\\'t know exactly how he did it . \\nrussell crowe should have become a major star after his gleefully over the top role as a computer generated serial killer in 1995\\'s virtuosity . \\nfor whatever reason his stardom never arrived . . . \\nbut he should have it now . \\nfrom here on moviegoers should now be able to say , \" let\\'s go see the new russell crowe movie \" . \\nhe gets the best scene in the film ( and one of the best moments of all recent movies ) when he reveals his identity to commodus in the colisseum . \\nit\\'s both rousing and chilling . \\njoaquin phoenix does a very effective job of making commodus a person and not just a cartoon character ( which could have easily happened ) . \\ncommodus is conniving , sneaky and whiny , but phoenix never lets the character get silly . \\nit\\'s a very good ( and very creepy ) performance . \\noliver reed died during the filming of gladiator , and it\\'s a huge loss to the acting world . \\ni\\'ve always been fascinated with reed . . . \\nhe\\'s one of those very talented performers who once had a fine career but ended up in direct to video junk during his twilight years . \\nit\\'s ironic that this film probably would have gotten him back into real movies again , as he gives a fun and sincere performance . \\nthe film is dedicated to him , and he will surely be missed . \\nreed\\'s death presented the filmmakers with an obvious problem , as he still had scenes to be completed . \\nrather than recast the role ( and end up reshooting a great deal of footage ) , a digital version of oliver reed was created at a reported cost of 2 million dollars . \\nironically , that was probably more money than reed ever earned for a single film . \\nanyway , this digital effect is only used in one scene that i am aware of ( for about twenty seconds ) and if you aren\\'t looking for it you won\\'t even be able to tell . \\nsome of the other digital effects are less convincing however . . . \\nand like i always say , noticable digital effects take me out of a movie immediately . \\nit\\'s sad that such a good film has these distractions . \\nmovies like the fall of the roman empire and spartacus seemed to do okay without the use of computer effects . \\nkeep in mind that gladiator is based on real people and real events , but is entirely a work of fiction . \\nhowever it\\'s a work of fiction that\\'s great entertainment , and another film to add to the list of damn fine flicks released in 2000 a . d . \\n',\n",
              "       'how many of us would become strippers ? \\nfor those of us who wouldn\\'t , is it a moral reason , or purely a lack of confidence ? \\nthat\\'s probably not a fair question , and for a lot of us , it could very well be for neither of those reasons . \\nas you watch the full monty , however , you may begin asking yourself these kinds of questions . \\nwould you be willing to grin and bare it to bring in some much needed dough ? \\nin case you haven\\'t guessed , the full monty is about stripping , but striptease it ain\\'t . \\nit\\'s actually quite a charming comedy that uses its ideas with a great deal of tact and sophistication . \\nit is the story of six out-of-work , out-of-shape blue collar brits whose recent job losses have left the boys penniless , but not without need . \\nwhat to do ? \\nit hits our main character gaz ( robert carlyle ) as he notices the large crowds of women who pour into a local male strip club on a regular basis . \\nit seems that simple : take it off and bring in the cash . \\neventually , gaz is able to convince his friends to join him in starting their own exotic dance routine despite their initial reluctance . \\nthese include the overweight , confidence-lacking dave ( mark addy ) , the uptight , overly-officious gerald ( tom wilkinson ) , the once suicidal lomper ( steve huison ) , and two additional fellows who gain their place among the group by audition : horse ( paul barber ) , an older gentlemen chock full of graceless energy , and guy ( hugo speer ) , a young well-endowed looker who compares himself to cary grant . \\nwhen the sextet is complete , we\\'re given a hefty dose of physical comedy . \\nwe watch the bumbling middle-aged men choreograph pseudo-sexy dance numbers , all the while proving why none of them were strippers in the first place . \\nas if there anti-appeal wasn\\'t enough , they decide to boost interest in the group by promising \" the full monty \" on opening night , which for us americans , means baring it all . \\n . \\n . \\nand i mean * all * . \\nthe movie actually ends on opening night ; a hilarious applause worthy ending i might add . \\nit\\'s sure to leave nothing short of a big smile on your face as you leave the theater . \\nwith the subject matter , you might not expect the fully monty to be such a feel-good , almost inspiring film , but it surprisingly turns out that way . \\nthe amount of light , touching drama also comes as a nice surprise , never feeling off-balance from the otherwise highly upbeat moments of the film . \\nthere\\'s a lot more to this movie than you might think in other words , and the ensemble cast couldn\\'t be better . \\neach character is completely individual , interesting , funny , and most importantly , real . \\nthe full monty is never offensive , a very impressive attribute since its subject matter alone could\\'ve easily fallen prey to tastelessness . \\nit\\'s one of those movies that is best described as a solid piece of entertainment , perfect for a great night on the town , or as a saturday night movie rental . \\neither way you see it , it shouldn\\'t let you down in the slightest . \\nand , pun heavily intended , when it\\'s all said and done , you\\'ll be smiling from cheek to cheek . \\n'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "xXCkmVlxsKo7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho1uGwLFfjm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e164aed3-995c-47d4-d714-4ad15648f5ee"
      },
      "source": [
        "# Usando el tokenizer de Keras\n",
        "tokenizer = Tokenizer(num_words=None)  # Puedes ajustar num_words si deseas limitar el tamaño del vocabulario\n",
        "\n",
        "# Ajustar el tokenizer a los textos de entrenamiento y validación\n",
        "tokenizer.fit_on_texts(list(xtrain) + list(xvalid))\n",
        "\n",
        "# Convertir los textos a secuencias de enteros\n",
        "xtrain_seq = tokenizer.texts_to_sequences(xtrain)\n",
        "xvalid_seq = tokenizer.texts_to_sequences(xvalid)\n",
        "xtest_seq = tokenizer.texts_to_sequences(xtest)\n",
        "\n",
        "# Aplicar padding a las secuencias\n",
        "xtrain_pad = pad_sequences(xtrain_seq, maxlen=max_len, padding='post')\n",
        "xvalid_pad = pad_sequences(xvalid_seq, maxlen=max_len, padding='post')\n",
        "xtest_pad = pad_sequences(xtest_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "# Obtener el índice de palabras del tokenizer\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Verificar los resultados\n",
        "print(f\"Tokenizador ajustado con {len(word_index)} palabras únicas.\")\n",
        "print(f\"Ejemplo de secuencia paddeada (xtrain_pad[0]): {xtrain_pad[0]}\")\n",
        "print(f\"Forma de xtrain_pad: {xtrain_pad.shape}\")\n",
        "print(f\"Forma de xvalid_pad: {xvalid_pad.shape}\")\n",
        "print(f\"Forma de xtest_pad: {xtest_pad.shape}\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizador ajustado con 39363 palabras únicas.\n",
            "Ejemplo de secuencia paddeada (xtrain_pad[0]): [3064 5759  471 ...    0    0    0]\n",
            "Forma de xtrain_pad: (1200, 2700)\n",
            "Forma de xvalid_pad: (400, 2700)\n",
            "Forma de xtest_pad: (400, 2700)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_pad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QIfNxgRo34F",
        "outputId": "80047501-50fa-4c99-ca7e-65936a1ff5f2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3064,  5759,   471, ...,     0,     0,     0],\n",
              "       [   44,    18,   339, ...,     0,     0,     0],\n",
              "       [ 1190,  5011,     6, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [   39,     2,  3809, ...,     0,     0,     0],\n",
              "       [ 3354,  3154, 13131, ...,     0,     0,     0],\n",
              "       [   98,   113,     4, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Convertir etiquetas de texto a enteros\n",
        "label_encoder = LabelEncoder()\n",
        "ytrain_encoded = label_encoder.fit_transform(ytrain)\n",
        "yvalid_encoded = label_encoder.transform(yvalid)\n",
        "ytest_encoded = label_encoder.transform(ytest)\n",
        "\n",
        "# Convertir los enteros a representación one-hot\n",
        "ytrain_one_hot = to_categorical(ytrain_encoded)\n",
        "yvalid_one_hot = to_categorical(yvalid_encoded)\n",
        "ytest_one_hot = to_categorical(ytest_encoded)\n",
        "\n",
        "# Verificar las formas de los arrays one-hot\n",
        "print(f\"Forma de ytrain_one_hot: {ytrain_one_hot.shape}\")\n",
        "print(f\"Forma de yvalid_one_hot: {yvalid_one_hot.shape}\")\n",
        "print(f\"Forma de ytest_one_hot: {ytest_one_hot.shape}\")\n",
        "\n",
        "# Opcional: Verificar los primeros ejemplos de etiquetas one-hot\n",
        "print(\"Ejemplo de etiquetas one-hot (ytrain_one_hot[0]):\")\n",
        "print(ytrain_one_hot[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgJPgPIxsphI",
        "outputId": "da9833ea-2dcd-4ad7-8d6f-c05e78af8574"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de ytrain_one_hot: (1200, 2)\n",
            "Forma de yvalid_one_hot: (400, 2)\n",
            "Forma de ytest_one_hot: (400, 2)\n",
            "Ejemplo de etiquetas one-hot (ytrain_one_hot[0]):\n",
            "[0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNxvBuDwhscW"
      },
      "source": [
        "En una RNN ingresamos una review palabra por palabra. Representamos cada palabra como un vector utilizando la técnica del one hot encoding. El vector va a tener cantidad de palabras en el vocabulario + 1 domensiones.\n",
        "\n",
        "Lo que hace keras Tokenizer es, toma todas las palabras únicas en el corpus, forma un diccionario con palabras como claves y su número de ocurrencias como valores (es el word_index), luego ordena el diccionario en orden descendente de conteos.\n",
        "\n",
        "Luego asigna a la primer palabra el valor 1, a la segunda el valor 2 y así sucesivamente.\n",
        "\n",
        "Así que supongamos que la palabra 'que' es la que se repite más en todas las canciones, a esa se le asignará el índice 1 y el vector que representa la palabra 'que' sería un vector one-hot con valor 1 en la posición 1 y resto ceros.\n",
        "\n",
        "La primera línea del modelo \"Sequential()\" le dice a Keras que construiremos nuestra red secuencialmente.\n",
        "\n",
        "Luego, primero agregamos la capa de incrustación. La capa de Embedding que es también una capa de neuronas que toma como entrada el vector one-hot n-ésimo de cada palabra y lo convierte en un vector de 300 dimensiones, nos da el enbeddubg de palabras similar a word2vec. Podríamos haber utilizado word2vec, pero la capa de Embedding aprende durante el entrenamiento para mejorar la forma de embeddear.\n",
        "\n",
        "A continuación, agregamos 100 unidades LSTM sin ningún dropout ni regularización.\n",
        "\n",
        "Por último, agregamos 5 neuronas (ya que tenemos 5 posibles clases) con función sigmoidea que toma la salida de las 100 células LSTM (tener en cuenta que tenemos 100 células LSTM, no capas) para predecir los resultados y luego compilamos el modelo usando adam optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd-FgV_L1xqr"
      },
      "source": [
        "# RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihmy2k5s1xYY",
        "outputId": "f67cfb4e-61ca-4bab-f6ed-0bc0e4a0aae0"
      },
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    # A simpleRNN without any pretrained embeddings and one dense layer\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1,#Cantidad de palabras distintas del corpus\n",
        "                     300,#tamaño del vector con el que va a encodear cada palabra (del 1-hot lo pasa a un vector de 300 dimensiones)\n",
        "                     input_length=max_len)) #El máximo de palabras que puede tener una review.\n",
        "    model.add(SimpleRNN(100))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(20, activation='relu'))\n",
        "    model.add(Dense(2, activation='sigmoid'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 2700, 300)         11829000  \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 100)               40100     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                1020      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 42        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11875212 (45.30 MB)\n",
            "Trainable params: 11875212 (45.30 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "CPU times: user 400 ms, sys: 200 ms, total: 600 ms\n",
            "Wall time: 990 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=64, validation_data=(xvalid_pad, yvalid_one_hot))\n",
        "\n",
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DLI2Ojovv1t",
        "outputId": "a763ca93-1f73-4e39-8400-1115dfb171c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 111s 6s/step - loss: 0.7034 - accuracy: 0.4900 - val_loss: 0.6932 - val_accuracy: 0.5400\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 96s 5s/step - loss: 0.7021 - accuracy: 0.4858 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 122s 6s/step - loss: 0.6953 - accuracy: 0.5292 - val_loss: 0.7042 - val_accuracy: 0.5075\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 103s 5s/step - loss: 0.7001 - accuracy: 0.4942 - val_loss: 0.7030 - val_accuracy: 0.4725\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 104s 6s/step - loss: 0.6977 - accuracy: 0.4858 - val_loss: 0.7011 - val_accuracy: 0.5050\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 104s 5s/step - loss: 0.7002 - accuracy: 0.4908 - val_loss: 0.6988 - val_accuracy: 0.4700\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 107s 6s/step - loss: 0.7018 - accuracy: 0.4858 - val_loss: 0.6940 - val_accuracy: 0.5125\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 107s 6s/step - loss: 0.7047 - accuracy: 0.4883 - val_loss: 0.6886 - val_accuracy: 0.5300\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 100s 5s/step - loss: 0.7000 - accuracy: 0.5025 - val_loss: 0.7064 - val_accuracy: 0.4900\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 103s 5s/step - loss: 0.7016 - accuracy: 0.4850 - val_loss: 0.6944 - val_accuracy: 0.4800\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 104s 5s/step - loss: 0.6970 - accuracy: 0.4942 - val_loss: 0.6872 - val_accuracy: 0.5625\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 106s 6s/step - loss: 0.6977 - accuracy: 0.4908 - val_loss: 0.6966 - val_accuracy: 0.4825\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 110s 6s/step - loss: 0.6968 - accuracy: 0.5058 - val_loss: 0.6968 - val_accuracy: 0.4875\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 98s 5s/step - loss: 0.6963 - accuracy: 0.5042 - val_loss: 0.6944 - val_accuracy: 0.5325\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 98s 5s/step - loss: 0.6979 - accuracy: 0.4933 - val_loss: 0.6919 - val_accuracy: 0.5225\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 100s 5s/step - loss: 0.6978 - accuracy: 0.5042 - val_loss: 0.6972 - val_accuracy: 0.4850\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 101s 5s/step - loss: 0.6987 - accuracy: 0.4925 - val_loss: 0.7011 - val_accuracy: 0.4650\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 94s 5s/step - loss: 0.6941 - accuracy: 0.5233 - val_loss: 0.6933 - val_accuracy: 0.5075\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 101s 5s/step - loss: 0.6964 - accuracy: 0.4825 - val_loss: 0.6991 - val_accuracy: 0.5100\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 98s 5s/step - loss: 0.6996 - accuracy: 0.4842 - val_loss: 0.6950 - val_accuracy: 0.4900\n",
            "13/13 [==============================] - 7s 537ms/step\n",
            "Accuracy: 0.49\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.49      0.69      0.57       200\n",
            "    positive       0.48      0.29      0.37       200\n",
            "\n",
            "    accuracy                           0.49       400\n",
            "   macro avg       0.49      0.49      0.47       400\n",
            "weighted avg       0.49      0.49      0.47       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8XfnnlZXyP7f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uViGkPDPpP8"
      },
      "source": [
        "# Convolutional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Crear el modelo CNN\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1, 300, input_length=max_len))\n",
        "model.add(Conv1D(128, 5, activation=\"relu\"))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Conv1D(128, 5, activation=\"relu\"))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Conv1D(128, 5, activation=\"relu\"))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))  # Ajustar el número de unidades a 2\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=64, validation_data=(xvalid_pad, yvalid_one_hot))\n",
        "\n",
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDhAosPp9NpT",
        "outputId": "f31eae06-86e8-4086-f9ba-7dd1be2140bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 2700, 300)         11829000  \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 2696, 128)         192128    \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 539, 128)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 535, 128)          82048     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 107, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 103, 128)          82048     \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 128)               0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12201994 (46.55 MB)\n",
            "Trainable params: 12201994 (46.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "19/19 [==============================] - 144s 7s/step - loss: 0.7006 - accuracy: 0.5000 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 138s 7s/step - loss: 0.6952 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 128s 7s/step - loss: 0.6919 - accuracy: 0.5142 - val_loss: 0.6929 - val_accuracy: 0.5250\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 118s 6s/step - loss: 0.6849 - accuracy: 0.6125 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 121s 6s/step - loss: 0.6458 - accuracy: 0.7342 - val_loss: 0.6707 - val_accuracy: 0.5100\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 129s 7s/step - loss: 0.4074 - accuracy: 0.8817 - val_loss: 0.5448 - val_accuracy: 0.7225\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 123s 7s/step - loss: 0.0467 - accuracy: 0.9925 - val_loss: 0.5697 - val_accuracy: 0.7875\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 120s 6s/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 0.8476 - val_accuracy: 0.7350\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 132s 7s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8171 - val_accuracy: 0.7700\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 130s 7s/step - loss: 5.9710e-04 - accuracy: 1.0000 - val_loss: 0.7309 - val_accuracy: 0.7900\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 130s 7s/step - loss: 3.2745e-04 - accuracy: 1.0000 - val_loss: 0.7632 - val_accuracy: 0.7925\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 119s 6s/step - loss: 2.2997e-04 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.7875\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 129s 7s/step - loss: 5.1060e-04 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.7775\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 119s 6s/step - loss: 1.6603e-04 - accuracy: 1.0000 - val_loss: 0.8294 - val_accuracy: 0.7750\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 128s 7s/step - loss: 1.9484e-04 - accuracy: 1.0000 - val_loss: 0.8569 - val_accuracy: 0.7725\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 128s 7s/step - loss: 1.0792e-04 - accuracy: 1.0000 - val_loss: 0.8716 - val_accuracy: 0.7750\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 119s 6s/step - loss: 6.7888e-05 - accuracy: 1.0000 - val_loss: 0.8701 - val_accuracy: 0.7750\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 130s 7s/step - loss: 5.9871e-05 - accuracy: 1.0000 - val_loss: 0.8787 - val_accuracy: 0.7750\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 119s 6s/step - loss: 1.7953e-04 - accuracy: 1.0000 - val_loss: 0.8754 - val_accuracy: 0.7775\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 129s 7s/step - loss: 8.9998e-05 - accuracy: 1.0000 - val_loss: 0.8722 - val_accuracy: 0.7800\n",
            "13/13 [==============================] - 10s 765ms/step\n",
            "Accuracy: 0.78\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.77      0.78       200\n",
            "    positive       0.77      0.79      0.78       200\n",
            "\n",
            "    accuracy                           0.78       400\n",
            "   macro avg       0.78      0.78      0.78       400\n",
            "weighted avg       0.78      0.78      0.78       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/drive/MyDrive/pretrainedwordvectorsforspanish/cc.es.300.vec.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvptzE9BoBhv",
        "outputId": "251e9b5a-7da0-42c2-f5b2-a4f054673c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-02 22:44:54--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.156.133.37, 108.156.133.4, 108.156.133.117, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.156.133.37|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1285580896 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘/content/drive/MyDrive/pretrainedwordvectorsforspanish/cc.es.300.vec.gz’\n",
            "\n",
            "/content/drive/MyDr 100%[===================>]   1.20G  23.7MB/s    in 53s     \n",
            "\n",
            "2024-07-02 22:45:48 (23.0 MB/s) - ‘/content/drive/MyDrive/pretrainedwordvectorsforspanish/cc.es.300.vec.gz’ saved [1285580896/1285580896]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 1: Descargar Embeddings de GloVe en Inglés"
      ],
      "metadata": {
        "id": "5MlHg-DhoUDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip -P /content/\n",
        "!unzip /content/glove.6B.zip -d /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64UGE_1joRj3",
        "outputId": "5fa681a0-3b93-4d11-af8f-b954240ae98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-04 11:29:05--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-07-04 11:29:06--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-07-04 11:29:06--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘/content/glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2024-07-04 11:31:46 (5.18 MB/s) - ‘/content/glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  /content/glove.6B.zip\n",
            "  inflating: /content/glove.6B.50d.txt  \n",
            "  inflating: /content/glove.6B.100d.txt  \n",
            "  inflating: /content/glove.6B.200d.txt  \n",
            "  inflating: /content/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Ruta al archivo de embeddings de GloVe\n",
        "glove_file = '/content/glove.6B.300d.txt'\n",
        "\n",
        "# Verificar si el archivo existe en la ruta especificada\n",
        "if os.path.exists(glove_file):\n",
        "    print(\"El archivo se ha encontrado correctamente.\")\n",
        "\n",
        "    # Cargar los embeddings de GloVe\n",
        "    def cargar_embeddings(file_path):\n",
        "        embeddings_index = {}\n",
        "        with open(file_path, encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                values = line.split()\n",
        "                word = values[0]\n",
        "                coefs = np.asarray(values[1:], dtype='float32')\n",
        "                embeddings_index[word] = coefs\n",
        "        return embeddings_index\n",
        "\n",
        "    wordvectors = cargar_embeddings(glove_file)  # Definimos wordvectors aquí\n",
        "    print(\"Embeddings de GloVe cargados exitosamente.\")\n",
        "else:\n",
        "    print(\"El archivo no se encuentra en la ruta especificada.\")\n",
        "\n",
        "# Crear una matriz de embeddings\n",
        "embedding_dim = 300\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = wordvectors.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25), embedding_dim)\n",
        "\n",
        "print(\"Matriz de embeddings creada exitosamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqIOW8YRimY5",
        "outputId": "95bf345c-b238-4389-e1f7-573bd907cdae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El archivo se ha encontrado correctamente.\n",
            "Embeddings de GloVe cargados exitosamente.\n",
            "Matriz de embeddings creada exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"movie\"\n",
        "if word in wordvectors:\n",
        "    vector = wordvectors[word]\n",
        "    print(f\"Vector for '{word}': {vector}\")\n",
        "else:\n",
        "    print(f\"'{word}' not found in word vectors\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7VJQtUPjDbw",
        "outputId": "f7eb183b-d854-47d1-e5ad-b1194721bb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'movie': [-0.138     -0.12203    0.0054643 -0.010215   0.13134    0.28616\n",
            " -0.36436   -0.035735  -0.17218   -0.38864    0.58637    0.13189\n",
            " -0.1513     0.35515   -0.34298   -0.54394   -0.40302   -0.17129\n",
            "  0.19899    0.24317    0.21332    0.60335    0.22556    0.46382\n",
            "  0.064101   0.36409    0.25328   -0.79771    0.26771    0.42462\n",
            " -0.62075    0.31208   -0.25316    0.13562   -1.1323     0.0099104\n",
            " -0.62471   -0.048047   0.23139    0.16102    0.24774   -0.26149\n",
            " -0.17341    0.34005    0.21511   -0.26714    0.45698   -0.13671\n",
            "  0.11654   -0.12222    0.062068  -0.45585   -0.30115    0.11208\n",
            "  0.31146   -0.048065   0.10067    0.1441     0.27139   -0.17809\n",
            " -0.41069    0.093994   0.499      0.023845   0.42438   -0.027703\n",
            "  0.044485  -0.15928    0.45054    0.13142    0.19913    0.36483\n",
            "  0.26074    0.55475    0.47258   -0.43104    0.23181   -0.177\n",
            "  0.21771   -0.37325   -0.15304   -0.45237    0.68007   -0.15976\n",
            " -0.094521   0.6455     0.10443   -0.19616    0.027374  -0.24713\n",
            " -0.24108    0.24404   -0.0066751 -0.055555  -0.13255    0.28159\n",
            "  0.10104    0.26669   -0.20363   -1.2499     0.17955    0.16492\n",
            "  0.29046    0.078206   0.36391    0.1972    -0.38922   -0.08842\n",
            "  0.36837   -0.46351   -0.05688    0.23692    0.25946   -0.0092949\n",
            "  0.55123    0.18405   -0.070915  -0.12583   -0.33538   -0.6216\n",
            "  0.10658   -0.04339    0.054995   0.46283    0.088233   0.051282\n",
            "  0.30242    0.045697  -0.30009    0.086718  -0.075517   0.10886\n",
            " -0.018905   0.11489    0.30604   -0.014883  -0.20549   -0.11995\n",
            " -0.57362    0.71357   -0.0056715 -0.11205   -0.32318   -0.058222\n",
            " -0.36446   -0.68901    0.07647   -0.027654  -0.080254  -0.22787\n",
            "  0.35799   -0.21695   -0.20211   -0.23662    0.58239    0.12348\n",
            "  0.053221   0.21873   -0.11821    0.11212    0.79703   -0.30937\n",
            "  0.2063    -0.17314    0.01498    0.76045    0.075878   0.047252\n",
            " -0.35795    0.30923   -0.082989  -0.30638   -1.6971     0.055546\n",
            "  0.089201   0.38312   -0.33247   -0.13426   -0.049802  -0.41536\n",
            " -0.13256   -0.066477  -0.18845    0.17874    0.19334   -0.22544\n",
            "  0.023197  -0.3343     0.21699   -0.16357   -0.3338    -0.15258\n",
            " -0.27453   -0.2123    -0.38512   -0.39829   -0.7472     0.19218\n",
            " -0.15262   -0.26095    1.9506    -0.30508    0.11658    0.01811\n",
            "  0.3887     0.02532   -0.073168   0.08531   -0.26947   -0.4158\n",
            " -0.5256    -0.3618     0.1364     0.14176    0.080273   0.31376\n",
            "  0.12755    0.1358     0.25489    0.33135   -0.75425   -0.10576\n",
            "  0.036561  -0.15502   -0.41141   -0.1202     0.27146   -0.44042\n",
            " -0.2921    -0.11905    0.62502   -0.27724   -0.59458   -0.31237\n",
            "  0.30283    0.28397    0.75238   -0.12298   -0.32536    0.12182\n",
            "  0.40979    0.15839   -0.26725   -0.21228   -0.51142   -0.34827\n",
            " -0.42788   -0.10433   -0.58671    0.26117   -0.021263  -0.16688\n",
            " -0.42097    1.0059     0.23808   -0.80147    0.3903    -0.34794\n",
            "  0.54537   -0.14279    0.17518   -0.083995   0.13864   -0.36321\n",
            "  0.44686   -0.18776    0.17833   -0.19966    0.53591    0.57662\n",
            "  0.54154   -0.10555   -0.27472    0.11733    0.22361    0.32645\n",
            " -1.6279    -0.14297   -0.010648  -0.62519   -0.037267  -0.35863\n",
            "  0.023786  -0.059398  -0.10813    0.59328   -0.11333   -0.1525\n",
            " -0.14136    0.67566    0.11331    0.15394   -0.3226     0.017754\n",
            " -0.97518    0.021112  -0.15476    0.19934    0.057473  -0.023767 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame para visualizar la matriz de embeddings\n",
        "# Seleccionar las primeras 10 filas para visualizar\n",
        "embedding_df = pd.DataFrame(embedding_matrix[:10], columns=[f\"dim_{i}\" for i in range(embedding_dim)])\n",
        "print(embedding_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p73uTho5pg3I",
        "outputId": "edf7057a-2024-4cfc-f134-210076708579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      dim_0     dim_1     dim_2    dim_3     dim_4     dim_5     dim_6  \\\n",
            "0  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
            "1  0.046560  0.213180 -0.007436 -0.45854 -0.035639  0.236430 -0.288360   \n",
            "2 -0.297120  0.094049 -0.096662 -0.34400 -0.184830 -0.123290 -0.116560   \n",
            "3  0.038466 -0.039792  0.082747 -0.38923 -0.214310  0.170200 -0.025657   \n",
            "4 -0.076947 -0.021211  0.212710 -0.72232 -0.139880 -0.122340 -0.175210   \n",
            "5 -0.257560 -0.057132 -0.671900 -0.38082 -0.364210 -0.082155 -0.010955   \n",
            "6 -0.174900  0.229560  0.249240 -0.20512 -0.122940  0.021297 -0.238150   \n",
            "7 -0.443990  0.128170 -0.252470 -0.18582 -0.166140  0.259090 -0.226780   \n",
            "8 -0.182560  0.498510 -0.163900 -0.17443 -0.163820 -0.044109  0.279570   \n",
            "9  0.033284 -0.040754 -0.048377  0.12017 -0.139150 -0.176940 -0.062908   \n",
            "\n",
            "      dim_7     dim_8   dim_9  ...   dim_290   dim_291   dim_292   dim_293  \\\n",
            "0  0.000000  0.000000  0.0000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "1  0.215210 -0.134860 -1.6413  ... -0.013064 -0.296860 -0.079913  0.195000   \n",
            "2 -0.099692  0.172650 -1.6386  ...  0.075972 -0.424260 -0.396700  0.326830   \n",
            "3  0.095780  0.238600 -1.6342  ...  0.045194 -0.204050 -0.210970 -0.110250   \n",
            "4  0.121370 -0.070866 -1.5721  ... -0.366730 -0.386030  0.302900  0.015747   \n",
            "5 -0.082047  0.460560 -1.8477  ... -0.012806 -0.597070  0.317340 -0.252670   \n",
            "6  0.137370 -0.089130 -2.0607  ...  0.313570 -0.134070  0.184650  0.234260   \n",
            "7 -0.069229 -0.077204 -1.5814  ... -0.274500 -0.037237  0.101040  0.107980   \n",
            "8  0.066851  0.122980 -2.4794  ... -0.082465 -0.232410  0.022031  0.354450   \n",
            "9  0.170560  0.200770 -2.4287  ...  0.091222 -0.402000  0.154300  0.230990   \n",
            "\n",
            "    dim_294   dim_295   dim_296   dim_297   dim_298   dim_299  \n",
            "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "1  0.031549  0.285060 -0.087461  0.009061 -0.209890  0.053913  \n",
            "2  0.620490  0.347190  0.269520  0.059717 -0.228530  0.296020  \n",
            "3  0.021766  0.441290  0.327970 -0.334270  0.011807  0.059703  \n",
            "4  0.340360  0.478410  0.068617  0.183510 -0.291830 -0.046533  \n",
            "5  0.543840  0.063007 -0.049795 -0.160430  0.046744 -0.070621  \n",
            "6  0.076272  0.105020  0.215210 -0.241310 -0.404020  0.054744  \n",
            "7  0.377270  0.879770  0.335830 -0.200430 -0.082191 -0.062550  \n",
            "8  0.172210  0.018176  0.038145 -0.272240 -0.191070 -0.094104  \n",
            "9  0.086138 -0.002428  0.065196 -0.154080  0.178060 -0.196830  \n",
            "\n",
            "[10 rows x 300 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame para visualizar la matriz de embeddings\n",
        "# Seleccionar las primeras 10 palabras para visualizar\n",
        "palabras = list(word_index.keys())[:10]\n",
        "vectores = embedding_matrix[:10]\n",
        "\n",
        "# Crear un DataFrame\n",
        "embedding_df = pd.DataFrame(vectores, index=palabras, columns=[f\"dim_{i}\" for i in range(embedding_dim)])\n",
        "print(embedding_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MixXJeOZhnd9",
        "outputId": "59eaf85a-2e78-4c36-94ed-736584e848cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         dim_0     dim_1     dim_2    dim_3     dim_4     dim_5     dim_6  \\\n",
            "the   0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
            "a     0.046560  0.213180 -0.007436 -0.45854 -0.035639  0.236430 -0.288360   \n",
            "and  -0.297120  0.094049 -0.096662 -0.34400 -0.184830 -0.123290 -0.116560   \n",
            "of    0.038466 -0.039792  0.082747 -0.38923 -0.214310  0.170200 -0.025657   \n",
            "to   -0.076947 -0.021211  0.212710 -0.72232 -0.139880 -0.122340 -0.175210   \n",
            "is   -0.257560 -0.057132 -0.671900 -0.38082 -0.364210 -0.082155 -0.010955   \n",
            "in   -0.174900  0.229560  0.249240 -0.20512 -0.122940  0.021297 -0.238150   \n",
            "that -0.443990  0.128170 -0.252470 -0.18582 -0.166140  0.259090 -0.226780   \n",
            "it   -0.182560  0.498510 -0.163900 -0.17443 -0.163820 -0.044109  0.279570   \n",
            "as    0.033284 -0.040754 -0.048377  0.12017 -0.139150 -0.176940 -0.062908   \n",
            "\n",
            "         dim_7     dim_8   dim_9  ...   dim_290   dim_291   dim_292   dim_293  \\\n",
            "the   0.000000  0.000000  0.0000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "a     0.215210 -0.134860 -1.6413  ... -0.013064 -0.296860 -0.079913  0.195000   \n",
            "and  -0.099692  0.172650 -1.6386  ...  0.075972 -0.424260 -0.396700  0.326830   \n",
            "of    0.095780  0.238600 -1.6342  ...  0.045194 -0.204050 -0.210970 -0.110250   \n",
            "to    0.121370 -0.070866 -1.5721  ... -0.366730 -0.386030  0.302900  0.015747   \n",
            "is   -0.082047  0.460560 -1.8477  ... -0.012806 -0.597070  0.317340 -0.252670   \n",
            "in    0.137370 -0.089130 -2.0607  ...  0.313570 -0.134070  0.184650  0.234260   \n",
            "that -0.069229 -0.077204 -1.5814  ... -0.274500 -0.037237  0.101040  0.107980   \n",
            "it    0.066851  0.122980 -2.4794  ... -0.082465 -0.232410  0.022031  0.354450   \n",
            "as    0.170560  0.200770 -2.4287  ...  0.091222 -0.402000  0.154300  0.230990   \n",
            "\n",
            "       dim_294   dim_295   dim_296   dim_297   dim_298   dim_299  \n",
            "the   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "a     0.031549  0.285060 -0.087461  0.009061 -0.209890  0.053913  \n",
            "and   0.620490  0.347190  0.269520  0.059717 -0.228530  0.296020  \n",
            "of    0.021766  0.441290  0.327970 -0.334270  0.011807  0.059703  \n",
            "to    0.340360  0.478410  0.068617  0.183510 -0.291830 -0.046533  \n",
            "is    0.543840  0.063007 -0.049795 -0.160430  0.046744 -0.070621  \n",
            "in    0.076272  0.105020  0.215210 -0.241310 -0.404020  0.054744  \n",
            "that  0.377270  0.879770  0.335830 -0.200430 -0.082191 -0.062550  \n",
            "it    0.172210  0.018176  0.038145 -0.272240 -0.191070 -0.094104  \n",
            "as    0.086138 -0.002428  0.065196 -0.154080  0.178060 -0.196830  \n",
            "\n",
            "[10 rows x 300 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representar_review_como_vector(review):\n",
        "    palabras = review.split()\n",
        "    vectores = np.zeros(300)  # Suponiendo que los embeddings tienen 300 dimensiones\n",
        "    palabras_encontradas = 0\n",
        "    for palabra in palabras:\n",
        "        try:\n",
        "            vector = wordvectors[palabra]\n",
        "            vectores = vectores + vector\n",
        "            palabras_encontradas = palabras_encontradas + 1\n",
        "        except KeyError:\n",
        "            print(\"No está la palabra \" + palabra)\n",
        "\n",
        "    if palabras_encontradas > 0:\n",
        "        promedio = vectores / palabras_encontradas\n",
        "    else:\n",
        "        promedio = vectores\n",
        "    return vectores, promedio\n"
      ],
      "metadata": {
        "id": "NKbZGSFAjRYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"The movie was fantastic with great performances\"\n",
        "suma_vectores, promedio_vector = representar_review_como_vector(review)\n",
        "\n",
        "print(\"Suma de vectores:\", suma_vectores)\n",
        "print(\"Promedio de vector:\", promedio_vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urijd9adh9oD",
        "outputId": "f3d01f5a-0576-4e26-db37-87c076278707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No está la palabra The\n",
            "Suma de vectores: [ 0.40194301  0.27216901  0.25342232 -1.239327    0.42250501  0.77834221\n",
            " -0.89730999 -0.09869419 -0.47823    -6.27481988  1.74771097  0.33666203\n",
            " -1.21395398  1.73060001 -0.87205403 -0.28724001 -0.671101    0.55715703\n",
            " -0.203493    0.51512298  0.07460097  1.34675997 -0.314656    1.5147994\n",
            "  0.234901    0.711936   -0.33728396 -1.50191233  0.91382099  1.02284802\n",
            " -0.57832701  0.45908001 -2.06607398  0.29664103 -6.47114003 -0.18947361\n",
            " -0.69258002  1.90620304  0.79380701  0.29453272 -0.73650301 -1.815127\n",
            " -0.50513499  0.32695003  1.19733     1.89346004  1.51674299  1.39860998\n",
            "  0.424275    0.05463     0.71797101 -0.964288   -0.85394699  0.07967199\n",
            "  0.10442099  1.65419494  0.45152101  1.69516997  2.07254399 -0.08804101\n",
            "  0.12355602 -0.11186601  1.61630002 -0.62362401  0.28783797 -0.66621302\n",
            "  0.72669702 -0.60223998  0.33667501  0.08499102 -0.53619501  0.02752199\n",
            " -0.13570798  0.86813002 -0.52545512 -0.67260298  0.98725199  0.81894898\n",
            "  0.15235002  0.098774   -0.68254599  0.03923202  2.25511996 -0.16955498\n",
            "  0.877849    1.98650002  0.78143102  0.04902697  1.45970819 -0.60615002\n",
            "  0.139767    0.33857399 -0.42907109 -0.25998701  0.15557101 -0.39383999\n",
            "  0.62944245 -0.62342303 -0.46362699 -2.598897   -0.34405078  0.6831638\n",
            " -0.21881902 -0.99869198  0.481019    0.34122699 -0.312448    0.86754096\n",
            " -0.66449601 -0.69265101  0.200502    0.09015202  0.90539201 -0.44293091\n",
            "  1.53369802 -1.00941401 -0.88411202  0.40522601  0.03792    -2.56117997\n",
            " -0.49163001 -0.22740262 -0.02479099  0.53831099  0.42749001 -0.77842801\n",
            " -0.39961202  0.98205697 -1.67093001  1.33309792 -0.36633011  1.166308\n",
            " -0.0248463  -0.50577102 -0.80994    -0.654117   -0.65117051 -0.31050999\n",
            " -0.72997102  3.27642992 -0.9525375  -0.25158699 -0.26714299 -0.44234799\n",
            " -0.02769999 -0.94269001  1.18497403 -0.48305401 -1.56465305 -1.347658\n",
            "  0.76842003 -0.76581399 -0.641954   -1.12052001  1.46954344  0.12904101\n",
            "  0.011334    1.09127341 -0.204604   -0.61592062  1.50043196 -1.48422803\n",
            "  0.39660798  0.1099423  -0.46003597  1.41398998 -0.95286099  1.07283199\n",
            "  0.97881204  0.96673601  1.48759101 -1.1538036  -5.05787012 -0.13238398\n",
            "  0.7741347   0.62606002 -1.66019998 -1.12751401 -0.258233    0.52496999\n",
            "  0.40350304  0.437559    1.43436597  0.32731299  0.50613002 -1.18618771\n",
            " -0.986828   -0.86322811 -0.55285498  0.53480099 -1.542165   -0.10661799\n",
            " -0.207314   -0.42556302 -1.18744001 -1.54081599 -1.885886    0.07237298\n",
            " -0.45552026 -1.13640232  8.08319998 -0.25120801 -0.180024   -0.24510801\n",
            "  0.95931999  0.93801001  0.16526598  1.94992998 -0.74561401 -2.19925699\n",
            " -1.5538946  -0.45945199  0.27103996 -1.60252198  0.79410801  0.65101201\n",
            " -0.08182998 -0.38772398  0.652364    0.67415002  0.05673698 -1.36486898\n",
            " -0.71324899 -0.83237513 -1.23870499  0.19611     0.96511599 -1.78706101\n",
            " -0.86925903  0.08936999 -0.44091799 -0.93989699 -0.70388001 -3.03719003\n",
            "  1.21632898  1.52174     0.51449301  0.12120603 -0.72049099  1.51802799\n",
            " -0.10211198  0.65644797 -0.07785998  2.15741    -3.37817001 -0.4928944\n",
            " -1.03200896  0.42496    -0.24630097  0.27611301  1.35608699 -1.51395131\n",
            " -1.03801602  0.96872502  2.38197903 -0.68751547  0.07566499 -1.73892101\n",
            "  0.80519298  0.58030398  0.28464001 -0.51856232  1.10458501  0.59330899\n",
            " -0.44880902  0.04030501 -1.00165001 -1.21248088  1.12997441 -0.15311303\n",
            "  0.89251106 -1.327129    0.192971    1.01902001  1.98504903  0.87520896\n",
            " -8.26752007 -0.19485     1.06985699 -0.16336602 -1.609587    0.805539\n",
            "  0.64798999  0.94270898  0.94352401  1.66223301 -2.30040003  0.66998401\n",
            " -0.50079999 -0.50369996  0.140137   -0.82546897 -1.89685996  0.17052403\n",
            " -0.75538098  0.17881802  0.23681059 -0.18867    -0.2517583  -0.881048  ]\n",
            "Promedio de vector: [ 0.0669905   0.0453615   0.04223705 -0.2065545   0.0704175   0.1297237\n",
            " -0.14955166 -0.01644903 -0.079705   -1.04580331  0.29128516  0.05611034\n",
            " -0.20232566  0.28843333 -0.14534234 -0.04787334 -0.11185017  0.0928595\n",
            " -0.0339155   0.08585383  0.0124335   0.22445999 -0.05244267  0.25246657\n",
            "  0.03915017  0.118656   -0.05621399 -0.25031872  0.1523035   0.17047467\n",
            " -0.09638784  0.07651334 -0.34434566  0.04944017 -1.07852334 -0.03157894\n",
            " -0.11543     0.31770051  0.13230117  0.04908879 -0.1227505  -0.30252117\n",
            " -0.08418916  0.05449167  0.199555    0.31557667  0.2527905   0.23310166\n",
            "  0.0707125   0.009105    0.11966184 -0.16071467 -0.1423245   0.01327867\n",
            "  0.0174035   0.27569916  0.0752535   0.28252833  0.345424   -0.0146735\n",
            "  0.02059267 -0.01864434  0.26938334 -0.10393733  0.047973   -0.1110355\n",
            "  0.12111617 -0.10037333  0.0561125   0.01416517 -0.08936583  0.004587\n",
            " -0.022618    0.14468834 -0.08757585 -0.1121005   0.164542    0.1364915\n",
            "  0.02539167  0.01646233 -0.11375766  0.00653867  0.37585333 -0.02825916\n",
            "  0.14630817  0.33108334  0.1302385   0.00817116  0.2432847  -0.101025\n",
            "  0.0232945   0.056429   -0.07151185 -0.04333117  0.0259285  -0.06564\n",
            "  0.10490708 -0.10390384 -0.07727116 -0.4331495  -0.0573418   0.11386063\n",
            " -0.03646984 -0.16644866  0.08016983  0.05687117 -0.05207467  0.14459016\n",
            " -0.11074934 -0.11544184  0.033417    0.01502534  0.15089867 -0.07382182\n",
            "  0.25561634 -0.16823567 -0.147352    0.06753767  0.00632    -0.42686333\n",
            " -0.08193834 -0.03790044 -0.00413183  0.0897185   0.07124834 -0.129738\n",
            " -0.066602    0.16367616 -0.27848834  0.22218299 -0.06105502  0.19438467\n",
            " -0.00414105 -0.08429517 -0.13499    -0.1090195  -0.10852842 -0.05175167\n",
            " -0.12166184  0.54607165 -0.15875625 -0.04193116 -0.04452383 -0.07372467\n",
            " -0.00461667 -0.157115    0.19749567 -0.080509   -0.26077551 -0.22460967\n",
            "  0.12807    -0.12763567 -0.10699233 -0.18675334  0.24492391  0.02150683\n",
            "  0.001889    0.1818789  -0.03410067 -0.10265344  0.25007199 -0.24737134\n",
            "  0.06610133  0.01832372 -0.07667266  0.235665   -0.15881016  0.17880533\n",
            "  0.16313534  0.16112267  0.24793183 -0.1923006  -0.84297835 -0.022064\n",
            "  0.12902245  0.10434334 -0.2767     -0.187919   -0.04303883  0.087495\n",
            "  0.06725051  0.0729265   0.23906099  0.05455217  0.084355   -0.19769795\n",
            " -0.16447133 -0.14387135 -0.0921425   0.0891335  -0.2570275  -0.01776966\n",
            " -0.03455233 -0.07092717 -0.19790667 -0.25680267 -0.31431433  0.01206216\n",
            " -0.07592004 -0.18940039  1.3472     -0.041868   -0.030004   -0.04085134\n",
            "  0.15988667  0.156335    0.02754433  0.32498833 -0.124269   -0.36654283\n",
            " -0.25898243 -0.07657533  0.04517333 -0.267087    0.13235133  0.108502\n",
            " -0.01363833 -0.06462066  0.10872733  0.11235834  0.00945616 -0.22747816\n",
            " -0.11887483 -0.13872919 -0.20645083  0.032685    0.16085266 -0.2978435\n",
            " -0.1448765   0.014895   -0.07348633 -0.1566495  -0.11731334 -0.50619834\n",
            "  0.2027215   0.25362333  0.08574884  0.02020101 -0.12008183  0.25300466\n",
            " -0.01701866  0.10940799 -0.01297666  0.35956833 -0.56302834 -0.08214907\n",
            " -0.17200149  0.07082667 -0.04105016  0.04601884  0.2260145  -0.25232522\n",
            " -0.17300267  0.16145417  0.3969965  -0.11458591  0.01261083 -0.28982017\n",
            "  0.13419883  0.09671733  0.04744    -0.08642705  0.1840975   0.09888483\n",
            " -0.0748015   0.0067175  -0.16694167 -0.20208015  0.18832907 -0.02551884\n",
            "  0.14875184 -0.22118817  0.03216183  0.16983667  0.3308415   0.14586816\n",
            " -1.37792001 -0.032475    0.1783095  -0.02722767 -0.2682645   0.1342565\n",
            "  0.10799833  0.15711816  0.157254    0.27703883 -0.3834      0.111664\n",
            " -0.08346667 -0.08394999  0.02335617 -0.13757816 -0.31614333  0.02842067\n",
            " -0.12589683  0.029803    0.03946843 -0.031445   -0.04195972 -0.14684133]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar una review específica para probar\n",
        "review_ejemplo = train_df[train_df['review'].str.contains('the only problem')]['review'].values[0]\n",
        "\n",
        "# Obtener los vectores suma y promedio de la review\n",
        "suma, promedio = representar_review_como_vector(review_ejemplo)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlP7h51JoELd",
        "outputId": "bcc49392-1a30-4ce1-8c00-1f54f17bdfd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No está la palabra closed-down\n",
            "No está la palabra don't\n",
            "No está la palabra couldn't\n",
            "No está la palabra killer's\n",
            "No está la palabra identital\n",
            "No está la palabra you'll\n",
            "No está la palabra suspeneful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIEZW-TTqs8V"
      },
      "source": [
        "## **Implementamos Doc2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPeCReMEo0IW",
        "outputId": "573d1cbf-7ed2-412a-fc36-685c12bf7ba9"
      },
      "source": [
        "\n",
        "problem = train_df[train_df['review'].str.contains('the only problem')]['review'].values[0]\n",
        "suma, promedio = representar_review_como_vector(problem)\n",
        "print(suma)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No está la palabra closed-down\n",
            "No está la palabra don't\n",
            "No está la palabra couldn't\n",
            "No está la palabra killer's\n",
            "No está la palabra identital\n",
            "No está la palabra you'll\n",
            "No está la palabra suspeneful\n",
            "[-4.59138169e+01  4.61852148e+01 -1.83477440e+00 -6.36723800e+01\n",
            " -1.25150736e+01  1.23591820e+01 -5.13842206e+01  2.69998580e+01\n",
            "  3.30345372e+01 -6.88852463e+02  8.27908245e+01  1.32319507e+01\n",
            " -3.51826081e+01  6.33438807e+01  4.42306485e+01  2.23102066e+01\n",
            " -1.01584576e+02 -4.41097325e+00  1.34701597e+01 -3.19089915e+01\n",
            "  9.94443619e-02  1.11540788e+02  8.03917519e+01  6.47379369e+01\n",
            " -8.04723655e+01  9.81717463e+00  3.01084539e+01 -6.09712993e+01\n",
            " -3.40426375e+01  4.76380967e+01 -3.58202230e+00  1.12309295e+02\n",
            " -8.40496673e+01  3.88052887e+01 -3.69947138e+02  2.08287777e+01\n",
            " -1.40937854e+01  3.79515735e+01 -4.07133025e+01  2.47540927e+01\n",
            "  2.40702482e+01 -6.90864819e+01 -3.76756686e+01  5.88299646e+01\n",
            "  3.66336603e+01  3.82451890e+01  6.87086589e+01  6.32599449e+01\n",
            " -3.60890346e+01  2.20133940e+01  1.43689172e+01 -4.44534243e+01\n",
            "  1.36193847e+01 -1.24877257e+01 -1.95696485e+01  6.85289102e+01\n",
            " -3.78980817e+01  8.95981611e+01  8.90504265e+01 -3.39301150e+01\n",
            "  2.43285918e+01  1.16199833e+01  1.08849474e+02  1.52442105e+01\n",
            " -2.97494023e+01 -1.58453054e+02  6.57624089e+01  6.71259918e+00\n",
            "  4.27585894e+01 -1.54138882e+01  8.32779819e+00  5.70273265e+00\n",
            "  2.35590658e+01  3.24265427e+01 -2.19725594e+01 -7.70746044e+00\n",
            "  5.21337156e+01  5.00399625e+01 -6.37819925e+01 -1.45659713e+01\n",
            " -4.20977470e+01 -4.54246807e+01  8.69416606e+01  3.12449365e+01\n",
            "  2.77612240e+01  4.37640848e+01 -3.33995971e+01  9.52677326e+01\n",
            "  1.06929764e+01  2.39253855e+01 -7.41867591e+01  6.52456313e+01\n",
            " -6.90914853e+01 -7.10883380e+01 -2.00576469e+01 -1.74696933e+00\n",
            " -1.00247936e+02  6.97562140e+00  3.93923453e+00 -1.60663722e+02\n",
            "  3.21967723e+01  9.65988616e+00 -1.44688952e+00 -2.48424793e+00\n",
            " -1.52019380e+01  3.30635458e+00  3.28700080e+01  2.59409321e+01\n",
            " -3.89275941e+01  4.40204456e+01 -3.38853535e+01 -5.17473839e+01\n",
            " -4.60286912e+01 -8.46229965e+01  7.74130752e+01  4.80810227e+01\n",
            " -3.38031900e+01  2.87508454e-01 -1.67175190e+01 -1.06075150e+02\n",
            " -3.00169341e+01 -3.61429559e+01  1.32811304e+01  5.43857396e+01\n",
            " -2.31921021e-02 -3.36518530e+01  4.25262954e+01  6.99139587e+01\n",
            "  3.74892342e+01  1.69072940e+01  1.46206561e+01  5.65421749e+01\n",
            "  6.30179318e+01 -1.12372453e+01 -1.98080194e+01  1.05450927e+01\n",
            " -4.31111282e+00 -2.35550488e+01 -2.43351298e+01  8.12316695e+01\n",
            " -2.27897494e+01  3.92621064e+01 -1.37854172e+01  4.16505797e+01\n",
            " -1.38734308e+02 -6.32758687e+01  3.78930351e+01  1.17361105e+01\n",
            " -9.04049250e+01  2.28470581e+01  7.64129801e+01 -4.26744010e+01\n",
            "  1.32158821e+01 -7.04695678e+00  1.36787458e+02  6.34607778e+00\n",
            " -1.88566784e+01 -4.13014424e+00  9.01304850e+00 -2.66019414e+01\n",
            "  6.25731946e+01 -8.28936320e+01  1.25112996e+01 -6.44557774e+01\n",
            " -7.47180689e+00  5.82308786e+01 -3.62089529e+00  3.51709839e+01\n",
            "  7.02690311e-01  5.50576087e+01  4.80912146e+01  2.61131185e+00\n",
            " -2.59953793e+02  3.86178871e+01 -1.44611274e+01  3.65139257e+01\n",
            " -2.95541101e+01  1.45513556e+01 -1.39491032e+01  1.04399134e+02\n",
            "  3.84879223e+01  4.86691347e+01  4.87355475e+01  1.47521712e+01\n",
            "  1.40103460e+00 -5.43985264e+01 -7.80287805e+01  7.17866025e+00\n",
            "  2.34138508e+01  5.78476653e+01 -3.00012102e+01  6.39774219e+01\n",
            "  3.98639165e+01 -4.31058065e+01 -2.43153911e+01 -3.49388610e+01\n",
            " -5.07731338e+01 -3.61893944e+01  2.22484962e+01 -4.45479344e+01\n",
            "  4.59819165e+02 -3.24459572e+01 -4.14411394e-01 -5.08810412e+00\n",
            "  4.80793751e+01  3.34835704e+01 -1.58932103e+01  3.69056264e+01\n",
            " -2.80737038e+01 -7.40600425e+01 -3.03434081e+01 -2.02518439e+01\n",
            "  5.80439587e+01  8.10776633e+00  4.93210465e+01  1.40310235e+01\n",
            "  3.29063851e+01  3.92506656e+01 -9.96920834e+00 -3.97486708e+00\n",
            "  3.85555724e+01 -3.49979005e+01 -5.96931109e+01  1.71969083e+01\n",
            " -2.01872255e+01 -4.83666563e+00  4.48001790e+01 -7.18560381e+00\n",
            " -1.82129536e+01 -3.72482704e+01  3.10477609e+01 -9.33571095e+00\n",
            " -1.48613833e+01 -7.99417615e+01  2.60629924e+01  5.71096232e+01\n",
            "  4.85908511e+01  2.19670179e+01 -3.32058687e+01  6.01385307e+01\n",
            "  2.57739379e+00  2.14191275e+01  1.18386866e+02  4.42986733e+01\n",
            " -2.43357975e+02 -3.22935657e+01  6.95723265e+01 -2.69234442e+00\n",
            " -3.27358957e+01 -9.64676381e+00  3.72488018e+01 -4.18842245e+01\n",
            " -6.27477209e+01  1.37906333e+01  1.31446110e+02 -5.27007176e+00\n",
            "  4.15361676e+00 -6.94459991e+01  6.09109520e+01  2.80644373e+01\n",
            " -1.03555984e+01 -6.95520168e+01  3.93010427e+01  1.66143203e+01\n",
            " -3.30754076e+01 -1.94294860e+01 -2.22479398e+01 -3.83469941e+01\n",
            "  6.73139395e+01  7.03630308e+01 -2.67258245e+00 -4.82475437e+01\n",
            "  7.38997020e+00  6.02701147e+01  1.78922207e+01  5.80211451e+01\n",
            " -8.49317668e+02 -3.03425533e+01  1.88814931e+02  2.47084556e+01\n",
            " -8.18175476e+01 -2.36499555e+00 -1.26462177e+01 -1.49247961e+01\n",
            " -1.34556976e+01  8.25857665e+01 -4.53203250e+01  5.98323598e+01\n",
            "  5.53178867e+00  3.68845228e+00 -8.28903665e+00 -8.37700131e+01\n",
            " -1.68780704e+01  3.56149915e+01  2.07283593e+01  5.50870919e+01\n",
            "  5.88062392e+00 -6.25099449e+01 -5.75366503e+01  3.70836116e+01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representar_review_como_vector_promedio(review):\n",
        "    # Utiliza la función previamente definida para obtener los vectores suma y promedio\n",
        "    vectores, promedio = representar_review_como_vector(review)\n",
        "    return promedio\n"
      ],
      "metadata": {
        "id": "rZPUAlOgqOT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscar reviews que contienen la frase 'the only problem'\n",
        "matching_reviews = train_df[train_df['review'].str.contains('the only problem', case=False)]\n",
        "\n",
        "# Verificar si se encontraron reviews\n",
        "if matching_reviews.empty:\n",
        "    print(\"No se encontraron reviews que contengan la frase 'the only problem'.\")\n",
        "else:\n",
        "    # Seleccionar la primera review que coincide\n",
        "    review_ejemplo = matching_reviews['review'].values[0]\n",
        "\n",
        "    # Obtener el vector promedio de la review\n",
        "    promedio = representar_review_como_vector_promedio(review_ejemplo)\n",
        "\n",
        "    # Encontrar las palabras más similares al vector promedio\n",
        "    print(\"Palabras similares al vector promedio:\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rII0xuQPqS1O",
        "outputId": "da7da9ef-9987-44cc-db72-d9a2d717246b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No está la palabra closed-down\n",
            "No está la palabra don't\n",
            "No está la palabra couldn't\n",
            "No está la palabra killer's\n",
            "No está la palabra identital\n",
            "No está la palabra you'll\n",
            "No está la palabra suspeneful\n",
            "Palabras similares al vector promedio:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drco-DEoOb6w"
      },
      "source": [
        "# Red RNN  pero con Embeddings preentrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReOXN3bAOXMm",
        "outputId": "b9b6d14a-cf6c-40a4-9cc2-64683aef8ccf"
      },
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    # A simpleRNN without any pretrained embeddings and one dense layer\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "    model.add(Conv1D(128, 5, activation=\"relu\"))\n",
        "    model.add(MaxPooling1D(5))\n",
        "    model.add(Conv1D(128, 5, activation=\"relu\"))\n",
        "    model.add(MaxPooling1D(5))\n",
        "    model.add(Conv1D(128, 5, activation=\"relu\"))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='sigmoid'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=64*strategy.num_replicas_in_sync, validation_data=(xvalid_pad,yvalid_one_hot))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 12s 155ms/step - loss: 0.7298 - accuracy: 0.5150 - val_loss: 0.7024 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 1s 62ms/step - loss: 0.6972 - accuracy: 0.5258 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 1s 62ms/step - loss: 0.6971 - accuracy: 0.5083 - val_loss: 0.6895 - val_accuracy: 0.6200\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 1s 62ms/step - loss: 0.6815 - accuracy: 0.5800 - val_loss: 0.6763 - val_accuracy: 0.5875\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 1s 62ms/step - loss: 0.6292 - accuracy: 0.6792 - val_loss: 0.7581 - val_accuracy: 0.5050\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 1s 62ms/step - loss: 0.5196 - accuracy: 0.7533 - val_loss: 0.5454 - val_accuracy: 0.7300\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 1s 64ms/step - loss: 0.3087 - accuracy: 0.8683 - val_loss: 0.5042 - val_accuracy: 0.7750\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 1s 65ms/step - loss: 0.1259 - accuracy: 0.9608 - val_loss: 0.5494 - val_accuracy: 0.7600\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 1s 66ms/step - loss: 0.0395 - accuracy: 0.9900 - val_loss: 0.6994 - val_accuracy: 0.7550\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 1s 75ms/step - loss: 0.0552 - accuracy: 0.9783 - val_loss: 0.7506 - val_accuracy: 0.7375\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 1s 67ms/step - loss: 0.0502 - accuracy: 0.9825 - val_loss: 0.9013 - val_accuracy: 0.7475\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 1s 77ms/step - loss: 0.0287 - accuracy: 0.9917 - val_loss: 0.9231 - val_accuracy: 0.7475\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 1s 67ms/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.8800 - val_accuracy: 0.7525\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 1s 76ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8675 - val_accuracy: 0.7700\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 1s 75ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 0.8884 - val_accuracy: 0.7725\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 1s 76ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.9407 - val_accuracy: 0.7600\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 1s 77ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 0.7625\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 1s 66ms/step - loss: 6.5188e-04 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.7575\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 1s 64ms/step - loss: 6.0753e-04 - accuracy: 1.0000 - val_loss: 1.0175 - val_accuracy: 0.7525\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 1s 64ms/step - loss: 4.9523e-04 - accuracy: 1.0000 - val_loss: 1.0307 - val_accuracy: 0.7550\n",
            "CPU times: user 23.2 s, sys: 1.25 s, total: 24.4 s\n",
            "Wall time: 43.7 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f111db7ace0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk8NlGCDmQer",
        "outputId": "0fb33557-d6be-4aea-9660-bdeb880a58d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 2s 11ms/step\n",
            "Accuracy: 0.755\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.74      0.75       200\n",
            "    positive       0.75      0.77      0.76       200\n",
            "\n",
            "    accuracy                           0.76       400\n",
            "   macro avg       0.76      0.76      0.75       400\n",
            "weighted avg       0.76      0.76      0.75       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQbY143FqUwf"
      },
      "source": [
        "# **LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM con los embeddings propios del corpus"
      ],
      "metadata": {
        "id": "rNov1S9VL-2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1,#Cantidad de palabras distintas del corpus\n",
        "              300,#tamaño del vector con el que va a encodear cada palabra (del 1-hot lo pasa a un vector de 300 dimensiones)\n",
        "              input_length=max_len)) #El máximo de palabras que puede tener una review. )\n",
        "    model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "    model.add(Dense(2, activation='sigmoid'))  # Cambiado a 2 para clasificación binaria\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqoZ-0uwLGyI",
        "outputId": "1ee9dc16-e86f-4361-cfb8-28a51d80d731"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 2700, 300)         11809200  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               160400    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11969802 (45.66 MB)\n",
            "Trainable params: 11969802 (45.66 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=64*strategy.num_replicas_in_sync, validation_data=(xvalid_pad,yvalid_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MLs-6wSLjrw",
        "outputId": "38ca496d-86f0-4361-bdcd-914e83edc298"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 259s 13s/step - loss: 0.6944 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 240s 13s/step - loss: 0.6944 - accuracy: 0.4892 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 236s 12s/step - loss: 0.6942 - accuracy: 0.4808 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 239s 13s/step - loss: 0.6939 - accuracy: 0.4992 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 237s 12s/step - loss: 0.6935 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 236s 12s/step - loss: 0.6939 - accuracy: 0.5050 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 242s 13s/step - loss: 0.6934 - accuracy: 0.5017 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 238s 13s/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 241s 13s/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 245s 13s/step - loss: 0.6935 - accuracy: 0.4875 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 241s 13s/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 235s 12s/step - loss: 0.6937 - accuracy: 0.4858 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 236s 12s/step - loss: 0.6934 - accuracy: 0.4783 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 234s 12s/step - loss: 0.6935 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 234s 12s/step - loss: 0.6935 - accuracy: 0.4808 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 236s 12s/step - loss: 0.6933 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 238s 13s/step - loss: 0.6931 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 235s 12s/step - loss: 0.6935 - accuracy: 0.4967 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 236s 12s/step - loss: 0.6933 - accuracy: 0.4967 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 235s 12s/step - loss: 0.6937 - accuracy: 0.4733 - val_loss: 0.6932 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e6bd4100490>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8xjaPupMHdP",
        "outputId": "3cfbef69-3af7-4b1e-ddbf-0e729c29e600"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 10s 737ms/step\n",
            "Accuracy: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.50      1.00      0.67       200\n",
            "    positive       0.00      0.00      0.00       200\n",
            "\n",
            "    accuracy                           0.50       400\n",
            "   macro avg       0.25      0.50      0.33       400\n",
            "weighted avg       0.25      0.50      0.33       400\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM con Embeddings preentrenados"
      ],
      "metadata": {
        "id": "b_rgyN8cL5bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el modelo\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(word_index) + 1,\n",
        "                        output_dim=embedding_dim,\n",
        "                        weights=[embedding_matrix],\n",
        "                        input_length=max_len,\n",
        "                        trainable=False))\n",
        "    model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "    model.add(Dense(2, activation='sigmoid'))  # Cambiado a 2 para clasificación binaria\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ-6UF3ktyBr",
        "outputId": "960989cf-3904-4446-9d87-5a9e276589a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 2700, 300)         11809200  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               160400    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11969802 (45.66 MB)\n",
            "Trainable params: 160602 (627.35 KB)\n",
            "Non-trainable params: 11809200 (45.05 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zr546G0tsY4",
        "outputId": "fa4f3dfe-3773-4eca-e617-e0f01f7257ad"
      },
      "source": [
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=64*strategy.num_replicas_in_sync, validation_data=(xvalid_pad,yvalid_one_hot))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 261s 14s/step - loss: 0.6934 - accuracy: 0.4917 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 261s 14s/step - loss: 0.6932 - accuracy: 0.4867 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 254s 14s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 252s 13s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 258s 13s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 257s 13s/step - loss: 0.6933 - accuracy: 0.4850 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 257s 14s/step - loss: 0.6932 - accuracy: 0.4675 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 251s 13s/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 250s 13s/step - loss: 0.6932 - accuracy: 0.4858 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 255s 13s/step - loss: 0.6932 - accuracy: 0.5050 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 256s 13s/step - loss: 0.6932 - accuracy: 0.4942 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 252s 13s/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 256s 14s/step - loss: 0.6932 - accuracy: 0.5058 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 258s 14s/step - loss: 0.6932 - accuracy: 0.5083 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 256s 14s/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 255s 14s/step - loss: 0.6932 - accuracy: 0.4908 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 244s 13s/step - loss: 0.6933 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 254s 13s/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 251s 13s/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 246s 13s/step - loss: 0.6932 - accuracy: 0.4842 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f1084376860>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi9BlwIm8MRp",
        "outputId": "8a5b7d48-7ca5-47e1-bb94-f1366b555816"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 10s 743ms/step\n",
            "Accuracy: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.50      1.00      0.67       200\n",
            "    positive       0.00      0.00      0.00       200\n",
            "\n",
            "    accuracy                           0.50       400\n",
            "   macro avg       0.25      0.50      0.33       400\n",
            "weighted avg       0.25      0.50      0.33       400\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXwtcBAXqZec"
      },
      "source": [
        "# **GRU**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(word_index) + 1,\n",
        "                        output_dim=embedding_dim,\n",
        "                        weights=[embedding_matrix],\n",
        "                        input_length=max_len,\n",
        "                        trainable=False))\n",
        "    model.add(SpatialDropout1D(0.3))\n",
        "    model.add(GRU(300))\n",
        "    model.add(Dense(2, activation='sigmoid'))  # Cambiado a 2 para clasificación binaria\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpYtKYhnsk0L",
        "outputId": "f98ae2e4-6b44-483d-9bf6-1a9b2503b8d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 2700, 300)         11809200  \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 2700, 300)         0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 300)               541800    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 602       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12351602 (47.12 MB)\n",
            "Trainable params: 542402 (2.07 MB)\n",
            "Non-trainable params: 11809200 (45.05 MB)\n",
            "_________________________________________________________________\n",
            "CPU times: user 324 ms, sys: 123 ms, total: 447 ms\n",
            "Wall time: 447 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ncf-UiS2Lxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6245bb-7cfe-472c-97da-6f040c57c309"
      },
      "source": [
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=64*strategy.num_replicas_in_sync, validation_data=(xvalid_pad,yvalid_one_hot))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 9s 321ms/step - loss: 0.6934 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 6s 302ms/step - loss: 0.6932 - accuracy: 0.4883 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 6s 339ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 6s 339ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 6s 304ms/step - loss: 0.6933 - accuracy: 0.4883 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 6s 338ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 6s 343ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 8s 410ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 6s 304ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 6s 338ms/step - loss: 0.6932 - accuracy: 0.4883 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 7s 376ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 6s 307ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 6s 300ms/step - loss: 0.6932 - accuracy: 0.4817 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 7s 363ms/step - loss: 0.6933 - accuracy: 0.4783 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 6s 340ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 6s 340ms/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 6s 301ms/step - loss: 0.6932 - accuracy: 0.4750 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 6s 305ms/step - loss: 0.6932 - accuracy: 0.4667 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 6s 341ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 6s 341ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f1072c22ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r-6LcmIuapP",
        "outputId": "1889501a-df89-4990-c079-2a675e48d65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 2s 72ms/step\n",
            "Accuracy: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.00      0.00      0.00       200\n",
            "    positive       0.50      1.00      0.67       200\n",
            "\n",
            "    accuracy                           0.50       400\n",
            "   macro avg       0.25      0.50      0.33       400\n",
            "weighted avg       0.25      0.50      0.33       400\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dByA5hFqqfO9"
      },
      "source": [
        "# **bidirectional LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definir el modelo bidireccional LSTM\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(word_index) + 1,\n",
        "                        output_dim=embedding_dim,\n",
        "                        weights=[embedding_matrix],\n",
        "                        input_length=max_len,\n",
        "                        trainable=False))\n",
        "    model.add(Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3)))\n",
        "    model.add(Dense(2, activation='sigmoid'))  # Cambiado a 2 para clasificación binaria\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWHoxIFPv6gR",
        "outputId": "3ab60867-3ffd-449c-a773-b523d4bf5e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 2700, 300)         11809200  \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 256)               439296    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12249010 (46.73 MB)\n",
            "Trainable params: 439810 (1.68 MB)\n",
            "Non-trainable params: 11809200 (45.05 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el callback personalizado\n",
        "import datetime\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch_time_start = datetime.datetime.now()\n",
        "        print(f\"Epoch {epoch + 1} start time: {self.epoch_time_start}\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.epoch_time_end = datetime.datetime.now()\n",
        "        print(f\"Epoch {epoch + 1} end time: {self.epoch_time_end}\")\n"
      ],
      "metadata": {
        "id": "_8xI7dB0lEgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EarlyStopping: Añadí el callback EarlyStopping para detener el entrenamiento si la validación no mejora después de 3 épocas, lo cual puede ahorrar tiempo."
      ],
      "metadata": {
        "id": "ZamugX5RtkcK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FuTmnT87tlUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduced batch size\n",
        "batch_size = 64 * strategy.num_replicas_in_sync\n",
        "# Crear una instancia de los callbacks\n",
        "time_callback = TimeHistory()\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Entrenar el modelo con los callbacks\n",
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=batch_size, validation_data=(xvalid_pad, yvalid_one_hot), callbacks=[time_callback, early_stopping])\n",
        "\n",
        "#model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=batch_size, validation_data=(xvalid_pad, yvalid_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNE01-i9yEWj",
        "outputId": "28fc2e0f-9832-4098-9e1d-e107761cb4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 start time: 2024-07-04 13:17:06.315802\n",
            "Epoch 1/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6964 - accuracy: 0.5183 Epoch 1 end time: 2024-07-04 13:23:55.106132\n",
            "19/19 [==============================] - 409s 21s/step - loss: 0.6964 - accuracy: 0.5183 - val_loss: 0.6936 - val_accuracy: 0.5275\n",
            "Epoch 2 start time: 2024-07-04 13:23:55.116909\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6778 - accuracy: 0.5775 Epoch 2 end time: 2024-07-04 13:30:34.453928\n",
            "19/19 [==============================] - 399s 21s/step - loss: 0.6778 - accuracy: 0.5775 - val_loss: 0.6941 - val_accuracy: 0.5125\n",
            "Epoch 3 start time: 2024-07-04 13:30:34.471241\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6625 - accuracy: 0.6358 Epoch 3 end time: 2024-07-04 13:37:25.832788\n",
            "19/19 [==============================] - 411s 22s/step - loss: 0.6625 - accuracy: 0.6358 - val_loss: 0.7025 - val_accuracy: 0.5400\n",
            "Epoch 4 start time: 2024-07-04 13:37:25.843448\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6426 - accuracy: 0.6433 Epoch 4 end time: 2024-07-04 13:44:20.176433\n",
            "19/19 [==============================] - 414s 22s/step - loss: 0.6426 - accuracy: 0.6433 - val_loss: 0.6826 - val_accuracy: 0.5825\n",
            "Epoch 5 start time: 2024-07-04 13:44:20.188203\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.6750 Epoch 5 end time: 2024-07-04 13:51:05.056435\n",
            "19/19 [==============================] - 405s 21s/step - loss: 0.6136 - accuracy: 0.6750 - val_loss: 0.6954 - val_accuracy: 0.5500\n",
            "Epoch 6 start time: 2024-07-04 13:51:05.072841\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5779 - accuracy: 0.7133 Epoch 6 end time: 2024-07-04 13:58:10.211631\n",
            "19/19 [==============================] - 425s 22s/step - loss: 0.5779 - accuracy: 0.7133 - val_loss: 0.6911 - val_accuracy: 0.6125\n",
            "Epoch 7 start time: 2024-07-04 13:58:10.227052\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5297 - accuracy: 0.7283 Epoch 7 end time: 2024-07-04 14:05:03.310320\n",
            "19/19 [==============================] - 413s 22s/step - loss: 0.5297 - accuracy: 0.7283 - val_loss: 0.7387 - val_accuracy: 0.5550\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f108454c880>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i-8g7N9ecyWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "13:52\n",
        "2:05\n",
        "15 min por epoch"
      ],
      "metadata": {
        "id": "SoLYSzRgg4A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq1E_HSpwJya",
        "outputId": "102e0f34-9307-4184-b9e8-6ceac98fe83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 22s 2s/step\n",
            "Accuracy: 0.555\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.56      0.48      0.52       200\n",
            "    positive       0.55      0.63      0.59       200\n",
            "\n",
            "    accuracy                           0.56       400\n",
            "   macro avg       0.56      0.55      0.55       400\n",
            "weighted avg       0.56      0.56      0.55       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(datetime.datetime.now())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpzyOe4Y9Z5k",
        "outputId": "28655a48-691c-4266-a366-da064cbc534f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-04 11:22:16.004477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_T5GB6ketS_",
        "outputId": "ecfdacb9-6870-4f9f-be7d-72d62afe2bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-04 11:22:16.016657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocesar_review(review, tokenizer, max_len):\n",
        "    # Convertir la review en una secuencia de índices\n",
        "    seq = tokenizer.texts_to_sequences([review])\n",
        "    # Aplicar padding a la secuencia\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_len)\n",
        "    return padded_seq\n",
        "\n",
        "def clasificar_review(review, model, tokenizer, max_len):\n",
        "    # Preprocesar la review\n",
        "    preprocessed_review = preprocesar_review(review, tokenizer, max_len)\n",
        "    # Hacer la predicción\n",
        "    pred = model.predict(preprocessed_review)\n",
        "    # Obtener la clase predicha\n",
        "    pred_class = (pred > 0.5).astype(int)\n",
        "    return 'positive' if pred_class[0][0] == 1 else 'negative'\n",
        "\n",
        "nueva_review = \"This movie was incredible, the acting was spectacular and the plot very engaging.\"\n",
        "resultado = clasificar_review(nueva_review, model, tokenizer, max_len)\n",
        "print(f\"La review es: {resultado}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qGQPrgxfHqn",
        "outputId": "c95533fd-6599-4e87-f2a8-954ddcb7c32f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "La review es: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WkyB9QSOMiEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nueva_review = \"The Adventure Never Ends is an absolute trainwreck, plagued by a nonsensical plot, painfully bad acting, and horrendous special effects.\"\n",
        "resultado = clasificar_review(nueva_review, model, tokenizer, max_len)\n",
        "print(f\"La review es: {resultado}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuaiDZ-VKSI4",
        "outputId": "8f34ed08-520b-4172-ce65-e0b27509e22d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 7s 7s/step\n",
            "La review es: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9dWuwfyxkaDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Supongamos que `model` es el modelo CNN ya entrenado\n",
        "# y `tokenizer` es el tokenizer ajustado en el conjunto de datos de entrenamiento\n",
        "\n",
        "def preprocesar_review(review, tokenizer, max_len):\n",
        "    # Convertir la review en una secuencia de índices\n",
        "    seq = tokenizer.texts_to_sequences([review])\n",
        "    # Aplicar padding a la secuencia\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_len)\n",
        "    return padded_seq\n",
        "\n",
        "def clasificar_review(review, model, tokenizer, max_len):\n",
        "    # Preprocesar la review\n",
        "    preprocessed_review = preprocesar_review(review, tokenizer, max_len)\n",
        "    # Hacer la predicción\n",
        "    pred = model.predict(preprocessed_review)\n",
        "    # Obtener la clase predicha\n",
        "    pred_class = np.argmax(pred, axis=1)\n",
        "    return 'positive' if pred_class[0] == 1 else 'negative'\n",
        "\n",
        "# Ejemplo de uso:\n",
        "nueva_review = \"This movie was incredible, the acting was spectacular and the plot was very involving.\"\n",
        "resultado = clasificar_review(nueva_review, model, tokenizer, max_len)\n",
        "print(f\"La review es: {resultado}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaciaV-PwI2R",
        "outputId": "109327cb-eb54-48f3-c04f-87611344ff88"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 886ms/step\n",
            "La review es: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de uso:\n",
        "nueva_review = \"This movie was pretty awful\"\n",
        "resultado = clasificar_review(nueva_review, model, tokenizer, max_len)\n",
        "print(f\"La review es: {resultado}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaekB28Oj36d",
        "outputId": "286026da-3951-4a1b-fb63-04b29c7bfa16"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "La review es: negative\n"
          ]
        }
      ]
    }
  ]
}