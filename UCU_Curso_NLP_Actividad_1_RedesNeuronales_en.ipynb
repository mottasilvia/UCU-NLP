{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mottasilvia/UCU-NLP/blob/main/UCU_Curso_NLP_Actividad_1_RedesNeuronales_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential # Import Sequential from tensorflow.keras\n",
        "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN # Import recurrent layers from tensorflow.keras\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout # Import core layers from tensorflow.keras\n",
        "from tensorflow.keras.layers import Embedding # Import Embedding layer from tensorflow.keras\n",
        "from tensorflow.keras.layers import BatchNormalization # Import BatchNormalization from tensorflow.keras\n",
        "from tensorflow.keras.utils import to_categorical # Import to_categorical for one-hot encoding\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D # Import additional layers from tensorflow.keras\n",
        "from tensorflow.keras.preprocessing import sequence, text # Import preprocessing modules from tensorflow.keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping # Import EarlyStopping from tensorflow.keras\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "8EHR_YVHCwHC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la disponibilidad de la GPU\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh7TSH6Ed2er",
        "outputId": "7ed8e1b9-ec86-4779-9111-7d80d9be9468"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "Default GPU Device: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqjQlE90bmXL",
        "outputId": "7273f477-c60f-4f77-a95f-d56e6dbda46d"
      },
      "source": [
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LATMW4Fyb5IM",
        "outputId": "1b746932-ce6a-42a4-e927-5dead9c60240"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "carpeta_laboratorios = \"/\"\n",
        "path_laboratorios = '/content/drive/My Drive/'\n",
        "#df = pd.read_csv(path_laboratorios+\"Canciones_limpias_finalisismo.csv\")\n",
        "\n",
        "#train = pd.read_csv(path_laboratorios+\"train.csv\")\n",
        "#test = pd.read_csv(path_laboratorios+\"test.csv\")\n",
        "#validation = pd.read_csv(path_laboratorios+\"val.csv\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_to_folder(zip_files, target_dir=\"unzipped_files\"):\n",
        "  os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "  for zip_file in zip_files:\n",
        "    filename, _ = os.path.splitext(os.path.basename(zip_file))\n",
        "    folder_name = target_dir\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "      zip_ref.extractall(folder_name)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # Example usage\n",
        "  zip_files = [\"/content/drive/MyDrive/UCU-TesisFinal/aarchive (3).zip\"]\n",
        "  unzip_to_folder(zip_files, \"/content/Movie\")\n"
      ],
      "metadata": {
        "id": "_WUBOSyMEn9y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "# Define los paths a los directorios que contienen las reseñas\n",
        "neg_dir = '/content/Movie/txt_sentoken/neg'\n",
        "pos_dir = '/content/Movie/txt_sentoken/pos'\n",
        "\n",
        "# Función para leer reseñas de un directorio y asignar una etiqueta\n",
        "def load_reviews_from_directory(directory, tag):\n",
        "    reviews = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
        "                review = file.read()\n",
        "                reviews.append((review, tag))\n",
        "    return reviews\n",
        "\n",
        "# Verificar si los directorios existen\n",
        "if os.path.exists(neg_dir) and os.path.exists(pos_dir):\n",
        "    # Cargar reseñas negativas y positivas\n",
        "    negative_reviews = load_reviews_from_directory(neg_dir, 'negative')\n",
        "    positive_reviews = load_reviews_from_directory(pos_dir, 'positive')\n",
        "\n",
        "    # Combinar las reseñas en un único DataFrame\n",
        "    all_reviews = negative_reviews + positive_reviews\n",
        "    df = pd.DataFrame(all_reviews, columns=['review', 'tag'])\n",
        "\n",
        "    # Mostrar el DataFrame\n",
        "    from IPython.display import display\n",
        "    display(df)\n",
        "\n",
        "    # Verificar las primeras filas del DataFrame\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"Los directorios especificados no existen. Verifica los paths y vuelve a intentarlo.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "TjjPOysInDBS",
        "outputId": "59bd8c79-2cf8-484a-b1e8-bb79b233e9ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                 review       tag\n",
              "0     alexandre dumas meets hong kong action with ne...  negative\n",
              "1     this is my first review that i post to this ne...  negative\n",
              "2     an 18-foot-high , 43-foot-long dragon is the c...  negative\n",
              "3     in double jeopardy , the stakes are high . \\nt...  negative\n",
              "4     when it comes to the average teenage romantic ...  negative\n",
              "...                                                 ...       ...\n",
              "1995  before even seeing a single frame of the film ...  positive\n",
              "1996  i'll be the first to admit i didn't expect muc...  positive\n",
              "1997  melvin udall is a heartless man . \\nhe spends ...  positive\n",
              "1998  the booming introduction music finishes , and ...  positive\n",
              "1999  ingredients : london gal , fate , true love , ...  positive\n",
              "\n",
              "[2000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2f636ce-4c19-4256-9e67-8634a4563ecb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>alexandre dumas meets hong kong action with ne...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this is my first review that i post to this ne...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>an 18-foot-high , 43-foot-long dragon is the c...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in double jeopardy , the stakes are high . \\nt...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>when it comes to the average teenage romantic ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>before even seeing a single frame of the film ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>i'll be the first to admit i didn't expect muc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>melvin udall is a heartless man . \\nhe spends ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>the booming introduction music finishes , and ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>ingredients : london gal , fate , true love , ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2f636ce-4c19-4256-9e67-8634a4563ecb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2f636ce-4c19-4256-9e67-8634a4563ecb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2f636ce-4c19-4256-9e67-8634a4563ecb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e197747f-d7e8-4b05-b2f4-7ba659a65760\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e197747f-d7e8-4b05-b2f4-7ba659a65760')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e197747f-d7e8-4b05-b2f4-7ba659a65760 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b704dabb-124c-4f7c-bdf2-5f624464f95c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b704dabb-124c-4f7c-bdf2-5f624464f95c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"in 1995 , brian singer and christopher mcquarrie dreamed up a simple concept : the audience isn't stupid . \\nfrom that , they went on and created the most plot-driven , intricately pieced movie in the last 25 years . \\nthe result : the usual suspects , one hell of a movie that redefines the word plot twist . \\nthe story is convoluted , and is really confusing to read , although easy to follow on screen . \\nspecial investigator kujan ( chazz palminteri ) grills \\\" verbal \\\" kint ( kevin spacey ) , a crippled con-man who is the lone survivor of an la boat explosion that claimed more than 20 victims . \\nkujan wants to confirm that his nemesis , the rogue cop keaton ( gabriel byrne ) , is actually dead . \\nkint relates the majority of the film in flashback , beginning with the fateful day when five shifty guys meet in a police-station lineup in new york city . \\nalong with dour keaton , kint encounters cheerfully sociopathic mcmanus ( stephen baldwin ) , mordantly sarcastic hockney ( kevin pollak ) , and fenster ( benicio del toro ) , whose speech is virtually incomprehensible . \\ntogether they plot to steal a small fortune in gems from \\\" new york's finest taxi service \\\" --crooked cops who provide escort service for visiting drug kingpins . \\nwhat follows is a shell-game of violence and betrayal , all hinging on the identity of a mysterious villain called keyser soze . \\nthe film is brilliantly compact : its the shortest 90 minutes you'll ever spend in a movie theater . \\nthe cast is exceptional . \\npalminteri shines , he is brutally honest , a true cop , one who is going after the whole story because its there . \\nbyrne is terrific , his brooding character , his seriousness is needed to supplement the hysteria of benicio del toro , who is a riot as fenster . \\ndel toro is brilliant , his lines are a jumbled mess , you can't understand a word the man says , but it sure is damn funny . \\nbaldwin is also very good , he is careful , methodical , and cold , a chilling character with a nasty streak of hot-blooded sarcasm . \\npollak is also terrific as usual , a very good character actor . \\nhowever , this will be forever known as the film that launched kevin spacey . \\nspacey is simply breathtaking , he is a force on screen , giving a magnetic performance that jars the senses at the end of this twisting maze . \\nspacey's performance will be remembered for years , for it is the best of his career , it may be the best supporting actor performance in the last 50 years . \\nverbal kint is a clever storyteller , weak , oppressed , and gleefully evil to the bone , yet pitiful , one who draws sympathy . \\nthe film is a good one , a decent film until the last 10 minutes . \\nwhat this film boils down to is the greatest ending in cinematic history , for me at least . \\nthe revelation of keyser soze , the closing gunfights , it is something wondrous . \\nyou have to see this movie about 10 times to believe what they do . \\nkudos to mcquarrie and singer for giving the audience a delightful , fast-paced , furiously plot-driven movie with quirky characters , phenomenal acting , and some hilarious moments stuck in the middle . \\nmcquarrie refuses to believe the audience is dumb . \\nwithout furnishing too many details , he concocts his story and lets it run , hoping the audience gets it at the end . \\nwe do . \\nthis might just be the finest cinematic puzzle ever created . \\nkudos also to singer and john ottman , who created the score . \\nthey both create what is a true film-noir setting , carefully setting up this intricate puzzle until the final , jarring ending . \\nthere are flaws : more questions raised than answers , lack of character development , and no strong female characters ( save one ) . \\nhowever , the plot , and that stunning ending , make up for all the flaws and more . \\nif you haven't seen the movie , rent it . \\nwatch it . \\nthen rewind the tape , and watch it again . \\ntrust me , you'll be amazed . \\n\",\n          \" \\\" love to kill \\\" starts off aimlessly and gets progressively less coherent as time passes . \\nat the outset , the movie appears to be about tony danza , who's an illegal distributor of guns , trying to establish a relationship with an unsuspecting woman . \\ndanza sets up a double date with her , her sister , and a collegue of his . \\neverything seems to be going well , until the sister accidentally dies by falling down a set of stairs . \\nmuch confusion and mahem ensues , as the death is covered up and other associates of danza's begin to emerge , all after one thing or another . \\nsound confusing ? \\nit is . \\ni think what the filmmakers were trying to do is take the standard crime movie and throw in a little humour and levity . \\nin some respects , it works . \\nbut the majority of the film is a convoluted and confusing mess . \\ncharacters keep popping up with no explanation , demanding money for deals that occur off-screen . \\nthe only aspect of the movie that actually works is the budding relationship between danza and the dead woman's sister . \\nbut so little time is devoted to this part of the story , we never really become too familiar with these characters , and because of this , we don't really care what happens to them . \\nwell , i didn't , at least . \\none thing i will give the movie is that it's a complete departure for tony danza . \\nhere's a guy , because of his many sitcom roles , who's ingrained in the consciousness as a nice guy who always does the right thing . \\nhere , he plays a man who's just looking out for himself , and if that means he needs to kill in order to save his own skin , so be it . \\ni was very impressed by his performance , and within minutes of the start of the film , i had forgotten all about his good-guy persona . \\nmichael madsen is also good as an associate of danza's who spends half the movie buddying up to him and the other half trying to kill him . \\nlike i said , it's not exactly a linear storyline . \\n \\\" love to kill \\\" should be praised for trying to do something different with the well worn crime genre , but it's just too bad that the story doesn't really add up to much . \\nthe stars deserved better , and so did the audience . \\n\",\n          \"mars attacks ! \\n ( 1996 ) - c : jack nicholson , glenn close , annette bening , martin short , danny devito , rod steiger , pierce brosnan , sarah jessica parker , michael j . fox , jim brown , pam grier , joe don baker , natalie portman , christina applegate , lisa marie , tom jones . \\nthis is director tim burton's finest film to date . \\nmany will compare this tale of martians who invade earth to independence day , but even though the stories are similar , they really are two distinctly different films . \\nhowever as a whole , mars attacks is much more entertaining than id4 , and i loved id4 . \\nyou really have to be in the right frame of mind to enjoy this film . \\nit is completely wacked-out and unlike anything you've ever seen . \\nonce the silly tone of the film is set , it's easy to just sit back and throw logic out the window because logic and comedy just don't mix . \\nthe plot is simple : martians invade the earth . \\nbut it's different than any other invasion film . \\nusually it's the evil aliens versus the heroic humans . \\nthis time however , it's the goofy aliens versus the equally goofy humans . \\nthe martians , who are all computer generated , are just about the funniest things i've seen in a long time . \\nthey look funny , they move funny , and their \\\" language \\\" is hilarious . \\nand about the special effects . \\nthe effects in mars attacks ! \\nare just about the most flawless ones i've seen to date . \\nthe computer animation of the martians combined with the goofy personalities they are given makes them seem 100% real . \\nthere are just a couple of scenes that don't work , mainly those involving sarah jessica parker and pierce brosnan on board an alien ship . \\nalso , glenn close overacts tremendously in her ( thankfully ) very limited screen time , so much so that i actually applauded silently when her character meets her demise . \\nbut there are many big laughs in the film , as i said , if you are in the right mood . \\ncould it have been funnier ? \\ncertainly . \\nwas it funny enough ? \\nyes . \\nwas i entertained ? \\nabsolutely . \\non a personal note , i'd like to thank whomever cast rod steiger ( my favorite actor ) in the film as war-crazy general decker . \\nfinally , after many very small parts in direct to video garbage and minor tv roles , steiger is back on the big screen in a real movie that many people will see . \\nwhile he's not given the type of role that you can give a real \\\" performance \\\" in , he does the job well and has some good lines of dialogue . \\nthe preview audience i saw the film with really seemed to enjoy him . \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review       tag\n",
            "0  alexandre dumas meets hong kong action with ne...  negative\n",
            "1  this is my first review that i post to this ne...  negative\n",
            "2  an 18-foot-high , 43-foot-long dragon is the c...  negative\n",
            "3  in double jeopardy , the stakes are high . \\nt...  negative\n",
            "4  when it comes to the average teenage romantic ...  negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir el DataFrame en train (60%) y temp (40%)\n",
        "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42, stratify=df['tag'])\n",
        "\n",
        "# Dividir el temp_df en validation (50% de 40% -> 20%) y test (50% de 40% -> 20%)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['tag'])\n",
        "\n",
        "# Mostrar los tamaños de los conjuntos de datos\n",
        "print(f\"Tamaño del conjunto de entrenamiento: {len(train_df)}\")\n",
        "print(f\"Tamaño del conjunto de validación: {len(val_df)}\")\n",
        "print(f\"Tamaño del conjunto de prueba: {len(test_df)}\")\n",
        "\n",
        "# Mostrar las primeras filas de cada conjunto de datos para verificación\n",
        "print(\"Conjunto de entrenamiento:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nConjunto de validación:\")\n",
        "print(val_df.head())\n",
        "\n",
        "print(\"\\nConjunto de prueba:\")\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW58VTUiqNb8",
        "outputId": "6f227530-03ad-43f1-f64a-fd122638080c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: 1200\n",
            "Tamaño del conjunto de validación: 400\n",
            "Tamaño del conjunto de prueba: 400\n",
            "Conjunto de entrenamiento:\n",
            "                                                 review       tag\n",
            "1523  susan granger's review of \" the closet \" ( mir...  positive\n",
            "1202  when i left the theater after seeing david lyn...  positive\n",
            "468    \" saving silverman \" is a good example of a g...  negative\n",
            "578   if you're into watching near on two hours of b...  negative\n",
            "1029   \" the end of the affair \" is a dark and moody...  positive\n",
            "\n",
            "Conjunto de validación:\n",
            "                                                 review       tag\n",
            "1152  full metal jacket , very much like every other...  positive\n",
            "1762  available for rental - october 12 , 1999 \\n10 ...  positive\n",
            "1142  i guess there are those who have never been ki...  positive\n",
            "612   first troy beyer wrote the critically panned \"...  negative\n",
            "202   what would you do if no one could see you ? \\n...  negative\n",
            "\n",
            "Conjunto de prueba:\n",
            "                                                 review       tag\n",
            "200    \" i would appreciate it if you didn't do that...  negative\n",
            "1702  if there is one thing that bothers me about ho...  positive\n",
            "1209  jacques tati's 1953 classic \" les vacances de ...  positive\n",
            "1451  the release of dolores claiborne into wide rel...  positive\n",
            "1409  on seeing the outrageous previews for bulworth...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX8PvSfgpc_1"
      },
      "source": [
        "# **Redes Neuronales Recurrentes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC_wtAZ_osQV"
      },
      "source": [
        "Veamos el máximo de palabras por review para tener una idea luego a la hora de paddear y todas esas cosas.-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjsIc7QXe9u6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "733520c5-44b5-4308-d620-de2da9cd646a"
      },
      "source": [
        "max_words_per_review = df['review'].apply(lambda x: len(str(x).split())).max()\n",
        "max_words_per_review"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2678"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78ZBJvU8y3ei"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x_m__V5yrjMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv7p-XHpzTFq"
      },
      "source": [
        "max_len = 2700 #Si bien el máximo es 2678, ponemos 2700 para tener un poco más de holgura. Se va a usar después para padear!"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFSFwIz0ylXC"
      },
      "source": [
        "xtrain = train_df.review.values\n",
        "xvalid = val_df.review.values\n",
        "xtest = test_df.review.values\n",
        "ytrain = train_df.tag.values\n",
        "yvalid = val_df.tag.values\n",
        "ytest = test_df.tag.values\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6LD_n0jmv3-",
        "outputId": "cad3649d-961c-4d68-b089-d4ec0a19f7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['every once in a while a movie comes along that completely redefines the genre : with dramas , it was citizen kane , with arthouse it was pulp fiction , and with comedy it was , well , that jim carrey guy ( okay , so he\\'s not a movie , but he did have a huge influence on the genre . \\nnot to mention an expensive one . ) \\nsometimes a movie even combines them all into a big , sprawling motion picture event , as did forrest gump four years ago . \\nwith action films , it was aliens , whic was released to much hype seven years after it\\'s equally-innovative parent , alien ( 1979 ) . \\ndirected and written by james cameron ( t2 : judgement day , the abyss , true lies ) , the authority on action films , it was a masterful encore to his sci-fi thriller the terminator ( 1984 ) . \\nwhile the original alien film was a dark , enclosed horror film that featured one alien slowly massacering a horrified crew , james cameron took the big-budget action film with aliens , which featured multiple aliens doing basically the same thing , although on a much-larger scale . \\nand boy , did he take that route ! \\ni\\'d say at about 165 mph or so . . . \\nthe film opens 57 years after the original , with lt . ripley ( weaver ) being found in her ship in a cryogenic state by a salvage vessel . \\nif you\\'ll recall , at the end of alien ripley , the only surviving member , cryogenically \" hibernated \" herself after expelling the rogue alien from her ship . \\nunfortunately , she thought she\\'d only be out for a couple of weeks . . . \\nonce she\\'s returned to earth , ripley is quickly interrogated by \" the company \" , who quickly dismiss her and her stories as lunacy . \\nin truth , they believe her , as they soon approach ripley with an offer to travel with some marines to a new colony planet as an \" alien advisor \" . \\nit seems that the colony planet was a once-breeding ground for the nasty aliens , and now all communication with the planet has been lost . . . \\nit doesn\\'t exactly take a genius to guess what happens next : ripley agrees , and before you can say \" big mistake \" , she and the half dozen marines , plus the slimy corporate guy ( reiser ) , who has more than it looks like up under his sleeve , are off to the colony . \\nwhen they arrive , they find the planet in ruins . \\nonly one survivor is found , a little girl , newt , who confirms that , yes , the aliens were here and that she only managed to survive by hidding in the ventilation system . \\nand soon enough , the marines come under attack from the aliens . . . \\nwhat happens for the next hour and a half or so is what completely sets this movie apart from any other standard alien sci-fi movie : the action scenes . \\ncameron directs them so skillfully , and so suspensefully , that you\\'re literally ringing your hands by the time the finale rolls around . \\nwhich features , in my opinion , the best fight scene ever recorded on film , as ripley straps herself into a huge robot and battles the nasty queen alien to the death . \\nmany people will tell you that this film , while being a great action film , has no real drama and is all cliches . \\nwell , they would be wrong , my friends . \\nif this film had no \" drama \" , then why was sigourney weaver nominated for best actress at the 1987 academy awards ? \\nthat\\'s right , best actress . \\nyou know that any action film that has an oscar nomination attached to it for something other than technical stuff like editing and f/x has got to be good . \\nin short , aliens combines all the right elements ( great action and f/x , drama , a good plot , good dialogue , and great villains ) into what could arguably be called the best action film of all time . \\nthen again , maybe not . \\nmovies rise and fall from glory and , sad to say , aliens was wrestled from it\\'s throne of best action movie by another cameron film , t2 : judgement day , in 1991 . \\nso who will be the next king ? \\nwell , let\\'s wait until december 19th and see yet another james cameron film-the highest budgeted film of all time-titanic to make that decision . \\ni can\\'t wait . \\n',\n",
              "       ' \" gattaca \" represents a solid breakthrough in the recent onslaught of science-fiction films -- it\\'s a genre picture that doesn\\'t rely on alien creatures or loud explosions to tell its story . \\nthe movie takes place in a futuristic world where babies are created through genetic tampering and not sexual reproduction . \\nthis allows parents to predetermine what kind of eye color , intelligence and life span they\\'d like for their child , and also eliminates most pesky chances of health defects . \\nthose made the old-fashioned way are labeled as \" in-valids \" and confined to the lower rung of society . \\nvincent freeman ( ethan hawke ) is one such person , born not too long before the genetic process was perfected and forced to grow up in a home with his petrie dish-molded younger brother anton . \\nfed up with being second-rate and enchanted by dreams of one day traveling through space , vincent leaves home and takes a janitorial position at the gattaca aerospace corporation . \\neveryday , he watches as \" superior \" folk make his fantasy a reality . \\ndetermined to do the same , vincent meets a dna broker ( tony shalhoub in a funny cameo ) who sells fake identities to in-valids . \\nhis counterpart for this scam is jerome morrow ( jude law ) , an ex-athlete left paralyzed in an accident and confined to a wheelchair for life . \\nfor a price and the promise of a caretaker , jerome supplies vincent with his identity , as well as blood , skin and urine samples for all of those pesky on-the-job tests and physical examinations -- this future is one where employees clock in by pricking their fingers instead of punching a time card . \\nbecause of his drastically improved status , vincent is quickly propelled to a high position in gattaca , and catches the eye of comely co-worker irene ( uma thurman ) on the way -- obsessed with her own minor heart defect , she\\'s enamored by his flawless persona she doesn\\'t know is a lie . \\nbut on the figurative eve of his upcoming planetary departure , the mission director is murdered . \\ntwo ardent detectives ( alan arkin and billy bathgate\\'s loren dean ) determine the killer is on the inside of gattaca , and the sole clue they find at the crime scene -- one of vincent\\'s eyelashes -- threatens to blow vincent\\'s cover and derail his goal . \\neven if \" gattaca \" were dramatically empty , it would still boast a sublime set of production credentials -- the film\\'s look is dazzling without ever being flashy . \\nfirst-time director/writer andrew niccol ( he also wrote the screenplay for the upcoming jim carrey drama \" the truman show \" ) demonstrates a keen eye for the stylish ; his collaboration with cinematographer slawomir idziak , production designer jan roelfs and costume designer colleen atwood result in a sophisticated composition that emanates classy , retro ambiance . \\nan opening credits sequence -- where skin , nail and hair fragments fall in slow-motion through a colored camera lens -- displays these combined talents uncannily . \\nniccol even utilizes voice-over narration ( a device almost always poorly-employed ) in an effective way . \\nwhen it comes to acting , the movie is also flawless . \\nethan hawke does magnificent work , proving his ability to carry a film and reaffirming his enormously high charisma level . \\nhis chemistry with thurman is a bit on the icy side , but needfully so , adding to the setting\\'s clinical chill . \\nas the bitter jerome , jude law has a star-making presence , and it\\'s his scenes with hawke that give the movie its fine emotional core . \\nin \" gattaca \" \\'s series of final shots , the fates of vincent and jerome are superimposed over each other , and the effect is sad , lyrical and beautiful . \\nthings get a little strange as the movie nears its climax , when vincent\\'s relationship with his brother comes back into view . \\nthe big dramatic culmination is a swim race , which is somewhat silly albeit beautifully photographed . \\nstill , the single most surprising aspect of gattaca is its use of backdrop -- it\\'s successful sci-fi without showy special effects , it\\'s a crisp thriller with character-driven thrills , it\\'s a futuristic fable without blood and guts . \\neven its murder mystery is relegated to a secondary subplot , ensuring that a smart story about smart people and smart science takes center stage . \\nalthough it\\'s portrayal of the upcoming century is grim , \" gattaca \" serves up one of the most thought-provoking societal forecasts ever depicted on film . \\n',\n",
              "       \"at the outset of swordfish , john travolta's gabriel shear is pontificating about the status of american cinema today . \\nbasically , he says , it boils down to a lack of imagination among the majority of writers . \\nhow ironic , as travolta seems to be describing his latest venture . \\nswordfish is loud , violent and amoral . \\nit has the audacity to justify murder and mayhem in the name of sustaining our way of life . \\nand how does travolta's gabriel plan to do this ? \\nby robbing billions from his own government and using the funds to out-terrorize terrorists . \\nswordfish is a very cynical movie . \\nit relies on an audience's perception of our leaders as ineffectual and duplicitous and on terrorists as non-human , faceless entities not worthy of compassion or consideration . \\nthe movie's plot is preposterous with enough illogical leaps that if the film ever slowed down , you'd actually see how ridiculous it all is . \\nthis is a live-action road runner cartoon , moving so quickly that it's over before you can catch your breath to ask any reasonable questions . \\nthe storyline revolves around super hacker stanley jobson ( hugh jackman ) , recruited by gabriel to crack the government's computer codes so gabriel can gather billions for his anti-terrorist campaign . \\ntalk about whacked-out patriotism . \\nmy objections to swordfish are many . \\nthe body count is high , but that is expected in a movie of this sort . \\nit's becoming a bore watching anonymous soldiers , police officers and government agents blown to bits . \\nanother example is the family dynamics between stanley , his 10-year-old daughter and his ex-wife . \\nstanley , though having served time in prison for hacking , is shown as a loving and caring father , forbidden by his ex to see his little girl . \\naudience animosity is immediately created for his former spouse by showing her as a drinker and smoker who also sometimes stars in her new husband's adult films . \\nthus when she is found murdered late in the movie , neither stanley nor his daughter are allowed any time to grieve . \\nin fact , subconsciously , many in the audience are probably glad she was killed . \\nthen there is the sequence involving one of gabriel's henchman holding a gun to the head of stanley's daughter to coerce the hacker to download the key computer program for gabriel . \\nchildren as pawns have become a most unwelcome clich ? in recent films . \\nthere is enough violence in the real world involving children without having to make them on-screen victims as well . \\nyea , it's only make believe , but that doesn't mean you have to tolerate it . \\ntravolta is cool , deadly charming and flamboyant as the near-crazy gabriel . \\nhis character is reminiscent of his villainous characterizations in broken arrow and face/off . \\njackman looks dour through most of the proceedings . \\nhis only moment of any depth comes when he finally is able to create the worm to get inside the government database . \\nhis sense of joy and accomplishment is one any computer whiz can appreciate . \\nhalle berry is decorative and lovely as gabriel's assistant , while don cheadle is given little to do as the head fbi agent hunting gabriel . \\nswordfish plays like a comic book with a larger-than-life character in gabriel . \\nviewers align themselves with him despite their uncertainty if he is hero or villain . \\nand maybe that is the movie's underlying flaw : there is no real hero to speak of , only those doing their upmost to survive . \\nand that is not enough . \\nthis is one swordfish that should have been thrown back in the water . \\n\",\n",
              "       ...,\n",
              "       'every year--every year at the festival , i wait for that film to come along , that one that just pulls me out of my seat , sticks its face up next to my nose , and roars \" sur-prise ! \" \\ninto my bewildered visage . \\nit\\'s almost always a surprise . \\nit sure as niflheim was this time . \\namazing grace and chuck is being advertised as a modern fairy tale , of a boy in montana who quits his little league team for a very unusual reason . \\nand , in the hands of anyone less careful than the creative staff of this film , it might very well be nothing more than a fairy tale , where we roll our eyes occasionally , smirk to ourselves , and maybe get a forced tear out of the eyes and a \" boy , i wish that could happen \" sigh out of the lips upon exiting the theater and tossing the empty pepsi cup into the trash . \\nanother e . t . \\nanother short circuit . \\nthis film floored me , for the simple reason that while it has a fairy tale concept , the rest of the film takes itself seriously enough , and presents itself well enough , to make it more of an american folk tale , with characters who are both icons and real people at the same time . \\namerica has always had its mythical heros , its paul bunyans and john waynes ; this film presents us with more general , but still universal , ideals : the honest , innocent children who have their own inner wisdom ; the athletes who seem to be amalgamations of courage , honor , and love for their respective sport ; the venerable elected official who leads with kindness and understanding , but has the grit to get things done when they need doin\\' ( does the latter sound familiar ? ) . \\namazing grace and chuck is a showcase for these characters , but it never leaves you with the feeling that it\\'s artificial , that it stands behind glass , or that any sharp breeze--or , more importantly , sharp thought--will shatter the wax facade of the panorama . \\nthis is a very sturdy scenario . \\nthe principals are always given dialogue , and always give performances--always ( it just blows me away ) -- which made them seem real , yet enforces their particular mythic role . \\nthe writer/producer , david field , seems to literally take all the \" yeah , but in real life , this would have happen \" thoughts you get in your head , sticks them in the movie and uses them to bend the plot around to his original heading , in a stronger way then before ! \\nastounding ! \\nhe uses obstacles to the plot to * enforce * it ! \\ni am truly impressed ( indeed , envious ) with the skill in which he wrote the story and screenplay ; it\\'s so very unusual , especially in a hollywood film . \\ni don\\'t want to give too much away , but the basic premise is that chuck ( joshua zuehlke ) , the little league pitcher , decides to give up baseball because of nuclear weapons . \\nhis decision begins an unlikely series of events that involve another athlete , a boston basketball player ( alex english ) , \" amazing \" grace smith , and , well , i\\'m leaving it at that because i wouldn\\'t spoil this film for you for the world . \\nlet me just say this , though : i am not recommending this film because i think it has a great message or because of any political positions it might imply . \\ni don\\'t give a rat\\'s ass for the political point-of-view this film expresses , one way or another ; i\\'m recommending you go see this film because , and only because , it\\'s an excellent story , told with excellence . \\nno , i don\\'t believe what happens in this film could happen in real life ; while i tend to believe the arms control policy of this country is stilted , i believe in careful negotiations , mutual verification , etc . screw what i think . \\nthe point is , this film is able to suspend my disbelief and tell a story that is one of the most finely crafted pieces of american dream i have ever seen on the movie screen . \\nthis is the natural and more--all the mythic qualities without the pretentiousness or the forced feeling of the conclusion , and a much better script to boot . \\nit carried me into the beliefs and ideals of my boyhood--and , more importantly , without any bumps or jolts that would snap me out of the trance with some hint of self-consciousness . \\nspecial kudos to : both zuehlke ( a real-life little league pitcher who was picked for the part ) and english ( a forward for the denver nuggets ) for their seamless personification of their characters ; jamie lee curtis , who takes a surprisingly small role and makes it exceedingly memorable as amazing\\'s manager and friend ; william l . peterson ( in a * big * change from his role in to live and die in l . a . ) as a father who shows principles without having to stand up and wave a flag doing it ; and gregory peck , as the guy we wish ronald reagan really was ( and who some numbskulls still probably think he is \\n',\n",
              "       'capsule : suprisingly more of a comedy than a straight action flick , which isn\\'t necessarily a bad thing . \\nnot exactly oscar caliber , but one helluva bullet-riddled good time . \\nextended review : you know , i remember when hitmen were evil , murderous scum . \\nalas , the times are a-changin\\' . \\nin a recent string of movies , hitmen are suddenly wise- cracking , fun-loving killers-with-hearts . \\nthis brings us to hong kong director kirk wong\\'s first american feature , the big hit . \\noddly enough , about the same time last year a similar film , grosse point blank , was released . \\nadvertised as a quirky comedy with hints of action , it turned out to have a suprising dosage of it . \\nthe big hit is quite the opposite . \\nit was hyped as \" the new film from producer john woo \" , so one would it expect lots of stylized killing and action . \\nhowever , there\\'s a sore lack of it , which is about the only thing wrong with the big hit . \\nthe film starts out with mel smiley and his cohorts doing a job on a white slaver . \\nmel , played by mark wahlberg in a dopey , milquetoast role , is a killing machine ; he flips , spins , even breakdances whilst popping caps . \\nsadly , he doesn\\'t get a chance to do much of it . \\nexcept for the beginning set piece and the last 20 twenty minutes or so , the film is in comedy mode . \\nthe action , at least what there is of it , is prime cut stuff . \\nwong , after numerous hong kong features , makes quite a nice u . s . debut . \\nhowever , his pacing is a bit off , with the action sequences only bookending the movie and not lasting long enough . \\nthey start off electrifying and fresh , but just kinda stop . \\nnormally , this would hamper a movie to the point of being unenjoyable . \\nluckily , we have ben ramsey\\'s screenplay , a bitingly funny piece of work . \\nthe only problem is there might be too much humor , one joke makes you laugh so hard you miss the next few . \\nsome of best gags include an oriental film maker down on his luck and one of mel\\'s hitmen pals that has just discovered onanism . \\nthe only problem is how some of the minor characters are handled , some being there only for a laugh , which sometimes works , sometimes doesn\\'t . \\noverall , the big hit may have it\\'s flaws , but it makes up for them in a stylishly directed , gut-wrenchingly funny joyride . \\ndefinately one of the better ways to spend two hours . \\n',\n",
              "       'i suppose an argument could be made that toy story is one of those films that didn\\'t need a sequel . \\nbeloved by kids and their parents , respected equally by mainstream america and geekish movie buffs , that first movie remains a landmark of recent history , the one that burst open the possibilities of computer animation and demonstrated through wild invention and giddy chutzpah just how complacent the disney animation machine had become in cranking out fluffy razzle-dazzle entertainment full of formula storytelling and banal songwriting . \\nif disney was embarrassed at being beaten at its own game ( toy story was a smash hit of unexpected proportions , and one that caught the merchandising end of the business unaware as demand for action figures far outstripped supply ) , it didn\\'t show , and as distributor and part-owner of the property , at least it had a piece of the action . \\ntoy story 2 was greenlighted as a direct-to-video project , disney\\'s standard tactic for milking a few more bucks out of hot franchises without expending the effort of developing a proper feature film . \\nas someone who doesn\\'t believe sequels are necessarily a bad thing ( granted , they usually are a bad thing , but that\\'s because they\\'re made for the wrong reasons ) , i had to wonder what in the world they were thinking . \\nfortunately , disney claimed to have been so knocked-out by early animation tests that they let pixar go full-speed ahead with a theatrical sequel . \\nlucky thing , too -- like the first movie , this one is a joy to behold on the big screen , and technically , it improves on its predecessor on just about every level . \\n ( from a business standpoint , the end credits show that the new creations are copyrighted by pixar , while the previous film\\'s elements are shared between pixar and disney , a sign of the production house\\'s new cachet in hollywood . ) \\nvisually , the main shortcoming of this fully computer-generated movie is that human figures are still rendered relatively poorly , making them look a little creepy . \\nfortunately , that eerie unreality fits in perfectly with the perspective of the movie , where the secret world of toys is more immediate , and arguably more attractive , than the world of the humans who surround them . \\nas before , the story is predicated on the premise that the toys scattered around the bedroom of a little boy named andy -- and , indeed , all the toys scattered around the bedrooms of all little children -- come to life in the child\\'s absence . \\nwhile the toys scamper about and chatter endlessly among themselves , the real joy of a toy\\'s life is to mean something to its owner . \\none of the subjects of this new film is the sadness of toys that have been broken or abandoned , left on a shelf to gather dust , and another is the sort of emotional limbo inhabited by toys that are mere prizes of covetous collectors . \\nmost often , those toys are packed away in dark spaces , safe from sunlight and humidity , and often they\\'re not even removed from their packaging . \\nimagine what a chip that would put on your shoulder , and you\\'ll understand the attitudes of the collector\\'s items that show up in this movie . \\nsheriff woody ( voiced by a note-perfect tom hanks ) , the longtime favorite among andy\\'s toys who was challenged in the previous go-round by the arrival of flashy-new-thing action figure buzz lightyear ( tim allen ) , suffers an injury early in the film , when andy tugs too hard on his arm and pulls a seam apart , revealing the stuffing inside . \\nthis accident catalyzes some uneasieness among the toys , who know too well that a broken toy is often a forgotten toy , and a forgotten toy is one that loses its reason for existence . \\nthose anxieties are crystallized when andy\\'s mom tears through his living room , collecting old toys for a yard sale . \\nand there\\'s an ironic twist to the tale , as woody winds up being stolen by an avid toy collector who needs exactly that quaint cowboy figure to complete a set that he hopes to sell to a japanese toy museum for a sizable sum . \\nthe rest of andy\\'s toys , who owe him quite a debt , resolve to rescue him . \\nthat this film manages to turn a box marked \" 25 cents \" into a symbol of doom , or to make its screed against the retention of collectible toys by wrongheaded profiteers fuel for a metaphysical dilemma , is a testament to its skill at metaphor , seamlessly translating the hopes and fears of our real world into that of the toys . \\noperating on this level of abstraction , toy story 2 tackles some mighty heavy issues without once preaching or veering into pretentiousness . \\n ( the worst i can say is that randy newman seems to have reserved his sappiest lyric in years for sarah mclachlan , who stops the movie cold by singing it at just about the halfway mark . ) \\nsometimes i think toy story 2 tries too hard . \\nthere\\'s somewhat less of the seat-of-the-pants loopiness that energized the first film , allowing it to surprise and excite on a near-constant basis , and more philosophizing about toys , collectors , the nature of happiness and the meaning of life . \\nwhile that leads to fewer bellylaughs , it does make way for more elaborate humor and an uncommonly ambitious reflexivity that asks the toys to consider their own status as commodities that move in and out of fashion . \\n ( just don\\'t ask why andy\\'s favorite toy is based on a tv series that was canceled in 1957 . ) \\nwhere else in mainstream movies do you get such an awesome moment as the one where buzz arrives at al\\'s toy barn to find it stocked to the gills with his doppelgangers , buzz lightyear action figures ? \\nforget the self-congratulatory science fiction of the matrix -- this is a fundamental mind-bender for buzz , and the audience shares his humility and wonderment at the sight . \\nhere , as in the roughly concurrent scene where woody watches tapes of the howdy doodyish children\\'s tv show that originated his character , we see our protagonists come face-to-face with god . \\nin sly ways , then , toy story 2 can be read as a film about mortality , a metaphorical consideration of aging and death . \\nsignificantly , the film\\'s very first sequence concludes with a grim shocker that had our opening-night crowd in a near-uproar . \\nand toward the end , when buzz and woody speculate on how long they have before andy grows up and discards his old toys , one of them observes , with an alacrity both inspirational and heartbreaking , that it will be fun while it lasts . \\nso toy story 2 joins the tradition of children\\'s stories , largely neglected of late , that say something real about the inevitable joys and tragedies of existence . \\nwhat\\'s really striking is that both toy story films ( and , to a lesser degree , pixar\\'s a bug\\'s life ) are kids\\' movies with wit and sophistication to shame most of their ostensibly adult counterparts , not to mention whatever piece of tot-friendly eye-candy is due from the disney dream factory any given summer . \\nit puts one in mind of the glory days of chuck jones and the old gang at warner bros . animation . \\ni\\'m not sure lasseter and his pals at pixar will ever operate at quite that level of purely visual invention -- they love traditional narrative too much -- but , boy , it makes me wonder what they might come up with next . \\n-------------------------------------------------------------- directed by john lasseter , colin brady , ash brannon , and lee unkrich written by lasseter , brannon , peter docter , andrew stanton , rita hsaio , doug chamberlain , and chris webb cinematography by sharon calahan starring ( voices ) tom hanks , tim allen , and joan cusack usa , 1999 \\ntheatrical aspect ratio : 1 . 85 : 1 -------------------------------------------------------------- \\n'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "xXCkmVlxsKo7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho1uGwLFfjm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "444a8546-de49-4c77-fe6a-2bf19cea31fb"
      },
      "source": [
        "# Usando el tokenizer de Keras\n",
        "tokenizer = Tokenizer(num_words=None)  # Puedes ajustar num_words si deseas limitar el tamaño del vocabulario\n",
        "\n",
        "# Ajustar el tokenizer a los textos de entrenamiento y validación\n",
        "tokenizer.fit_on_texts(list(xtrain) + list(xvalid))\n",
        "\n",
        "# Convertir los textos a secuencias de enteros\n",
        "xtrain_seq = tokenizer.texts_to_sequences(xtrain)\n",
        "xvalid_seq = tokenizer.texts_to_sequences(xvalid)\n",
        "xtest_seq = tokenizer.texts_to_sequences(xtest)\n",
        "\n",
        "# Aplicar padding a las secuencias\n",
        "xtrain_pad = pad_sequences(xtrain_seq, maxlen=max_len, padding='post')\n",
        "xvalid_pad = pad_sequences(xvalid_seq, maxlen=max_len, padding='post')\n",
        "xtest_pad = pad_sequences(xtest_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "# Obtener el índice de palabras del tokenizer\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Verificar los resultados\n",
        "print(f\"Tokenizador ajustado con {len(word_index)} palabras únicas.\")\n",
        "print(f\"Ejemplo de secuencia paddeada (xtrain_pad[0]): {xtrain_pad[0]}\")\n",
        "print(f\"Forma de xtrain_pad: {xtrain_pad.shape}\")\n",
        "print(f\"Forma de xvalid_pad: {xvalid_pad.shape}\")\n",
        "print(f\"Forma de xtest_pad: {xtest_pad.shape}\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizador ajustado con 39363 palabras únicas.\n",
            "Ejemplo de secuencia paddeada (xtrain_pad[0]): [3064 5759  471 ...    0    0    0]\n",
            "Forma de xtrain_pad: (1200, 2700)\n",
            "Forma de xvalid_pad: (400, 2700)\n",
            "Forma de xtest_pad: (400, 2700)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_pad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QIfNxgRo34F",
        "outputId": "2d99c0de-961a-45e5-f7ce-120ece6163b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 112,   99, 7160, ...,    0,    0,    0],\n",
              "       [3862,  328,  942, ...,    0,    0,    0],\n",
              "       [  17,   30,    2, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [4326,    6,   76, ...,    0,    0,    0],\n",
              "       [  11,    2,  448, ...,    0,    0,    0],\n",
              "       [  17,  123,  120, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Convertir etiquetas de texto a enteros\n",
        "label_encoder = LabelEncoder()\n",
        "ytrain_encoded = label_encoder.fit_transform(ytrain)\n",
        "yvalid_encoded = label_encoder.transform(yvalid)\n",
        "ytest_encoded = label_encoder.transform(ytest)\n",
        "\n",
        "# Convertir los enteros a representación one-hot\n",
        "ytrain_one_hot = to_categorical(ytrain_encoded)\n",
        "yvalid_one_hot = to_categorical(yvalid_encoded)\n",
        "ytest_one_hot = to_categorical(ytest_encoded)\n",
        "\n",
        "# Verificar las formas de los arrays one-hot\n",
        "print(f\"Forma de ytrain_one_hot: {ytrain_one_hot.shape}\")\n",
        "print(f\"Forma de yvalid_one_hot: {yvalid_one_hot.shape}\")\n",
        "print(f\"Forma de ytest_one_hot: {ytest_one_hot.shape}\")\n",
        "\n",
        "# Opcional: Verificar los primeros ejemplos de etiquetas one-hot\n",
        "print(\"Ejemplo de etiquetas one-hot (ytrain_one_hot[0]):\")\n",
        "print(ytrain_one_hot[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgJPgPIxsphI",
        "outputId": "8d8ee749-9f46-45bc-a5eb-1ded2c38f634"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de ytrain_one_hot: (1200, 2)\n",
            "Forma de yvalid_one_hot: (400, 2)\n",
            "Forma de ytest_one_hot: (400, 2)\n",
            "Ejemplo de etiquetas one-hot (ytrain_one_hot[0]):\n",
            "[0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNxvBuDwhscW"
      },
      "source": [
        "En una RNN ingresamos una review palabra por palabra. Representamos cada palabra como un vector utilizando la técnica del one hot encoding. El vector va a tener cantidad de palabras en el vocabulario + 1 domensiones.\n",
        "\n",
        "Lo que hace keras Tokenizer es, toma todas las palabras únicas en el corpus, forma un diccionario con palabras como claves y su número de ocurrencias como valores (es el word_index), luego ordena el diccionario en orden descendente de conteos.\n",
        "\n",
        "Luego asigna a la primer palabra el valor 1, a la segunda el valor 2 y así sucesivamente.\n",
        "\n",
        "Así que supongamos que la palabra 'que' es la que se repite más en todas las canciones, a esa se le asignará el índice 1 y el vector que representa la palabra 'que' sería un vector one-hot con valor 1 en la posición 1 y resto ceros.\n",
        "\n",
        "La primera línea del modelo \"Sequential()\" le dice a Keras que construiremos nuestra red secuencialmente.\n",
        "\n",
        "Luego, primero agregamos la capa de incrustación. La capa de Embedding que es también una capa de neuronas que toma como entrada el vector one-hot n-ésimo de cada palabra y lo convierte en un vector de 300 dimensiones, nos da el enbeddubg de palabras similar a word2vec. Podríamos haber utilizado word2vec, pero la capa de Embedding aprende durante el entrenamiento para mejorar la forma de embeddear.\n",
        "\n",
        "A continuación, agregamos 100 unidades LSTM sin ningún dropout ni regularización.\n",
        "\n",
        "Por último, agregamos 5 neuronas (ya que tenemos 5 posibles clases) con función sigmoidea que toma la salida de las 100 células LSTM (tener en cuenta que tenemos 100 células LSTM, no capas) para predecir los resultados y luego compilamos el modelo usando adam optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd-FgV_L1xqr"
      },
      "source": [
        "# RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihmy2k5s1xYY",
        "outputId": "f67cfb4e-61ca-4bab-f6ed-0bc0e4a0aae0"
      },
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    # A simpleRNN without any pretrained embeddings and one dense layer\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1,#Cantidad de palabras distintas del corpus\n",
        "                     300,#tamaño del vector con el que va a encodear cada palabra (del 1-hot lo pasa a un vector de 300 dimensiones)\n",
        "                     input_length=max_len)) #El máximo de palabras que puede tener una canción.\n",
        "    model.add(SimpleRNN(100))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(20, activation='relu'))\n",
        "    model.add(Dense(2, activation='sigmoid'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 2700, 300)         11829000  \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 100)               40100     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                1020      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 42        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11875212 (45.30 MB)\n",
            "Trainable params: 11875212 (45.30 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "CPU times: user 400 ms, sys: 200 ms, total: 600 ms\n",
            "Wall time: 990 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=64, validation_data=(xvalid_pad, yvalid_one_hot))\n",
        "\n",
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DLI2Ojovv1t",
        "outputId": "a763ca93-1f73-4e39-8400-1115dfb171c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 111s 6s/step - loss: 0.7034 - accuracy: 0.4900 - val_loss: 0.6932 - val_accuracy: 0.5400\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 96s 5s/step - loss: 0.7021 - accuracy: 0.4858 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 122s 6s/step - loss: 0.6953 - accuracy: 0.5292 - val_loss: 0.7042 - val_accuracy: 0.5075\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 103s 5s/step - loss: 0.7001 - accuracy: 0.4942 - val_loss: 0.7030 - val_accuracy: 0.4725\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 104s 6s/step - loss: 0.6977 - accuracy: 0.4858 - val_loss: 0.7011 - val_accuracy: 0.5050\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 104s 5s/step - loss: 0.7002 - accuracy: 0.4908 - val_loss: 0.6988 - val_accuracy: 0.4700\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 107s 6s/step - loss: 0.7018 - accuracy: 0.4858 - val_loss: 0.6940 - val_accuracy: 0.5125\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 107s 6s/step - loss: 0.7047 - accuracy: 0.4883 - val_loss: 0.6886 - val_accuracy: 0.5300\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 100s 5s/step - loss: 0.7000 - accuracy: 0.5025 - val_loss: 0.7064 - val_accuracy: 0.4900\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 103s 5s/step - loss: 0.7016 - accuracy: 0.4850 - val_loss: 0.6944 - val_accuracy: 0.4800\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 104s 5s/step - loss: 0.6970 - accuracy: 0.4942 - val_loss: 0.6872 - val_accuracy: 0.5625\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 106s 6s/step - loss: 0.6977 - accuracy: 0.4908 - val_loss: 0.6966 - val_accuracy: 0.4825\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 110s 6s/step - loss: 0.6968 - accuracy: 0.5058 - val_loss: 0.6968 - val_accuracy: 0.4875\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 98s 5s/step - loss: 0.6963 - accuracy: 0.5042 - val_loss: 0.6944 - val_accuracy: 0.5325\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 98s 5s/step - loss: 0.6979 - accuracy: 0.4933 - val_loss: 0.6919 - val_accuracy: 0.5225\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 100s 5s/step - loss: 0.6978 - accuracy: 0.5042 - val_loss: 0.6972 - val_accuracy: 0.4850\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 101s 5s/step - loss: 0.6987 - accuracy: 0.4925 - val_loss: 0.7011 - val_accuracy: 0.4650\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 94s 5s/step - loss: 0.6941 - accuracy: 0.5233 - val_loss: 0.6933 - val_accuracy: 0.5075\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 101s 5s/step - loss: 0.6964 - accuracy: 0.4825 - val_loss: 0.6991 - val_accuracy: 0.5100\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 98s 5s/step - loss: 0.6996 - accuracy: 0.4842 - val_loss: 0.6950 - val_accuracy: 0.4900\n",
            "13/13 [==============================] - 7s 537ms/step\n",
            "Accuracy: 0.49\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.49      0.69      0.57       200\n",
            "    positive       0.48      0.29      0.37       200\n",
            "\n",
            "    accuracy                           0.49       400\n",
            "   macro avg       0.49      0.49      0.47       400\n",
            "weighted avg       0.49      0.49      0.47       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8XfnnlZXyP7f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uViGkPDPpP8"
      },
      "source": [
        "# Convolutional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Crear el modelo CNN\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1, 300, input_length=max_len))\n",
        "model.add(Conv1D(128, 5, activation=\"relu\"))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Conv1D(128, 5, activation=\"relu\"))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Conv1D(128, 5, activation=\"relu\"))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))  # Ajustar el número de unidades a 2\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=64, validation_data=(xvalid_pad, yvalid_one_hot))\n",
        "\n",
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDhAosPp9NpT",
        "outputId": "f31eae06-86e8-4086-f9ba-7dd1be2140bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 2700, 300)         11829000  \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 2696, 128)         192128    \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 539, 128)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 535, 128)          82048     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 107, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 103, 128)          82048     \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 128)               0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12201994 (46.55 MB)\n",
            "Trainable params: 12201994 (46.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "19/19 [==============================] - 144s 7s/step - loss: 0.7006 - accuracy: 0.5000 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 138s 7s/step - loss: 0.6952 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 128s 7s/step - loss: 0.6919 - accuracy: 0.5142 - val_loss: 0.6929 - val_accuracy: 0.5250\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 118s 6s/step - loss: 0.6849 - accuracy: 0.6125 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 121s 6s/step - loss: 0.6458 - accuracy: 0.7342 - val_loss: 0.6707 - val_accuracy: 0.5100\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 129s 7s/step - loss: 0.4074 - accuracy: 0.8817 - val_loss: 0.5448 - val_accuracy: 0.7225\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 123s 7s/step - loss: 0.0467 - accuracy: 0.9925 - val_loss: 0.5697 - val_accuracy: 0.7875\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 120s 6s/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 0.8476 - val_accuracy: 0.7350\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 132s 7s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8171 - val_accuracy: 0.7700\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 130s 7s/step - loss: 5.9710e-04 - accuracy: 1.0000 - val_loss: 0.7309 - val_accuracy: 0.7900\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 130s 7s/step - loss: 3.2745e-04 - accuracy: 1.0000 - val_loss: 0.7632 - val_accuracy: 0.7925\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 119s 6s/step - loss: 2.2997e-04 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.7875\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 129s 7s/step - loss: 5.1060e-04 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.7775\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 119s 6s/step - loss: 1.6603e-04 - accuracy: 1.0000 - val_loss: 0.8294 - val_accuracy: 0.7750\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 128s 7s/step - loss: 1.9484e-04 - accuracy: 1.0000 - val_loss: 0.8569 - val_accuracy: 0.7725\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 128s 7s/step - loss: 1.0792e-04 - accuracy: 1.0000 - val_loss: 0.8716 - val_accuracy: 0.7750\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 119s 6s/step - loss: 6.7888e-05 - accuracy: 1.0000 - val_loss: 0.8701 - val_accuracy: 0.7750\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 130s 7s/step - loss: 5.9871e-05 - accuracy: 1.0000 - val_loss: 0.8787 - val_accuracy: 0.7750\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 119s 6s/step - loss: 1.7953e-04 - accuracy: 1.0000 - val_loss: 0.8754 - val_accuracy: 0.7775\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 129s 7s/step - loss: 8.9998e-05 - accuracy: 1.0000 - val_loss: 0.8722 - val_accuracy: 0.7800\n",
            "13/13 [==============================] - 10s 765ms/step\n",
            "Accuracy: 0.78\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.77      0.78       200\n",
            "    positive       0.77      0.79      0.78       200\n",
            "\n",
            "    accuracy                           0.78       400\n",
            "   macro avg       0.78      0.78      0.78       400\n",
            "weighted avg       0.78      0.78      0.78       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/drive/MyDrive/pretrainedwordvectorsforspanish/cc.es.300.vec.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvptzE9BoBhv",
        "outputId": "251e9b5a-7da0-42c2-f5b2-a4f054673c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-02 22:44:54--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.156.133.37, 108.156.133.4, 108.156.133.117, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.156.133.37|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1285580896 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘/content/drive/MyDrive/pretrainedwordvectorsforspanish/cc.es.300.vec.gz’\n",
            "\n",
            "/content/drive/MyDr 100%[===================>]   1.20G  23.7MB/s    in 53s     \n",
            "\n",
            "2024-07-02 22:45:48 (23.0 MB/s) - ‘/content/drive/MyDrive/pretrainedwordvectorsforspanish/cc.es.300.vec.gz’ saved [1285580896/1285580896]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Descargar Embeddings de FastText en Español"
      ],
      "metadata": {
        "id": "CYbG7P98oYnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip /content/drive/MyDrive/pretrainedwordvectorsforspanish/cc.es.300.vec.gz\n"
      ],
      "metadata": {
        "id": "Y2OHy8Y-pfFE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351c47a7-686b-421f-b644-d11044c5ac01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: /content/drive/MyDrive/pretrainedwordvectorsforspanish/cc.es.300.vec already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 1: Descargar Embeddings de GloVe en Inglés"
      ],
      "metadata": {
        "id": "5MlHg-DhoUDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip -P /content/\n",
        "!unzip /content/glove.6B.zip -d /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64UGE_1joRj3",
        "outputId": "5fa681a0-3b93-4d11-af8f-b954240ae98d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-04 11:29:05--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-07-04 11:29:06--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-07-04 11:29:06--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘/content/glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2024-07-04 11:31:46 (5.18 MB/s) - ‘/content/glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  /content/glove.6B.zip\n",
            "  inflating: /content/glove.6B.50d.txt  \n",
            "  inflating: /content/glove.6B.100d.txt  \n",
            "  inflating: /content/glove.6B.200d.txt  \n",
            "  inflating: /content/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Ruta al archivo de embeddings de GloVe\n",
        "glove_file = '/content/glove.6B.300d.txt'\n",
        "\n",
        "# Verificar si el archivo existe en la ruta especificada\n",
        "if os.path.exists(glove_file):\n",
        "    print(\"El archivo se ha encontrado correctamente.\")\n",
        "\n",
        "    # Cargar los embeddings de GloVe\n",
        "    def cargar_embeddings(file_path):\n",
        "        embeddings_index = {}\n",
        "        with open(file_path, encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                values = line.split()\n",
        "                word = values[0]\n",
        "                coefs = np.asarray(values[1:], dtype='float32')\n",
        "                embeddings_index[word] = coefs\n",
        "        return embeddings_index\n",
        "\n",
        "    wordvectors = cargar_embeddings(glove_file)  # Definimos wordvectors aquí\n",
        "    print(\"Embeddings de GloVe cargados exitosamente.\")\n",
        "else:\n",
        "    print(\"El archivo no se encuentra en la ruta especificada.\")\n",
        "\n",
        "# Crear una matriz de embeddings\n",
        "embedding_dim = 300\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = wordvectors.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25), embedding_dim)\n",
        "\n",
        "print(\"Matriz de embeddings creada exitosamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqIOW8YRimY5",
        "outputId": "95bf345c-b238-4389-e1f7-573bd907cdae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El archivo se ha encontrado correctamente.\n",
            "Embeddings de GloVe cargados exitosamente.\n",
            "Matriz de embeddings creada exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"movie\"\n",
        "if word in wordvectors:\n",
        "    vector = wordvectors[word]\n",
        "    print(f\"Vector for '{word}': {vector}\")\n",
        "else:\n",
        "    print(f\"'{word}' not found in word vectors\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7VJQtUPjDbw",
        "outputId": "f7eb183b-d854-47d1-e5ad-b1194721bb04"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'movie': [-0.138     -0.12203    0.0054643 -0.010215   0.13134    0.28616\n",
            " -0.36436   -0.035735  -0.17218   -0.38864    0.58637    0.13189\n",
            " -0.1513     0.35515   -0.34298   -0.54394   -0.40302   -0.17129\n",
            "  0.19899    0.24317    0.21332    0.60335    0.22556    0.46382\n",
            "  0.064101   0.36409    0.25328   -0.79771    0.26771    0.42462\n",
            " -0.62075    0.31208   -0.25316    0.13562   -1.1323     0.0099104\n",
            " -0.62471   -0.048047   0.23139    0.16102    0.24774   -0.26149\n",
            " -0.17341    0.34005    0.21511   -0.26714    0.45698   -0.13671\n",
            "  0.11654   -0.12222    0.062068  -0.45585   -0.30115    0.11208\n",
            "  0.31146   -0.048065   0.10067    0.1441     0.27139   -0.17809\n",
            " -0.41069    0.093994   0.499      0.023845   0.42438   -0.027703\n",
            "  0.044485  -0.15928    0.45054    0.13142    0.19913    0.36483\n",
            "  0.26074    0.55475    0.47258   -0.43104    0.23181   -0.177\n",
            "  0.21771   -0.37325   -0.15304   -0.45237    0.68007   -0.15976\n",
            " -0.094521   0.6455     0.10443   -0.19616    0.027374  -0.24713\n",
            " -0.24108    0.24404   -0.0066751 -0.055555  -0.13255    0.28159\n",
            "  0.10104    0.26669   -0.20363   -1.2499     0.17955    0.16492\n",
            "  0.29046    0.078206   0.36391    0.1972    -0.38922   -0.08842\n",
            "  0.36837   -0.46351   -0.05688    0.23692    0.25946   -0.0092949\n",
            "  0.55123    0.18405   -0.070915  -0.12583   -0.33538   -0.6216\n",
            "  0.10658   -0.04339    0.054995   0.46283    0.088233   0.051282\n",
            "  0.30242    0.045697  -0.30009    0.086718  -0.075517   0.10886\n",
            " -0.018905   0.11489    0.30604   -0.014883  -0.20549   -0.11995\n",
            " -0.57362    0.71357   -0.0056715 -0.11205   -0.32318   -0.058222\n",
            " -0.36446   -0.68901    0.07647   -0.027654  -0.080254  -0.22787\n",
            "  0.35799   -0.21695   -0.20211   -0.23662    0.58239    0.12348\n",
            "  0.053221   0.21873   -0.11821    0.11212    0.79703   -0.30937\n",
            "  0.2063    -0.17314    0.01498    0.76045    0.075878   0.047252\n",
            " -0.35795    0.30923   -0.082989  -0.30638   -1.6971     0.055546\n",
            "  0.089201   0.38312   -0.33247   -0.13426   -0.049802  -0.41536\n",
            " -0.13256   -0.066477  -0.18845    0.17874    0.19334   -0.22544\n",
            "  0.023197  -0.3343     0.21699   -0.16357   -0.3338    -0.15258\n",
            " -0.27453   -0.2123    -0.38512   -0.39829   -0.7472     0.19218\n",
            " -0.15262   -0.26095    1.9506    -0.30508    0.11658    0.01811\n",
            "  0.3887     0.02532   -0.073168   0.08531   -0.26947   -0.4158\n",
            " -0.5256    -0.3618     0.1364     0.14176    0.080273   0.31376\n",
            "  0.12755    0.1358     0.25489    0.33135   -0.75425   -0.10576\n",
            "  0.036561  -0.15502   -0.41141   -0.1202     0.27146   -0.44042\n",
            " -0.2921    -0.11905    0.62502   -0.27724   -0.59458   -0.31237\n",
            "  0.30283    0.28397    0.75238   -0.12298   -0.32536    0.12182\n",
            "  0.40979    0.15839   -0.26725   -0.21228   -0.51142   -0.34827\n",
            " -0.42788   -0.10433   -0.58671    0.26117   -0.021263  -0.16688\n",
            " -0.42097    1.0059     0.23808   -0.80147    0.3903    -0.34794\n",
            "  0.54537   -0.14279    0.17518   -0.083995   0.13864   -0.36321\n",
            "  0.44686   -0.18776    0.17833   -0.19966    0.53591    0.57662\n",
            "  0.54154   -0.10555   -0.27472    0.11733    0.22361    0.32645\n",
            " -1.6279    -0.14297   -0.010648  -0.62519   -0.037267  -0.35863\n",
            "  0.023786  -0.059398  -0.10813    0.59328   -0.11333   -0.1525\n",
            " -0.14136    0.67566    0.11331    0.15394   -0.3226     0.017754\n",
            " -0.97518    0.021112  -0.15476    0.19934    0.057473  -0.023767 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame para visualizar la matriz de embeddings\n",
        "# Seleccionar las primeras 10 filas para visualizar\n",
        "embedding_df = pd.DataFrame(embedding_matrix[:10], columns=[f\"dim_{i}\" for i in range(embedding_dim)])\n",
        "print(embedding_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p73uTho5pg3I",
        "outputId": "edf7057a-2024-4cfc-f134-210076708579"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      dim_0     dim_1     dim_2    dim_3     dim_4     dim_5     dim_6  \\\n",
            "0  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
            "1  0.046560  0.213180 -0.007436 -0.45854 -0.035639  0.236430 -0.288360   \n",
            "2 -0.297120  0.094049 -0.096662 -0.34400 -0.184830 -0.123290 -0.116560   \n",
            "3  0.038466 -0.039792  0.082747 -0.38923 -0.214310  0.170200 -0.025657   \n",
            "4 -0.076947 -0.021211  0.212710 -0.72232 -0.139880 -0.122340 -0.175210   \n",
            "5 -0.257560 -0.057132 -0.671900 -0.38082 -0.364210 -0.082155 -0.010955   \n",
            "6 -0.174900  0.229560  0.249240 -0.20512 -0.122940  0.021297 -0.238150   \n",
            "7 -0.443990  0.128170 -0.252470 -0.18582 -0.166140  0.259090 -0.226780   \n",
            "8 -0.182560  0.498510 -0.163900 -0.17443 -0.163820 -0.044109  0.279570   \n",
            "9  0.033284 -0.040754 -0.048377  0.12017 -0.139150 -0.176940 -0.062908   \n",
            "\n",
            "      dim_7     dim_8   dim_9  ...   dim_290   dim_291   dim_292   dim_293  \\\n",
            "0  0.000000  0.000000  0.0000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "1  0.215210 -0.134860 -1.6413  ... -0.013064 -0.296860 -0.079913  0.195000   \n",
            "2 -0.099692  0.172650 -1.6386  ...  0.075972 -0.424260 -0.396700  0.326830   \n",
            "3  0.095780  0.238600 -1.6342  ...  0.045194 -0.204050 -0.210970 -0.110250   \n",
            "4  0.121370 -0.070866 -1.5721  ... -0.366730 -0.386030  0.302900  0.015747   \n",
            "5 -0.082047  0.460560 -1.8477  ... -0.012806 -0.597070  0.317340 -0.252670   \n",
            "6  0.137370 -0.089130 -2.0607  ...  0.313570 -0.134070  0.184650  0.234260   \n",
            "7 -0.069229 -0.077204 -1.5814  ... -0.274500 -0.037237  0.101040  0.107980   \n",
            "8  0.066851  0.122980 -2.4794  ... -0.082465 -0.232410  0.022031  0.354450   \n",
            "9  0.170560  0.200770 -2.4287  ...  0.091222 -0.402000  0.154300  0.230990   \n",
            "\n",
            "    dim_294   dim_295   dim_296   dim_297   dim_298   dim_299  \n",
            "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "1  0.031549  0.285060 -0.087461  0.009061 -0.209890  0.053913  \n",
            "2  0.620490  0.347190  0.269520  0.059717 -0.228530  0.296020  \n",
            "3  0.021766  0.441290  0.327970 -0.334270  0.011807  0.059703  \n",
            "4  0.340360  0.478410  0.068617  0.183510 -0.291830 -0.046533  \n",
            "5  0.543840  0.063007 -0.049795 -0.160430  0.046744 -0.070621  \n",
            "6  0.076272  0.105020  0.215210 -0.241310 -0.404020  0.054744  \n",
            "7  0.377270  0.879770  0.335830 -0.200430 -0.082191 -0.062550  \n",
            "8  0.172210  0.018176  0.038145 -0.272240 -0.191070 -0.094104  \n",
            "9  0.086138 -0.002428  0.065196 -0.154080  0.178060 -0.196830  \n",
            "\n",
            "[10 rows x 300 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame para visualizar la matriz de embeddings\n",
        "# Seleccionar las primeras 10 palabras para visualizar\n",
        "palabras = list(word_index.keys())[:10]\n",
        "vectores = embedding_matrix[:10]\n",
        "\n",
        "# Crear un DataFrame\n",
        "embedding_df = pd.DataFrame(vectores, index=palabras, columns=[f\"dim_{i}\" for i in range(embedding_dim)])\n",
        "print(embedding_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MixXJeOZhnd9",
        "outputId": "59eaf85a-2e78-4c36-94ed-736584e848cb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         dim_0     dim_1     dim_2    dim_3     dim_4     dim_5     dim_6  \\\n",
            "the   0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
            "a     0.046560  0.213180 -0.007436 -0.45854 -0.035639  0.236430 -0.288360   \n",
            "and  -0.297120  0.094049 -0.096662 -0.34400 -0.184830 -0.123290 -0.116560   \n",
            "of    0.038466 -0.039792  0.082747 -0.38923 -0.214310  0.170200 -0.025657   \n",
            "to   -0.076947 -0.021211  0.212710 -0.72232 -0.139880 -0.122340 -0.175210   \n",
            "is   -0.257560 -0.057132 -0.671900 -0.38082 -0.364210 -0.082155 -0.010955   \n",
            "in   -0.174900  0.229560  0.249240 -0.20512 -0.122940  0.021297 -0.238150   \n",
            "that -0.443990  0.128170 -0.252470 -0.18582 -0.166140  0.259090 -0.226780   \n",
            "it   -0.182560  0.498510 -0.163900 -0.17443 -0.163820 -0.044109  0.279570   \n",
            "as    0.033284 -0.040754 -0.048377  0.12017 -0.139150 -0.176940 -0.062908   \n",
            "\n",
            "         dim_7     dim_8   dim_9  ...   dim_290   dim_291   dim_292   dim_293  \\\n",
            "the   0.000000  0.000000  0.0000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "a     0.215210 -0.134860 -1.6413  ... -0.013064 -0.296860 -0.079913  0.195000   \n",
            "and  -0.099692  0.172650 -1.6386  ...  0.075972 -0.424260 -0.396700  0.326830   \n",
            "of    0.095780  0.238600 -1.6342  ...  0.045194 -0.204050 -0.210970 -0.110250   \n",
            "to    0.121370 -0.070866 -1.5721  ... -0.366730 -0.386030  0.302900  0.015747   \n",
            "is   -0.082047  0.460560 -1.8477  ... -0.012806 -0.597070  0.317340 -0.252670   \n",
            "in    0.137370 -0.089130 -2.0607  ...  0.313570 -0.134070  0.184650  0.234260   \n",
            "that -0.069229 -0.077204 -1.5814  ... -0.274500 -0.037237  0.101040  0.107980   \n",
            "it    0.066851  0.122980 -2.4794  ... -0.082465 -0.232410  0.022031  0.354450   \n",
            "as    0.170560  0.200770 -2.4287  ...  0.091222 -0.402000  0.154300  0.230990   \n",
            "\n",
            "       dim_294   dim_295   dim_296   dim_297   dim_298   dim_299  \n",
            "the   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "a     0.031549  0.285060 -0.087461  0.009061 -0.209890  0.053913  \n",
            "and   0.620490  0.347190  0.269520  0.059717 -0.228530  0.296020  \n",
            "of    0.021766  0.441290  0.327970 -0.334270  0.011807  0.059703  \n",
            "to    0.340360  0.478410  0.068617  0.183510 -0.291830 -0.046533  \n",
            "is    0.543840  0.063007 -0.049795 -0.160430  0.046744 -0.070621  \n",
            "in    0.076272  0.105020  0.215210 -0.241310 -0.404020  0.054744  \n",
            "that  0.377270  0.879770  0.335830 -0.200430 -0.082191 -0.062550  \n",
            "it    0.172210  0.018176  0.038145 -0.272240 -0.191070 -0.094104  \n",
            "as    0.086138 -0.002428  0.065196 -0.154080  0.178060 -0.196830  \n",
            "\n",
            "[10 rows x 300 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representar_review_como_vector(review):\n",
        "    palabras = review.split()\n",
        "    vectores = np.zeros(300)  # Suponiendo que los embeddings tienen 300 dimensiones\n",
        "    palabras_encontradas = 0\n",
        "    for palabra in palabras:\n",
        "        try:\n",
        "            vector = wordvectors[palabra]\n",
        "            vectores = vectores + vector\n",
        "            palabras_encontradas = palabras_encontradas + 1\n",
        "        except KeyError:\n",
        "            print(\"No está la palabra \" + palabra)\n",
        "\n",
        "    if palabras_encontradas > 0:\n",
        "        promedio = vectores / palabras_encontradas\n",
        "    else:\n",
        "        promedio = vectores\n",
        "    return vectores, promedio\n"
      ],
      "metadata": {
        "id": "NKbZGSFAjRYI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"The movie was fantastic with great performances\"\n",
        "suma_vectores, promedio_vector = representar_review_como_vector(review)\n",
        "\n",
        "print(\"Suma de vectores:\", suma_vectores)\n",
        "print(\"Promedio de vector:\", promedio_vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urijd9adh9oD",
        "outputId": "f3d01f5a-0576-4e26-db37-87c076278707"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No está la palabra The\n",
            "Suma de vectores: [ 0.40194301  0.27216901  0.25342232 -1.239327    0.42250501  0.77834221\n",
            " -0.89730999 -0.09869419 -0.47823    -6.27481988  1.74771097  0.33666203\n",
            " -1.21395398  1.73060001 -0.87205403 -0.28724001 -0.671101    0.55715703\n",
            " -0.203493    0.51512298  0.07460097  1.34675997 -0.314656    1.5147994\n",
            "  0.234901    0.711936   -0.33728396 -1.50191233  0.91382099  1.02284802\n",
            " -0.57832701  0.45908001 -2.06607398  0.29664103 -6.47114003 -0.18947361\n",
            " -0.69258002  1.90620304  0.79380701  0.29453272 -0.73650301 -1.815127\n",
            " -0.50513499  0.32695003  1.19733     1.89346004  1.51674299  1.39860998\n",
            "  0.424275    0.05463     0.71797101 -0.964288   -0.85394699  0.07967199\n",
            "  0.10442099  1.65419494  0.45152101  1.69516997  2.07254399 -0.08804101\n",
            "  0.12355602 -0.11186601  1.61630002 -0.62362401  0.28783797 -0.66621302\n",
            "  0.72669702 -0.60223998  0.33667501  0.08499102 -0.53619501  0.02752199\n",
            " -0.13570798  0.86813002 -0.52545512 -0.67260298  0.98725199  0.81894898\n",
            "  0.15235002  0.098774   -0.68254599  0.03923202  2.25511996 -0.16955498\n",
            "  0.877849    1.98650002  0.78143102  0.04902697  1.45970819 -0.60615002\n",
            "  0.139767    0.33857399 -0.42907109 -0.25998701  0.15557101 -0.39383999\n",
            "  0.62944245 -0.62342303 -0.46362699 -2.598897   -0.34405078  0.6831638\n",
            " -0.21881902 -0.99869198  0.481019    0.34122699 -0.312448    0.86754096\n",
            " -0.66449601 -0.69265101  0.200502    0.09015202  0.90539201 -0.44293091\n",
            "  1.53369802 -1.00941401 -0.88411202  0.40522601  0.03792    -2.56117997\n",
            " -0.49163001 -0.22740262 -0.02479099  0.53831099  0.42749001 -0.77842801\n",
            " -0.39961202  0.98205697 -1.67093001  1.33309792 -0.36633011  1.166308\n",
            " -0.0248463  -0.50577102 -0.80994    -0.654117   -0.65117051 -0.31050999\n",
            " -0.72997102  3.27642992 -0.9525375  -0.25158699 -0.26714299 -0.44234799\n",
            " -0.02769999 -0.94269001  1.18497403 -0.48305401 -1.56465305 -1.347658\n",
            "  0.76842003 -0.76581399 -0.641954   -1.12052001  1.46954344  0.12904101\n",
            "  0.011334    1.09127341 -0.204604   -0.61592062  1.50043196 -1.48422803\n",
            "  0.39660798  0.1099423  -0.46003597  1.41398998 -0.95286099  1.07283199\n",
            "  0.97881204  0.96673601  1.48759101 -1.1538036  -5.05787012 -0.13238398\n",
            "  0.7741347   0.62606002 -1.66019998 -1.12751401 -0.258233    0.52496999\n",
            "  0.40350304  0.437559    1.43436597  0.32731299  0.50613002 -1.18618771\n",
            " -0.986828   -0.86322811 -0.55285498  0.53480099 -1.542165   -0.10661799\n",
            " -0.207314   -0.42556302 -1.18744001 -1.54081599 -1.885886    0.07237298\n",
            " -0.45552026 -1.13640232  8.08319998 -0.25120801 -0.180024   -0.24510801\n",
            "  0.95931999  0.93801001  0.16526598  1.94992998 -0.74561401 -2.19925699\n",
            " -1.5538946  -0.45945199  0.27103996 -1.60252198  0.79410801  0.65101201\n",
            " -0.08182998 -0.38772398  0.652364    0.67415002  0.05673698 -1.36486898\n",
            " -0.71324899 -0.83237513 -1.23870499  0.19611     0.96511599 -1.78706101\n",
            " -0.86925903  0.08936999 -0.44091799 -0.93989699 -0.70388001 -3.03719003\n",
            "  1.21632898  1.52174     0.51449301  0.12120603 -0.72049099  1.51802799\n",
            " -0.10211198  0.65644797 -0.07785998  2.15741    -3.37817001 -0.4928944\n",
            " -1.03200896  0.42496    -0.24630097  0.27611301  1.35608699 -1.51395131\n",
            " -1.03801602  0.96872502  2.38197903 -0.68751547  0.07566499 -1.73892101\n",
            "  0.80519298  0.58030398  0.28464001 -0.51856232  1.10458501  0.59330899\n",
            " -0.44880902  0.04030501 -1.00165001 -1.21248088  1.12997441 -0.15311303\n",
            "  0.89251106 -1.327129    0.192971    1.01902001  1.98504903  0.87520896\n",
            " -8.26752007 -0.19485     1.06985699 -0.16336602 -1.609587    0.805539\n",
            "  0.64798999  0.94270898  0.94352401  1.66223301 -2.30040003  0.66998401\n",
            " -0.50079999 -0.50369996  0.140137   -0.82546897 -1.89685996  0.17052403\n",
            " -0.75538098  0.17881802  0.23681059 -0.18867    -0.2517583  -0.881048  ]\n",
            "Promedio de vector: [ 0.0669905   0.0453615   0.04223705 -0.2065545   0.0704175   0.1297237\n",
            " -0.14955166 -0.01644903 -0.079705   -1.04580331  0.29128516  0.05611034\n",
            " -0.20232566  0.28843333 -0.14534234 -0.04787334 -0.11185017  0.0928595\n",
            " -0.0339155   0.08585383  0.0124335   0.22445999 -0.05244267  0.25246657\n",
            "  0.03915017  0.118656   -0.05621399 -0.25031872  0.1523035   0.17047467\n",
            " -0.09638784  0.07651334 -0.34434566  0.04944017 -1.07852334 -0.03157894\n",
            " -0.11543     0.31770051  0.13230117  0.04908879 -0.1227505  -0.30252117\n",
            " -0.08418916  0.05449167  0.199555    0.31557667  0.2527905   0.23310166\n",
            "  0.0707125   0.009105    0.11966184 -0.16071467 -0.1423245   0.01327867\n",
            "  0.0174035   0.27569916  0.0752535   0.28252833  0.345424   -0.0146735\n",
            "  0.02059267 -0.01864434  0.26938334 -0.10393733  0.047973   -0.1110355\n",
            "  0.12111617 -0.10037333  0.0561125   0.01416517 -0.08936583  0.004587\n",
            " -0.022618    0.14468834 -0.08757585 -0.1121005   0.164542    0.1364915\n",
            "  0.02539167  0.01646233 -0.11375766  0.00653867  0.37585333 -0.02825916\n",
            "  0.14630817  0.33108334  0.1302385   0.00817116  0.2432847  -0.101025\n",
            "  0.0232945   0.056429   -0.07151185 -0.04333117  0.0259285  -0.06564\n",
            "  0.10490708 -0.10390384 -0.07727116 -0.4331495  -0.0573418   0.11386063\n",
            " -0.03646984 -0.16644866  0.08016983  0.05687117 -0.05207467  0.14459016\n",
            " -0.11074934 -0.11544184  0.033417    0.01502534  0.15089867 -0.07382182\n",
            "  0.25561634 -0.16823567 -0.147352    0.06753767  0.00632    -0.42686333\n",
            " -0.08193834 -0.03790044 -0.00413183  0.0897185   0.07124834 -0.129738\n",
            " -0.066602    0.16367616 -0.27848834  0.22218299 -0.06105502  0.19438467\n",
            " -0.00414105 -0.08429517 -0.13499    -0.1090195  -0.10852842 -0.05175167\n",
            " -0.12166184  0.54607165 -0.15875625 -0.04193116 -0.04452383 -0.07372467\n",
            " -0.00461667 -0.157115    0.19749567 -0.080509   -0.26077551 -0.22460967\n",
            "  0.12807    -0.12763567 -0.10699233 -0.18675334  0.24492391  0.02150683\n",
            "  0.001889    0.1818789  -0.03410067 -0.10265344  0.25007199 -0.24737134\n",
            "  0.06610133  0.01832372 -0.07667266  0.235665   -0.15881016  0.17880533\n",
            "  0.16313534  0.16112267  0.24793183 -0.1923006  -0.84297835 -0.022064\n",
            "  0.12902245  0.10434334 -0.2767     -0.187919   -0.04303883  0.087495\n",
            "  0.06725051  0.0729265   0.23906099  0.05455217  0.084355   -0.19769795\n",
            " -0.16447133 -0.14387135 -0.0921425   0.0891335  -0.2570275  -0.01776966\n",
            " -0.03455233 -0.07092717 -0.19790667 -0.25680267 -0.31431433  0.01206216\n",
            " -0.07592004 -0.18940039  1.3472     -0.041868   -0.030004   -0.04085134\n",
            "  0.15988667  0.156335    0.02754433  0.32498833 -0.124269   -0.36654283\n",
            " -0.25898243 -0.07657533  0.04517333 -0.267087    0.13235133  0.108502\n",
            " -0.01363833 -0.06462066  0.10872733  0.11235834  0.00945616 -0.22747816\n",
            " -0.11887483 -0.13872919 -0.20645083  0.032685    0.16085266 -0.2978435\n",
            " -0.1448765   0.014895   -0.07348633 -0.1566495  -0.11731334 -0.50619834\n",
            "  0.2027215   0.25362333  0.08574884  0.02020101 -0.12008183  0.25300466\n",
            " -0.01701866  0.10940799 -0.01297666  0.35956833 -0.56302834 -0.08214907\n",
            " -0.17200149  0.07082667 -0.04105016  0.04601884  0.2260145  -0.25232522\n",
            " -0.17300267  0.16145417  0.3969965  -0.11458591  0.01261083 -0.28982017\n",
            "  0.13419883  0.09671733  0.04744    -0.08642705  0.1840975   0.09888483\n",
            " -0.0748015   0.0067175  -0.16694167 -0.20208015  0.18832907 -0.02551884\n",
            "  0.14875184 -0.22118817  0.03216183  0.16983667  0.3308415   0.14586816\n",
            " -1.37792001 -0.032475    0.1783095  -0.02722767 -0.2682645   0.1342565\n",
            "  0.10799833  0.15711816  0.157254    0.27703883 -0.3834      0.111664\n",
            " -0.08346667 -0.08394999  0.02335617 -0.13757816 -0.31614333  0.02842067\n",
            " -0.12589683  0.029803    0.03946843 -0.031445   -0.04195972 -0.14684133]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar una review específica para probar\n",
        "review_ejemplo = train_df[train_df['review'].str.contains('the only problem')]['review'].values[0]\n",
        "\n",
        "# Obtener los vectores suma y promedio de la review\n",
        "suma, promedio = representar_review_como_vector(review_ejemplo)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlP7h51JoELd",
        "outputId": "bcc49392-1a30-4ce1-8c00-1f54f17bdfd6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No está la palabra closed-down\n",
            "No está la palabra don't\n",
            "No está la palabra couldn't\n",
            "No está la palabra killer's\n",
            "No está la palabra identital\n",
            "No está la palabra you'll\n",
            "No está la palabra suspeneful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIEZW-TTqs8V"
      },
      "source": [
        "## **Implementamos Doc2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPeCReMEo0IW",
        "outputId": "573d1cbf-7ed2-412a-fc36-685c12bf7ba9"
      },
      "source": [
        "\n",
        "problem = train_df[train_df['review'].str.contains('the only problem')]['review'].values[0]\n",
        "suma, promedio = representar_review_como_vector(problem)\n",
        "print(suma)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No está la palabra closed-down\n",
            "No está la palabra don't\n",
            "No está la palabra couldn't\n",
            "No está la palabra killer's\n",
            "No está la palabra identital\n",
            "No está la palabra you'll\n",
            "No está la palabra suspeneful\n",
            "[-4.59138169e+01  4.61852148e+01 -1.83477440e+00 -6.36723800e+01\n",
            " -1.25150736e+01  1.23591820e+01 -5.13842206e+01  2.69998580e+01\n",
            "  3.30345372e+01 -6.88852463e+02  8.27908245e+01  1.32319507e+01\n",
            " -3.51826081e+01  6.33438807e+01  4.42306485e+01  2.23102066e+01\n",
            " -1.01584576e+02 -4.41097325e+00  1.34701597e+01 -3.19089915e+01\n",
            "  9.94443619e-02  1.11540788e+02  8.03917519e+01  6.47379369e+01\n",
            " -8.04723655e+01  9.81717463e+00  3.01084539e+01 -6.09712993e+01\n",
            " -3.40426375e+01  4.76380967e+01 -3.58202230e+00  1.12309295e+02\n",
            " -8.40496673e+01  3.88052887e+01 -3.69947138e+02  2.08287777e+01\n",
            " -1.40937854e+01  3.79515735e+01 -4.07133025e+01  2.47540927e+01\n",
            "  2.40702482e+01 -6.90864819e+01 -3.76756686e+01  5.88299646e+01\n",
            "  3.66336603e+01  3.82451890e+01  6.87086589e+01  6.32599449e+01\n",
            " -3.60890346e+01  2.20133940e+01  1.43689172e+01 -4.44534243e+01\n",
            "  1.36193847e+01 -1.24877257e+01 -1.95696485e+01  6.85289102e+01\n",
            " -3.78980817e+01  8.95981611e+01  8.90504265e+01 -3.39301150e+01\n",
            "  2.43285918e+01  1.16199833e+01  1.08849474e+02  1.52442105e+01\n",
            " -2.97494023e+01 -1.58453054e+02  6.57624089e+01  6.71259918e+00\n",
            "  4.27585894e+01 -1.54138882e+01  8.32779819e+00  5.70273265e+00\n",
            "  2.35590658e+01  3.24265427e+01 -2.19725594e+01 -7.70746044e+00\n",
            "  5.21337156e+01  5.00399625e+01 -6.37819925e+01 -1.45659713e+01\n",
            " -4.20977470e+01 -4.54246807e+01  8.69416606e+01  3.12449365e+01\n",
            "  2.77612240e+01  4.37640848e+01 -3.33995971e+01  9.52677326e+01\n",
            "  1.06929764e+01  2.39253855e+01 -7.41867591e+01  6.52456313e+01\n",
            " -6.90914853e+01 -7.10883380e+01 -2.00576469e+01 -1.74696933e+00\n",
            " -1.00247936e+02  6.97562140e+00  3.93923453e+00 -1.60663722e+02\n",
            "  3.21967723e+01  9.65988616e+00 -1.44688952e+00 -2.48424793e+00\n",
            " -1.52019380e+01  3.30635458e+00  3.28700080e+01  2.59409321e+01\n",
            " -3.89275941e+01  4.40204456e+01 -3.38853535e+01 -5.17473839e+01\n",
            " -4.60286912e+01 -8.46229965e+01  7.74130752e+01  4.80810227e+01\n",
            " -3.38031900e+01  2.87508454e-01 -1.67175190e+01 -1.06075150e+02\n",
            " -3.00169341e+01 -3.61429559e+01  1.32811304e+01  5.43857396e+01\n",
            " -2.31921021e-02 -3.36518530e+01  4.25262954e+01  6.99139587e+01\n",
            "  3.74892342e+01  1.69072940e+01  1.46206561e+01  5.65421749e+01\n",
            "  6.30179318e+01 -1.12372453e+01 -1.98080194e+01  1.05450927e+01\n",
            " -4.31111282e+00 -2.35550488e+01 -2.43351298e+01  8.12316695e+01\n",
            " -2.27897494e+01  3.92621064e+01 -1.37854172e+01  4.16505797e+01\n",
            " -1.38734308e+02 -6.32758687e+01  3.78930351e+01  1.17361105e+01\n",
            " -9.04049250e+01  2.28470581e+01  7.64129801e+01 -4.26744010e+01\n",
            "  1.32158821e+01 -7.04695678e+00  1.36787458e+02  6.34607778e+00\n",
            " -1.88566784e+01 -4.13014424e+00  9.01304850e+00 -2.66019414e+01\n",
            "  6.25731946e+01 -8.28936320e+01  1.25112996e+01 -6.44557774e+01\n",
            " -7.47180689e+00  5.82308786e+01 -3.62089529e+00  3.51709839e+01\n",
            "  7.02690311e-01  5.50576087e+01  4.80912146e+01  2.61131185e+00\n",
            " -2.59953793e+02  3.86178871e+01 -1.44611274e+01  3.65139257e+01\n",
            " -2.95541101e+01  1.45513556e+01 -1.39491032e+01  1.04399134e+02\n",
            "  3.84879223e+01  4.86691347e+01  4.87355475e+01  1.47521712e+01\n",
            "  1.40103460e+00 -5.43985264e+01 -7.80287805e+01  7.17866025e+00\n",
            "  2.34138508e+01  5.78476653e+01 -3.00012102e+01  6.39774219e+01\n",
            "  3.98639165e+01 -4.31058065e+01 -2.43153911e+01 -3.49388610e+01\n",
            " -5.07731338e+01 -3.61893944e+01  2.22484962e+01 -4.45479344e+01\n",
            "  4.59819165e+02 -3.24459572e+01 -4.14411394e-01 -5.08810412e+00\n",
            "  4.80793751e+01  3.34835704e+01 -1.58932103e+01  3.69056264e+01\n",
            " -2.80737038e+01 -7.40600425e+01 -3.03434081e+01 -2.02518439e+01\n",
            "  5.80439587e+01  8.10776633e+00  4.93210465e+01  1.40310235e+01\n",
            "  3.29063851e+01  3.92506656e+01 -9.96920834e+00 -3.97486708e+00\n",
            "  3.85555724e+01 -3.49979005e+01 -5.96931109e+01  1.71969083e+01\n",
            " -2.01872255e+01 -4.83666563e+00  4.48001790e+01 -7.18560381e+00\n",
            " -1.82129536e+01 -3.72482704e+01  3.10477609e+01 -9.33571095e+00\n",
            " -1.48613833e+01 -7.99417615e+01  2.60629924e+01  5.71096232e+01\n",
            "  4.85908511e+01  2.19670179e+01 -3.32058687e+01  6.01385307e+01\n",
            "  2.57739379e+00  2.14191275e+01  1.18386866e+02  4.42986733e+01\n",
            " -2.43357975e+02 -3.22935657e+01  6.95723265e+01 -2.69234442e+00\n",
            " -3.27358957e+01 -9.64676381e+00  3.72488018e+01 -4.18842245e+01\n",
            " -6.27477209e+01  1.37906333e+01  1.31446110e+02 -5.27007176e+00\n",
            "  4.15361676e+00 -6.94459991e+01  6.09109520e+01  2.80644373e+01\n",
            " -1.03555984e+01 -6.95520168e+01  3.93010427e+01  1.66143203e+01\n",
            " -3.30754076e+01 -1.94294860e+01 -2.22479398e+01 -3.83469941e+01\n",
            "  6.73139395e+01  7.03630308e+01 -2.67258245e+00 -4.82475437e+01\n",
            "  7.38997020e+00  6.02701147e+01  1.78922207e+01  5.80211451e+01\n",
            " -8.49317668e+02 -3.03425533e+01  1.88814931e+02  2.47084556e+01\n",
            " -8.18175476e+01 -2.36499555e+00 -1.26462177e+01 -1.49247961e+01\n",
            " -1.34556976e+01  8.25857665e+01 -4.53203250e+01  5.98323598e+01\n",
            "  5.53178867e+00  3.68845228e+00 -8.28903665e+00 -8.37700131e+01\n",
            " -1.68780704e+01  3.56149915e+01  2.07283593e+01  5.50870919e+01\n",
            "  5.88062392e+00 -6.25099449e+01 -5.75366503e+01  3.70836116e+01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representar_review_como_vector_promedio(review):\n",
        "    # Utiliza la función previamente definida para obtener los vectores suma y promedio\n",
        "    vectores, promedio = representar_review_como_vector(review)\n",
        "    return promedio\n"
      ],
      "metadata": {
        "id": "rZPUAlOgqOT-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscar reviews que contienen la frase 'the only problem'\n",
        "matching_reviews = train_df[train_df['review'].str.contains('the only problem', case=False)]\n",
        "\n",
        "# Verificar si se encontraron reviews\n",
        "if matching_reviews.empty:\n",
        "    print(\"No se encontraron reviews que contengan la frase 'the only problem'.\")\n",
        "else:\n",
        "    # Seleccionar la primera review que coincide\n",
        "    review_ejemplo = matching_reviews['review'].values[0]\n",
        "\n",
        "    # Obtener el vector promedio de la review\n",
        "    promedio = representar_review_como_vector_promedio(review_ejemplo)\n",
        "\n",
        "    # Encontrar las palabras más similares al vector promedio\n",
        "    print(\"Palabras similares al vector promedio:\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rII0xuQPqS1O",
        "outputId": "da7da9ef-9987-44cc-db72-d9a2d717246b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No está la palabra closed-down\n",
            "No está la palabra don't\n",
            "No está la palabra couldn't\n",
            "No está la palabra killer's\n",
            "No está la palabra identital\n",
            "No está la palabra you'll\n",
            "No está la palabra suspeneful\n",
            "Palabras similares al vector promedio:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drco-DEoOb6w"
      },
      "source": [
        "# Red RNN  pero con Embeddings preentrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReOXN3bAOXMm",
        "outputId": "b9b6d14a-cf6c-40a4-9cc2-64683aef8ccf"
      },
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    # A simpleRNN without any pretrained embeddings and one dense layer\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "    model.add(Conv1D(128, 5, activation=\"relu\"))\n",
        "    model.add(MaxPooling1D(5))\n",
        "    model.add(Conv1D(128, 5, activation=\"relu\"))\n",
        "    model.add(MaxPooling1D(5))\n",
        "    model.add(Conv1D(128, 5, activation=\"relu\"))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='sigmoid'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=64*strategy.num_replicas_in_sync, validation_data=(xvalid_pad,yvalid_one_hot))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 12s 155ms/step - loss: 0.7298 - accuracy: 0.5150 - val_loss: 0.7024 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 1s 62ms/step - loss: 0.6972 - accuracy: 0.5258 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 1s 62ms/step - loss: 0.6971 - accuracy: 0.5083 - val_loss: 0.6895 - val_accuracy: 0.6200\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 1s 62ms/step - loss: 0.6815 - accuracy: 0.5800 - val_loss: 0.6763 - val_accuracy: 0.5875\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 1s 62ms/step - loss: 0.6292 - accuracy: 0.6792 - val_loss: 0.7581 - val_accuracy: 0.5050\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 1s 62ms/step - loss: 0.5196 - accuracy: 0.7533 - val_loss: 0.5454 - val_accuracy: 0.7300\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 1s 64ms/step - loss: 0.3087 - accuracy: 0.8683 - val_loss: 0.5042 - val_accuracy: 0.7750\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 1s 65ms/step - loss: 0.1259 - accuracy: 0.9608 - val_loss: 0.5494 - val_accuracy: 0.7600\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 1s 66ms/step - loss: 0.0395 - accuracy: 0.9900 - val_loss: 0.6994 - val_accuracy: 0.7550\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 1s 75ms/step - loss: 0.0552 - accuracy: 0.9783 - val_loss: 0.7506 - val_accuracy: 0.7375\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 1s 67ms/step - loss: 0.0502 - accuracy: 0.9825 - val_loss: 0.9013 - val_accuracy: 0.7475\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 1s 77ms/step - loss: 0.0287 - accuracy: 0.9917 - val_loss: 0.9231 - val_accuracy: 0.7475\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 1s 67ms/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.8800 - val_accuracy: 0.7525\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 1s 76ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8675 - val_accuracy: 0.7700\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 1s 75ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 0.8884 - val_accuracy: 0.7725\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 1s 76ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.9407 - val_accuracy: 0.7600\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 1s 77ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 0.7625\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 1s 66ms/step - loss: 6.5188e-04 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.7575\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 1s 64ms/step - loss: 6.0753e-04 - accuracy: 1.0000 - val_loss: 1.0175 - val_accuracy: 0.7525\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 1s 64ms/step - loss: 4.9523e-04 - accuracy: 1.0000 - val_loss: 1.0307 - val_accuracy: 0.7550\n",
            "CPU times: user 23.2 s, sys: 1.25 s, total: 24.4 s\n",
            "Wall time: 43.7 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f111db7ace0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk8NlGCDmQer",
        "outputId": "0fb33557-d6be-4aea-9660-bdeb880a58d2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 2s 11ms/step\n",
            "Accuracy: 0.755\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.74      0.75       200\n",
            "    positive       0.75      0.77      0.76       200\n",
            "\n",
            "    accuracy                           0.76       400\n",
            "   macro avg       0.76      0.76      0.75       400\n",
            "weighted avg       0.76      0.76      0.75       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQbY143FqUwf"
      },
      "source": [
        "# **LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el modelo\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(word_index) + 1,\n",
        "                        output_dim=embedding_dim,\n",
        "                        weights=[embedding_matrix],\n",
        "                        input_length=max_len,\n",
        "                        trainable=False))\n",
        "    model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "    model.add(Dense(2, activation='sigmoid'))  # Cambiado a 2 para clasificación binaria\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ-6UF3ktyBr",
        "outputId": "960989cf-3904-4446-9d87-5a9e276589a4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 2700, 300)         11809200  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               160400    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11969802 (45.66 MB)\n",
            "Trainable params: 160602 (627.35 KB)\n",
            "Non-trainable params: 11809200 (45.05 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zr546G0tsY4",
        "outputId": "fa4f3dfe-3773-4eca-e617-e0f01f7257ad"
      },
      "source": [
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=64*strategy.num_replicas_in_sync, validation_data=(xvalid_pad,yvalid_one_hot))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 261s 14s/step - loss: 0.6934 - accuracy: 0.4917 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 261s 14s/step - loss: 0.6932 - accuracy: 0.4867 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 254s 14s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 252s 13s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 258s 13s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 257s 13s/step - loss: 0.6933 - accuracy: 0.4850 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 257s 14s/step - loss: 0.6932 - accuracy: 0.4675 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 251s 13s/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 250s 13s/step - loss: 0.6932 - accuracy: 0.4858 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 255s 13s/step - loss: 0.6932 - accuracy: 0.5050 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 256s 13s/step - loss: 0.6932 - accuracy: 0.4942 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 252s 13s/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 256s 14s/step - loss: 0.6932 - accuracy: 0.5058 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 258s 14s/step - loss: 0.6932 - accuracy: 0.5083 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 256s 14s/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 255s 14s/step - loss: 0.6932 - accuracy: 0.4908 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 244s 13s/step - loss: 0.6933 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 254s 13s/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 251s 13s/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 246s 13s/step - loss: 0.6932 - accuracy: 0.4842 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f1084376860>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi9BlwIm8MRp",
        "outputId": "8fb221d5-2983-4dec-e58b-7f29b5b42b42"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 40s 3s/step\n",
            "Accuracy: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.00      0.00      0.00       200\n",
            "    positive       0.50      1.00      0.67       200\n",
            "\n",
            "    accuracy                           0.50       400\n",
            "   macro avg       0.25      0.50      0.33       400\n",
            "weighted avg       0.25      0.50      0.33       400\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXwtcBAXqZec"
      },
      "source": [
        "# **GRU**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(word_index) + 1,\n",
        "                        output_dim=embedding_dim,\n",
        "                        weights=[embedding_matrix],\n",
        "                        input_length=max_len,\n",
        "                        trainable=False))\n",
        "    model.add(SpatialDropout1D(0.3))\n",
        "    model.add(GRU(300))\n",
        "    model.add(Dense(2, activation='sigmoid'))  # Cambiado a 2 para clasificación binaria\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpYtKYhnsk0L",
        "outputId": "f98ae2e4-6b44-483d-9bf6-1a9b2503b8d8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 2700, 300)         11809200  \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 2700, 300)         0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 300)               541800    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 602       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12351602 (47.12 MB)\n",
            "Trainable params: 542402 (2.07 MB)\n",
            "Non-trainable params: 11809200 (45.05 MB)\n",
            "_________________________________________________________________\n",
            "CPU times: user 324 ms, sys: 123 ms, total: 447 ms\n",
            "Wall time: 447 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ncf-UiS2Lxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6245bb-7cfe-472c-97da-6f040c57c309"
      },
      "source": [
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=64*strategy.num_replicas_in_sync, validation_data=(xvalid_pad,yvalid_one_hot))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 9s 321ms/step - loss: 0.6934 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 6s 302ms/step - loss: 0.6932 - accuracy: 0.4883 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 6s 339ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 6s 339ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 6s 304ms/step - loss: 0.6933 - accuracy: 0.4883 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 6s 338ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 6s 343ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 8s 410ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 6s 304ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 6s 338ms/step - loss: 0.6932 - accuracy: 0.4883 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 7s 376ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 6s 307ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 6s 300ms/step - loss: 0.6932 - accuracy: 0.4817 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 7s 363ms/step - loss: 0.6933 - accuracy: 0.4783 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 6s 340ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 6s 340ms/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 6s 301ms/step - loss: 0.6932 - accuracy: 0.4750 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 6s 305ms/step - loss: 0.6932 - accuracy: 0.4667 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 6s 341ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 6s 341ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f1072c22ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r-6LcmIuapP",
        "outputId": "1889501a-df89-4990-c079-2a675e48d65c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 2s 72ms/step\n",
            "Accuracy: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.00      0.00      0.00       200\n",
            "    positive       0.50      1.00      0.67       200\n",
            "\n",
            "    accuracy                           0.50       400\n",
            "   macro avg       0.25      0.50      0.33       400\n",
            "weighted avg       0.25      0.50      0.33       400\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dByA5hFqqfO9"
      },
      "source": [
        "# **bidirectional LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definir el modelo bidireccional LSTM\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(word_index) + 1,\n",
        "                        output_dim=embedding_dim,\n",
        "                        weights=[embedding_matrix],\n",
        "                        input_length=max_len,\n",
        "                        trainable=False))\n",
        "    model.add(Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3)))\n",
        "    model.add(Dense(2, activation='sigmoid'))  # Cambiado a 2 para clasificación binaria\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWHoxIFPv6gR",
        "outputId": "3ab60867-3ffd-449c-a773-b523d4bf5e12"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 2700, 300)         11809200  \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 256)               439296    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12249010 (46.73 MB)\n",
            "Trainable params: 439810 (1.68 MB)\n",
            "Non-trainable params: 11809200 (45.05 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el callback personalizado\n",
        "import datetime\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch_time_start = datetime.datetime.now()\n",
        "        print(f\"Epoch {epoch + 1} start time: {self.epoch_time_start}\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.epoch_time_end = datetime.datetime.now()\n",
        "        print(f\"Epoch {epoch + 1} end time: {self.epoch_time_end}\")\n"
      ],
      "metadata": {
        "id": "_8xI7dB0lEgO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EarlyStopping: Añadí el callback EarlyStopping para detener el entrenamiento si la validación no mejora después de 3 épocas, lo cual puede ahorrar tiempo."
      ],
      "metadata": {
        "id": "ZamugX5RtkcK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FuTmnT87tlUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduced batch size\n",
        "batch_size = 64 * strategy.num_replicas_in_sync\n",
        "# Crear una instancia de los callbacks\n",
        "time_callback = TimeHistory()\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Entrenar el modelo con los callbacks\n",
        "model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=batch_size, validation_data=(xvalid_pad, yvalid_one_hot), callbacks=[time_callback, early_stopping])\n",
        "\n",
        "#model.fit(xtrain_pad, ytrain_one_hot, epochs=20, batch_size=batch_size, validation_data=(xvalid_pad, yvalid_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNE01-i9yEWj",
        "outputId": "28fc2e0f-9832-4098-9e1d-e107761cb4bf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 start time: 2024-07-04 13:17:06.315802\n",
            "Epoch 1/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6964 - accuracy: 0.5183 Epoch 1 end time: 2024-07-04 13:23:55.106132\n",
            "19/19 [==============================] - 409s 21s/step - loss: 0.6964 - accuracy: 0.5183 - val_loss: 0.6936 - val_accuracy: 0.5275\n",
            "Epoch 2 start time: 2024-07-04 13:23:55.116909\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6778 - accuracy: 0.5775 Epoch 2 end time: 2024-07-04 13:30:34.453928\n",
            "19/19 [==============================] - 399s 21s/step - loss: 0.6778 - accuracy: 0.5775 - val_loss: 0.6941 - val_accuracy: 0.5125\n",
            "Epoch 3 start time: 2024-07-04 13:30:34.471241\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6625 - accuracy: 0.6358 Epoch 3 end time: 2024-07-04 13:37:25.832788\n",
            "19/19 [==============================] - 411s 22s/step - loss: 0.6625 - accuracy: 0.6358 - val_loss: 0.7025 - val_accuracy: 0.5400\n",
            "Epoch 4 start time: 2024-07-04 13:37:25.843448\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6426 - accuracy: 0.6433 Epoch 4 end time: 2024-07-04 13:44:20.176433\n",
            "19/19 [==============================] - 414s 22s/step - loss: 0.6426 - accuracy: 0.6433 - val_loss: 0.6826 - val_accuracy: 0.5825\n",
            "Epoch 5 start time: 2024-07-04 13:44:20.188203\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.6750 Epoch 5 end time: 2024-07-04 13:51:05.056435\n",
            "19/19 [==============================] - 405s 21s/step - loss: 0.6136 - accuracy: 0.6750 - val_loss: 0.6954 - val_accuracy: 0.5500\n",
            "Epoch 6 start time: 2024-07-04 13:51:05.072841\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5779 - accuracy: 0.7133 Epoch 6 end time: 2024-07-04 13:58:10.211631\n",
            "19/19 [==============================] - 425s 22s/step - loss: 0.5779 - accuracy: 0.7133 - val_loss: 0.6911 - val_accuracy: 0.6125\n",
            "Epoch 7 start time: 2024-07-04 13:58:10.227052\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5297 - accuracy: 0.7283 Epoch 7 end time: 2024-07-04 14:05:03.310320\n",
            "19/19 [==============================] - 413s 22s/step - loss: 0.5297 - accuracy: 0.7283 - val_loss: 0.7387 - val_accuracy: 0.5550\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f108454c880>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i-8g7N9ecyWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "13:52\n",
        "2:05\n",
        "15 min por epoch"
      ],
      "metadata": {
        "id": "SoLYSzRgg4A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir en el conjunto de validación\n",
        "preds = np.argmax(model.predict(xvalid_pad), axis=-1)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = metrics.accuracy_score(yvalid_encoded, preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "target_names = label_encoder.classes_  # Esto debería ser ['negative', 'positive']\n",
        "clas_report = classification_report(yvalid_encoded, preds, target_names=target_names)\n",
        "print(clas_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq1E_HSpwJya",
        "outputId": "102e0f34-9307-4184-b9e8-6ceac98fe83d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 22s 2s/step\n",
            "Accuracy: 0.555\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.56      0.48      0.52       200\n",
            "    positive       0.55      0.63      0.59       200\n",
            "\n",
            "    accuracy                           0.56       400\n",
            "   macro avg       0.56      0.55      0.55       400\n",
            "weighted avg       0.56      0.56      0.55       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(datetime.datetime.now())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpzyOe4Y9Z5k",
        "outputId": "28655a48-691c-4266-a366-da064cbc534f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-04 11:22:16.004477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_T5GB6ketS_",
        "outputId": "ecfdacb9-6870-4f9f-be7d-72d62afe2bac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-04 11:22:16.016657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocesar_review(review, tokenizer, max_len):\n",
        "    # Convertir la review en una secuencia de índices\n",
        "    seq = tokenizer.texts_to_sequences([review])\n",
        "    # Aplicar padding a la secuencia\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_len)\n",
        "    return padded_seq\n",
        "\n",
        "def clasificar_review(review, model, tokenizer, max_len):\n",
        "    # Preprocesar la review\n",
        "    preprocessed_review = preprocesar_review(review, tokenizer, max_len)\n",
        "    # Hacer la predicción\n",
        "    pred = model.predict(preprocessed_review)\n",
        "    # Obtener la clase predicha\n",
        "    pred_class = (pred > 0.5).astype(int)\n",
        "    return 'positive' if pred_class[0][0] == 1 else 'negative'\n",
        "\n",
        "nueva_review = \"This movie was incredible, the acting was spectacular and the plot very engaging.\"\n",
        "resultado = clasificar_review(nueva_review, model, tokenizer, max_len)\n",
        "print(f\"La review es: {resultado}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qGQPrgxfHqn",
        "outputId": "c95533fd-6599-4e87-f2a8-954ddcb7c32f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "La review es: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WkyB9QSOMiEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nueva_review = \"The Adventure Never Ends is an absolute trainwreck, plagued by a nonsensical plot, painfully bad acting, and horrendous special effects.\"\n",
        "resultado = clasificar_review(nueva_review, model, tokenizer, max_len)\n",
        "print(f\"La review es: {resultado}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuaiDZ-VKSI4",
        "outputId": "8f34ed08-520b-4172-ce65-e0b27509e22d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 7s 7s/step\n",
            "La review es: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9dWuwfyxkaDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados de la Clasificación de Reviews de Películas\n",
        "\n",
        "| Modelo                       | Embeddings          | Accuracy | Negative Precision | Negative Recall | Negative F1-Score | Positive Precision | Positive Recall | Positive F1-Score | Macro Avg Precision | Macro Avg Recall | Macro Avg F1-Score | Weighted Avg Precision | Weighted Avg Recall | Weighted Avg F1-Score |\n",
        "|------------------------------|---------------------|----------|--------------------|----------------|-------------------|--------------------|----------------|-------------------|----------------------|------------------|---------------------|-------------------------|---------------------|------------------------|\n",
        "| SimpleRNN                    | Aleatorios          | 0.49     | 0.49               | 0.69           | 0.57              | 0.48               | 0.29           | 0.37              | 0.49                 | 0.49             | 0.47                | 0.49                    | 0.49                | 0.47                   |\n",
        "| CNN                          | Aleatorios          | 0.78     | 0.79               | 0.77           | 0.78              | 0.77               | 0.79           | 0.78              | 0.78                 | 0.78             | 0.78                | 0.78                    | 0.78                | 0.78                   |\n",
        "| RNN                          | Preentrenados (es)  | 0.65     | 0.66               | 0.60           | 0.63              | 0.63               | 0.69           | 0.66              | 0.65                 | 0.65             | 0.64                | 0.65                    | 0.65                | 0.64                   |\n",
        "| RNN                          | Preentrenados (en)  | 0.76     | 0.76               | 0.74           | 0.75              | 0.75               | 0.77           | 0.76              | 0.76                 | 0.76             | 0.75                | 0.76                    | 0.76                | 0.75                   |\n",
        "| LSTM                         | Preentrenados (es)  | 0.50     | 0.50               | 1.00           | 0.67              | 0.00               | 0.00           | 0.00              | 0.25                 | 0.50             | 0.33                | 0.25                    | 0.50                | 0.33                   |\n",
        "| LSTM                         | Preentrenados (en)  | 0.50     | 0.00               | 0.00           | 0.00              | 0.50               | 1.00           | 0.67              | 0.25                 | 0.50             | 0.33                | 0.25                    | 0.50                | 0.33                   |\n",
        "| GRU                          | Preentrenados (es)  | 0.50     | 0.50               | 1.00           | 0.67              | 0.00               | 0.00           | 0.00              | 0.25                 | 0.50             | 0.33                | 0.25                    | 0.50                | 0.33                   |\n",
        "| GRU                          | Preentrenados (en)  | 0.50     | 0.00               | 0.00           | 0.00              | 0.50               | 1.00           | 0.67              | 0.25                 | 0.50             | 0.33                | 0.25                    | 0.50                | 0.33                   |\n",
        "| Bidirectional LSTM           | Preentrenados (es)  | 0.48     | 0.47               | 0.47           | 0.48              | 0.47               | 0.47           | 0.48              | 0.47                 | 0.47             | 0.48                | 0.47                    | 0.47                | 0.47                   |\n",
        "| Bidirectional LSTM           | Preentrenados (en)  | 0.56     | 0.56               | 0.48           | 0.52              | 0.55               | 0.63           | 0.59              | 0.56                 | 0.55             | 0.55                | 0.56                    | 0.56                | 0.55                   |\n",
        "\n",
        "## Conclusiones\n",
        "\n",
        "1. **Mejor Modelo**:\n",
        "   - El **CNN con embeddings aleatorios** se destacó como el mejor modelo con una accuracy de 0.78. Este modelo también tuvo buenos valores en todas las métricas de precisión, recall y F1-score.\n",
        "\n",
        "2. **Influencia de los Embeddings**:\n",
        "   - Los embeddings preentrenados en inglés mostraron mejor rendimiento que los embeddings preentrenados en español, lo cual es lógico dado que las reviews están en inglés.\n",
        "   - El uso de embeddings aleatorios fue sorprendentemente efectivo, especialmente en el modelo CNN.\n",
        "\n",
        "3. **Desempeño de Diferentes Modelos**:\n",
        "   - Los modelos basados en RNN y LSTM no mejoraron significativamente con los embeddings preentrenados en español debido a la discrepancia idiomática.\n",
        "   - El modelo Bidirectional LSTM con embeddings preentrenados en inglés mostró un desempeño aceptable, pero no superó al modelo CNN.\n",
        "\n",
        "\n",
        "Estos resultados destacan la importancia de utilizar embeddings en el idioma adecuado y el potencial de diferentes arquitecturas de redes neuronales en tareas de clasificación de texto.\n"
      ],
      "metadata": {
        "id": "UcIt_SWmkmXA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFnZwCVCkmE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Supongamos que `model` es el modelo CNN ya entrenado\n",
        "# y `tokenizer` es el tokenizer ajustado en el conjunto de datos de entrenamiento\n",
        "\n",
        "def preprocesar_review(review, tokenizer, max_len):\n",
        "    # Convertir la review en una secuencia de índices\n",
        "    seq = tokenizer.texts_to_sequences([review])\n",
        "    # Aplicar padding a la secuencia\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_len)\n",
        "    return padded_seq\n",
        "\n",
        "def clasificar_review(review, model, tokenizer, max_len):\n",
        "    # Preprocesar la review\n",
        "    preprocessed_review = preprocesar_review(review, tokenizer, max_len)\n",
        "    # Hacer la predicción\n",
        "    pred = model.predict(preprocessed_review)\n",
        "    # Obtener la clase predicha\n",
        "    pred_class = np.argmax(pred, axis=1)\n",
        "    return 'positive' if pred_class[0] == 1 else 'negative'\n",
        "\n",
        "# Ejemplo de uso:\n",
        "nueva_review = \"This movie was incredible, the acting was spectacular and the plot was very involving.\"\n",
        "resultado = clasificar_review(nueva_review, model, tokenizer, max_len)\n",
        "print(f\"La review es: {resultado}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaciaV-PwI2R",
        "outputId": "8d2964a4-d3b6-4c60-f88b-25c810250591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "La review es: positive\n"
          ]
        }
      ]
    }
  ]
}